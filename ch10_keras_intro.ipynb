{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 17:47:23.709935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras originally stores the image arrays as 28x28 matrices w/ pixel intensities represented as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                   \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Model Using the Sequential API\n",
    "- A Sequential model is the simplest kind of Keras model, for NNs composed of single stack of layers, connected sequentially\n",
    "- Flatten layer converts input image to 1D array\n",
    "    - input layer, doesn't have parameters, just preprocessing\n",
    "- Dense hidden layer manages its own weight matrix and vector of bias terms\n",
    "- Final layer is dense output w/ 1 neuron per clas using softmax since the classes are exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers\n",
    "hidden1 = model.layers[1].name\n",
    "weights, biases = model.get_layer(hidden1).get_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model weights are initialized randomly to break symmetry, w/ biases initialized to zero. A different initialization method can be set with kernel_initializer or bias_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = \"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model_cloned = keras.models.clone_model(model)\n",
    "model_cloned.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use many other losses, optimizers and met‐ rics in this book, but for the full lists see https://keras.io/losses/, https://keras.io/optimizers/ and https://keras.io/metrics/ \\\n",
    "First, we use the \"sparse_categorical_crossen tropy\" loss because we have sparse labels (i.e., for each instance there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had one target probability per class for each instance (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need to use the \"categorical_crossentropy\" loss instead. If we were doing binary classi‐ fication (with one or more binary labels), then we would use the \"sigmoid\" (i.e., logistic) activation function in the output layer instead of the \"softmax\" activation function, and we would use the \"binary_crossentropy\" loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can convert sparse labels (class indices) to one-hot vector labesl w/ keras.utils.to_categorical() or np.argmax() fcn w/ axis = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"sgd\" means model will be trained with Stochastic Gradient Descent to perform backpropagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model\n",
    "Model is ready to be trained w/ fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 0.0794 - accuracy: 0.9735 - val_loss: 0.3367 - val_accuracy: 0.8982\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0797 - accuracy: 0.9723 - val_loss: 0.3471 - val_accuracy: 0.8978\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0796 - accuracy: 0.9735 - val_loss: 0.3451 - val_accuracy: 0.8992\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 0.3433 - val_accuracy: 0.8994\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0754 - accuracy: 0.9745 - val_loss: 0.3452 - val_accuracy: 0.9018\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0752 - accuracy: 0.9738 - val_loss: 0.3928 - val_accuracy: 0.8900\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0739 - accuracy: 0.9751 - val_loss: 0.3435 - val_accuracy: 0.8992\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0718 - accuracy: 0.9756 - val_loss: 0.3544 - val_accuracy: 0.8996\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0704 - accuracy: 0.9766 - val_loss: 0.3432 - val_accuracy: 0.8994\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0686 - accuracy: 0.9769 - val_loss: 0.3846 - val_accuracy: 0.8934\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0680 - accuracy: 0.9768 - val_loss: 0.3473 - val_accuracy: 0.9026\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.3548 - val_accuracy: 0.9032\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0660 - accuracy: 0.9779 - val_loss: 0.3747 - val_accuracy: 0.9018\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0660 - accuracy: 0.9781 - val_loss: 0.3898 - val_accuracy: 0.8918\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0630 - accuracy: 0.9788 - val_loss: 0.3783 - val_accuracy: 0.8964\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0606 - accuracy: 0.9803 - val_loss: 0.3690 - val_accuracy: 0.8966\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0609 - accuracy: 0.9799 - val_loss: 0.3885 - val_accuracy: 0.8980\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.3741 - val_accuracy: 0.8998\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0587 - accuracy: 0.9805 - val_loss: 0.3853 - val_accuracy: 0.8926\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.0580 - accuracy: 0.9808 - val_loss: 0.3657 - val_accuracy: 0.8978\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0558 - accuracy: 0.9815 - val_loss: 0.3832 - val_accuracy: 0.9000\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 0.4137 - val_accuracy: 0.8936\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0533 - accuracy: 0.9828 - val_loss: 0.3957 - val_accuracy: 0.8920\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.3890 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0514 - accuracy: 0.9830 - val_loss: 0.4041 - val_accuracy: 0.8968\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.3938 - val_accuracy: 0.8936\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.4264 - val_accuracy: 0.8952\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0508 - accuracy: 0.9834 - val_loss: 0.3886 - val_accuracy: 0.9008\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0479 - accuracy: 0.9846 - val_loss: 0.4272 - val_accuracy: 0.8908\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.4008 - val_accuracy: 0.8994\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.4177 - val_accuracy: 0.8968\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.4223 - val_accuracy: 0.9010\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.4148 - val_accuracy: 0.8964\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 0.4161 - val_accuracy: 0.8920\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.4213 - val_accuracy: 0.8960\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.4058 - val_accuracy: 0.8988\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.4420 - val_accuracy: 0.8866\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.4108 - val_accuracy: 0.8996\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.3985 - val_accuracy: 0.8976\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.4397 - val_accuracy: 0.8946\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.4232 - val_accuracy: 0.8998\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0393 - accuracy: 0.9879 - val_loss: 0.4331 - val_accuracy: 0.8974\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.4385 - val_accuracy: 0.8994\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 0.4324 - val_accuracy: 0.8976\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0342 - accuracy: 0.9898 - val_loss: 0.4359 - val_accuracy: 0.8958\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 0.4268 - val_accuracy: 0.9014\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.4438 - val_accuracy: 0.8970\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.4256 - val_accuracy: 0.8998\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.4479 - val_accuracy: 0.8982\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 0.4432 - val_accuracy: 0.9026\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 50,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.7060 - accuracy: 0.7658 - val_loss: 0.4935 - val_accuracy: 0.8370\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4894 - accuracy: 0.8313 - val_loss: 0.4423 - val_accuracy: 0.8504\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4447 - accuracy: 0.8438 - val_loss: 0.4214 - val_accuracy: 0.8572\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4169 - accuracy: 0.8536 - val_loss: 0.4310 - val_accuracy: 0.8534\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3979 - accuracy: 0.8598 - val_loss: 0.4044 - val_accuracy: 0.8588\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3798 - accuracy: 0.8647 - val_loss: 0.3736 - val_accuracy: 0.8692\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3669 - accuracy: 0.8699 - val_loss: 0.3785 - val_accuracy: 0.8630\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3553 - accuracy: 0.8737 - val_loss: 0.3573 - val_accuracy: 0.8784\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3440 - accuracy: 0.8774 - val_loss: 0.3638 - val_accuracy: 0.8686\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3344 - accuracy: 0.8812 - val_loss: 0.3395 - val_accuracy: 0.8776\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3256 - accuracy: 0.8829 - val_loss: 0.3355 - val_accuracy: 0.8810\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3169 - accuracy: 0.8860 - val_loss: 0.3467 - val_accuracy: 0.8742\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3098 - accuracy: 0.8885 - val_loss: 0.3300 - val_accuracy: 0.8800\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3035 - accuracy: 0.8916 - val_loss: 0.3276 - val_accuracy: 0.8818\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2967 - accuracy: 0.8930 - val_loss: 0.3309 - val_accuracy: 0.8780\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2904 - accuracy: 0.8960 - val_loss: 0.3485 - val_accuracy: 0.8740\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.2856 - accuracy: 0.8972 - val_loss: 0.3327 - val_accuracy: 0.8806\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.2799 - accuracy: 0.8990 - val_loss: 0.3192 - val_accuracy: 0.8824\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 24s 14ms/step - loss: 0.2742 - accuracy: 0.9018 - val_loss: 0.3337 - val_accuracy: 0.8784\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.2698 - accuracy: 0.9035 - val_loss: 0.3135 - val_accuracy: 0.8838\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2646 - accuracy: 0.9051 - val_loss: 0.3271 - val_accuracy: 0.8850\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2598 - accuracy: 0.9080 - val_loss: 0.3390 - val_accuracy: 0.8760\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.2558 - accuracy: 0.9076 - val_loss: 0.3180 - val_accuracy: 0.8864\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.2511 - accuracy: 0.9100 - val_loss: 0.3028 - val_accuracy: 0.8890\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.2472 - accuracy: 0.9105 - val_loss: 0.3163 - val_accuracy: 0.8876\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2431 - accuracy: 0.9121 - val_loss: 0.3171 - val_accuracy: 0.8862\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2391 - accuracy: 0.9143 - val_loss: 0.3095 - val_accuracy: 0.8910\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.2350 - accuracy: 0.9151 - val_loss: 0.2987 - val_accuracy: 0.8898\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2305 - accuracy: 0.9181 - val_loss: 0.2944 - val_accuracy: 0.8920\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2274 - accuracy: 0.9186 - val_loss: 0.3056 - val_accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "history_cloned = model_cloned.fit(X_train, y_train, epochs = 30,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History object returned by fit() contains training params(history.params), epochs (history.epcoch), and a dictionary (history.history) containing the loss and extra metrics measured at the end of each epoch. Can use Pandas to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize = (4,3))\n",
    "pd.DataFrame(history_cloned.history).plot(figsize=(4,3))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model was trained more compared with model_cloned. it should perform much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 99.0828 - accuracy: 0.8518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[99.08284759521484, 0.8518000245094299]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_prob = model.predict(X_new)\n",
    "y_prob.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Regression MLP Using the Sequential API\n",
    "- Main differences between building classification and regression:\n",
    "    - Output layer has a single neuron (to predict a single value)\n",
    "    - Uses no activation function\n",
    "    - Loss function is mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.1087 - val_loss: 0.8258\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5665 - val_loss: 0.5096\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4997 - val_loss: 0.4841\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4734 - val_loss: 0.4566\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4576 - val_loss: 0.4478\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4478 - val_loss: 0.4369\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4299\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4354 - val_loss: 0.4262\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4307 - val_loss: 0.4203\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4259 - val_loss: 0.4155\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4207 - val_loss: 0.4102\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4164 - val_loss: 0.4129\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4065\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4031\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4064 - val_loss: 0.3961\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4033 - val_loss: 0.3978\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4006 - val_loss: 0.3967\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3979 - val_loss: 0.3905\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4000 - val_loss: 0.3922\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3938 - val_loss: 0.3921\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3913 - val_loss: 0.3852\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3816\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.3817\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 0.3780\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.3792\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.3807\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3817 - val_loss: 0.3782\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3806 - val_loss: 0.3850\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.3768\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.3769\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3784 - val_loss: 0.3723\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.3683\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.3747\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3680\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3732 - val_loss: 0.3656\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.3703\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3718 - val_loss: 0.3667\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3721 - val_loss: 0.3648\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3703 - val_loss: 0.3653\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3689 - val_loss: 0.3609\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3604\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3674 - val_loss: 0.3631\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.3599\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.3563\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3656 - val_loss: 0.3629\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3640 - val_loss: 0.3546\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3639 - val_loss: 0.3552\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3547\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3627 - val_loss: 0.3528\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3523\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3301\n",
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = \"relu\", \n",
    "    input_shape=X_train_scaled.shape[1:]), keras.layers.Dense(1)   \n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    workers=2)\n",
    "mse_test = model.evaluate(X_test_scaled, y_test)\n",
    "X_new = X_test_scaled[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.15674  ],\n",
       "       [0.7498647],\n",
       "       [3.602102 ]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "hidden3 = keras.layers.Dense(30, activation=\"relu\")(hidden2)\n",
    "concat = keras.layers.Concatenate()([input, hidden3])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Notice how layers are used like functions once they are created. For example: in hidden1, the input layer is passed in to tell the layer where to connect to\n",
    "-Concatenate is used to connect input and hidden2 layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2995 - val_loss: 0.4650\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2985 - val_loss: 0.3288\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2972 - val_loss: 0.3268\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2950 - val_loss: 0.3550\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.3314\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2965 - val_loss: 0.3226\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2925 - val_loss: 0.3987\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2918 - val_loss: 0.3790\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2909 - val_loss: 0.4383\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2900 - val_loss: 0.3962\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2883 - val_loss: 0.4447\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2997 - val_loss: 0.3469\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2887 - val_loss: 0.3451\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.4384\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2937 - val_loss: 0.3666\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2877 - val_loss: 0.4378\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.5843\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.4572\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3002 - val_loss: 0.3750\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.4903\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3009 - val_loss: 0.3846\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2887 - val_loss: 0.3558\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.4689\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.6571\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.4832\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2985 - val_loss: 0.3784\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.3408\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2780 - val_loss: 0.3364\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2789 - val_loss: 0.4838\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2954 - val_loss: 0.3694\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3029\n",
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train_scaled,  y_train, epochs=30,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    workers=2)\n",
    "mse_test = model.evaluate(X_test_scaled, y_test)\n",
    "X_new = X_test_scaled[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to send a subset of the features through one path and a different (possibly overlapping) subset through a deep path. See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_A, X_train_B = X_train_scaled[:, :5], X_train_scaled[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid_scaled[:, :5], X_valid_scaled[:, 2:]\n",
    "X_test_A, X_test_B = X_test_scaled[:, :5], X_test_scaled[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit((X_train_A, X_train_B), y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m      2\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m((X_valid_A, X_valid_B), y_valid),\n\u001b[1;32m      3\u001b[0m                     workers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m mse_test \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate((X_test_A, X_test_B), y_test)\n\u001b[1;32m      5\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict((X_new_A, X_new_B))\n",
      "File \u001b[0;32m~/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/micromamba/envs/robostackenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:956\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    954\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    955\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m--> 956\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    958\u001b[0m   \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid),\n",
    "                    workers=2)\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also want multiple outputs:\n",
    "- Maybe you want to locate and classify the main object in a picture. This is a regression and classification task\n",
    "- May have multiple independent tasks to perform based on teh same data\n",
    "    - Can use same neural network for different tasks due to ability to learn features in data\n",
    "- As a regularization technique (i.e. a training constraint whose objective is to reduce overfitting and thus improve the model's ability to generalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "aux_output = keras.layers.Dense(1)(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output needs its own loss function -> need to pass a list of losses\n",
    "- We care more about the main output's loss  so will give it a much greater weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "363/363 [==============================] - 3s 6ms/step - loss: 0.9710 - dense_99_loss: 0.8329 - dense_100_loss: 2.2137 - val_loss: 0.6113 - val_dense_99_loss: 0.5345 - val_dense_100_loss: 1.3029\n",
      "Epoch 2/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5996 - dense_99_loss: 0.5341 - dense_100_loss: 1.1885 - val_loss: 0.5521 - val_dense_99_loss: 0.4933 - val_dense_100_loss: 1.0808\n",
      "Epoch 3/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5577 - dense_99_loss: 0.5057 - dense_100_loss: 1.0253 - val_loss: 0.5299 - val_dense_99_loss: 0.4820 - val_dense_100_loss: 0.9614\n",
      "Epoch 4/40\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5138 - dense_99_loss: 0.4702 - dense_100_loss: 0.9063 - val_loss: 0.4987 - val_dense_99_loss: 0.4595 - val_dense_100_loss: 0.8519\n",
      "Epoch 5/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4960 - dense_99_loss: 0.4609 - dense_100_loss: 0.8113 - val_loss: 0.4853 - val_dense_99_loss: 0.4530 - val_dense_100_loss: 0.7759\n",
      "Epoch 6/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4822 - dense_99_loss: 0.4519 - dense_100_loss: 0.7556 - val_loss: 0.4770 - val_dense_99_loss: 0.4487 - val_dense_100_loss: 0.7318\n",
      "Epoch 7/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4713 - dense_99_loss: 0.4440 - dense_100_loss: 0.7173 - val_loss: 0.4713 - val_dense_99_loss: 0.4440 - val_dense_100_loss: 0.7170\n",
      "Epoch 8/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4617 - dense_99_loss: 0.4368 - dense_100_loss: 0.6858 - val_loss: 0.4560 - val_dense_99_loss: 0.4311 - val_dense_100_loss: 0.6796\n",
      "Epoch 9/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4595 - dense_99_loss: 0.4369 - dense_100_loss: 0.6627 - val_loss: 0.4554 - val_dense_99_loss: 0.4319 - val_dense_100_loss: 0.6661\n",
      "Epoch 10/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4495 - dense_99_loss: 0.4263 - dense_100_loss: 0.6582 - val_loss: 0.4537 - val_dense_99_loss: 0.4309 - val_dense_100_loss: 0.6589\n",
      "Epoch 11/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4421 - dense_99_loss: 0.4207 - dense_100_loss: 0.6349 - val_loss: 0.4367 - val_dense_99_loss: 0.4144 - val_dense_100_loss: 0.6376\n",
      "Epoch 12/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4347 - dense_99_loss: 0.4137 - dense_100_loss: 0.6233 - val_loss: 0.4323 - val_dense_99_loss: 0.4104 - val_dense_100_loss: 0.6287\n",
      "Epoch 13/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4284 - dense_99_loss: 0.4081 - dense_100_loss: 0.6115 - val_loss: 0.4232 - val_dense_99_loss: 0.4019 - val_dense_100_loss: 0.6147\n",
      "Epoch 14/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4198 - dense_99_loss: 0.3993 - dense_100_loss: 0.6045 - val_loss: 0.4180 - val_dense_99_loss: 0.3973 - val_dense_100_loss: 0.6043\n",
      "Epoch 15/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4147 - dense_99_loss: 0.3951 - dense_100_loss: 0.5914 - val_loss: 0.4179 - val_dense_99_loss: 0.3980 - val_dense_100_loss: 0.5964\n",
      "Epoch 16/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4154 - dense_99_loss: 0.3974 - dense_100_loss: 0.5774 - val_loss: 0.4068 - val_dense_99_loss: 0.3877 - val_dense_100_loss: 0.5791\n",
      "Epoch 17/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4024 - dense_99_loss: 0.3841 - dense_100_loss: 0.5669 - val_loss: 0.4020 - val_dense_99_loss: 0.3832 - val_dense_100_loss: 0.5721\n",
      "Epoch 18/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4035 - dense_99_loss: 0.3865 - dense_100_loss: 0.5569 - val_loss: 0.3954 - val_dense_99_loss: 0.3771 - val_dense_100_loss: 0.5605\n",
      "Epoch 19/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3957 - dense_99_loss: 0.3788 - dense_100_loss: 0.5474 - val_loss: 0.3929 - val_dense_99_loss: 0.3750 - val_dense_100_loss: 0.5535\n",
      "Epoch 20/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3916 - dense_99_loss: 0.3751 - dense_100_loss: 0.5399 - val_loss: 0.3843 - val_dense_99_loss: 0.3665 - val_dense_100_loss: 0.5441\n",
      "Epoch 21/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3872 - dense_99_loss: 0.3715 - dense_100_loss: 0.5291 - val_loss: 0.3806 - val_dense_99_loss: 0.3631 - val_dense_100_loss: 0.5381\n",
      "Epoch 22/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3859 - dense_99_loss: 0.3707 - dense_100_loss: 0.5224 - val_loss: 0.3945 - val_dense_99_loss: 0.3788 - val_dense_100_loss: 0.5357\n",
      "Epoch 23/40\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3753 - dense_99_loss: 0.3601 - dense_100_loss: 0.5119 - val_loss: 0.3822 - val_dense_99_loss: 0.3659 - val_dense_100_loss: 0.5295\n",
      "Epoch 24/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3789 - dense_99_loss: 0.3647 - dense_100_loss: 0.5067 - val_loss: 0.3739 - val_dense_99_loss: 0.3581 - val_dense_100_loss: 0.5167\n",
      "Epoch 25/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3763 - dense_99_loss: 0.3626 - dense_100_loss: 0.4989 - val_loss: 0.3697 - val_dense_99_loss: 0.3545 - val_dense_100_loss: 0.5067\n",
      "Epoch 26/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3640 - dense_99_loss: 0.3500 - dense_100_loss: 0.4896 - val_loss: 0.3652 - val_dense_99_loss: 0.3504 - val_dense_100_loss: 0.4987\n",
      "Epoch 27/40\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3652 - dense_99_loss: 0.3520 - dense_100_loss: 0.4842 - val_loss: 0.3663 - val_dense_99_loss: 0.3523 - val_dense_100_loss: 0.4923\n",
      "Epoch 28/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3639 - dense_99_loss: 0.3509 - dense_100_loss: 0.4802 - val_loss: 0.3667 - val_dense_99_loss: 0.3532 - val_dense_100_loss: 0.4888\n",
      "Epoch 29/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3605 - dense_99_loss: 0.3477 - dense_100_loss: 0.4756 - val_loss: 0.3587 - val_dense_99_loss: 0.3454 - val_dense_100_loss: 0.4781\n",
      "Epoch 30/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3762 - dense_99_loss: 0.3644 - dense_100_loss: 0.4819 - val_loss: 0.3603 - val_dense_99_loss: 0.3461 - val_dense_100_loss: 0.4879\n",
      "Epoch 31/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3645 - dense_99_loss: 0.3533 - dense_100_loss: 0.4660 - val_loss: 0.3668 - val_dense_99_loss: 0.3542 - val_dense_100_loss: 0.4800\n",
      "Epoch 32/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3522 - dense_99_loss: 0.3404 - dense_100_loss: 0.4587 - val_loss: 0.3555 - val_dense_99_loss: 0.3422 - val_dense_100_loss: 0.4757\n",
      "Epoch 33/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3513 - dense_99_loss: 0.3398 - dense_100_loss: 0.4544 - val_loss: 0.3510 - val_dense_99_loss: 0.3386 - val_dense_100_loss: 0.4631\n",
      "Epoch 34/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3541 - dense_99_loss: 0.3436 - dense_100_loss: 0.4493 - val_loss: 0.3502 - val_dense_99_loss: 0.3381 - val_dense_100_loss: 0.4589\n",
      "Epoch 35/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3495 - dense_99_loss: 0.3386 - dense_100_loss: 0.4477 - val_loss: 0.3557 - val_dense_99_loss: 0.3446 - val_dense_100_loss: 0.4558\n",
      "Epoch 36/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3478 - dense_99_loss: 0.3371 - dense_100_loss: 0.4440 - val_loss: 0.3611 - val_dense_99_loss: 0.3501 - val_dense_100_loss: 0.4600\n",
      "Epoch 37/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3535 - dense_99_loss: 0.3430 - dense_100_loss: 0.4485 - val_loss: 0.3551 - val_dense_99_loss: 0.3435 - val_dense_100_loss: 0.4595\n",
      "Epoch 38/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3487 - dense_99_loss: 0.3383 - dense_100_loss: 0.4422 - val_loss: 0.3613 - val_dense_99_loss: 0.3503 - val_dense_100_loss: 0.4609\n",
      "Epoch 39/40\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3443 - dense_99_loss: 0.3342 - dense_100_loss: 0.4349 - val_loss: 0.3604 - val_dense_99_loss: 0.3504 - val_dense_100_loss: 0.4501\n",
      "Epoch 40/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3460 - dense_99_loss: 0.3362 - dense_100_loss: 0.4340 - val_loss: 0.3583 - val_dense_99_loss: 0.3479 - val_dense_100_loss: 0.4522\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "history = model.fit(\n",
    "        [X_train_A, X_train_B], [y_train, y_train], epochs=40,\n",
    "        validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "        workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.3491 - dense_99_loss: 0.3406 - dense_100_loss: 0.4259\n",
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Dynamic Models Using the Subclassing API\n",
    "- Sequential and Functional API are declarative: declare which layers to use and connections -> start feeding model data\n",
    "- Advantages: model can easily be saved, cloned, shared, its structure displayed and analyzed, errors can be caught early, easy to debug\n",
    "- Disadvantages: its static\n",
    "- Using Subclassing API, can add loops, varying shapes, conditional branching and other dynamic behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating this class gives you more flexibility w/ the ability to create for loops, if statements, use low-level TF operations, etc. \\\n",
    "This extra flexibility means your model's architechture is hidden w/in call()\n",
    "- Can only get a list of layers w/out info on how they are connected\n",
    "    - Could probably make a method w/in class to do this\n",
    "- Easier to make mistakes, can't easily save or clone architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model\n",
    "Saving a trained Keras model: <br>\n",
    "<code>\n",
    "model.save(\"my_keras_model.h5\")\n",
    "</code>\n",
    "- Saves both the model's architecture and the value of all model parameters for every layer. It also saves the optimizer\n",
    "- Will typically have a script that trains a model and saves and add'l ones to load model and use it\n",
    "\n",
    "-To load a model: <br>\n",
    "```\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") \n",
    "```\n",
    "- Doesn't work when using Model subclassing\n",
    "    - can use save_weights() and load_weights() to save and restore model parameters\n",
    "- With large training sets that could take hours, need to save at the end and at regular checkpoints\n",
    "    - Use callbacks to tell the fit() method to save\n",
    "\n",
    "## Using Callbacks\n",
    "- fit() method accepts a callbacks argument that can specify a list of objects to be called during the start and end of training and/or during training\n",
    "``` \n",
    "[...] # build and compile the model \n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")  history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "```\n",
    "<br>\n",
    "- If a validation set is used during training, you can set <code> save_best_only=True</code> using ModelCheckpoint\n",
    "    - This helps implement early stopping \n",
    "\n",
    "```\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                    save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to \n",
    "                    best  model\n",
    "```\n",
    "- Can also just use the EarlyStopping callback \n",
    "``` \n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                      restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                validation_data=(X_valid, y_valid),\n",
    "                callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "```\n",
    "Custom callback:\n",
    "```\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback): def on_epoch_end(self, epoch, logs):\n",
    "print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "```\n",
    "<br>\n",
    "- Can change when the callback is implemented with on_train_begin(), on_train_end(), on_epoch_begin()...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Using TensorBoard\n",
    "- must modify your program so that it outputs data to visualize to special binary log files called event files\n",
    "- Each binary record is called a summary\n",
    "    - TensorBoard server will monitor log directory, automatically pick up changes and update visualizations\n",
    "    - Write to different subdirectory every time it runs to compare data between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(11610, 1), dtype=float32, numpy=\n",
       " array([[-3.9380568e-01],\n",
       "        [ 2.3260915e-01],\n",
       "        [-1.2930308e-04],\n",
       "        ...,\n",
       "        [-4.9869254e-01],\n",
       "        [ 2.5163606e-01],\n",
       "        [-2.3401736e-01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(11610, 1), dtype=float32, numpy=\n",
       " array([[-0.11978765],\n",
       "        [-0.16178036],\n",
       "        [ 0.05858804],\n",
       "        ...,\n",
       "        [-0.29009983],\n",
       "        [-0.15356521],\n",
       "        [-0.12667227]], dtype=float32)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call([X_train_A, X_train_B]) #.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 0.5392 - dense_17_loss: 0.4930 - dense_18_loss: 0.9547 - val_loss: 0.5450 - val_dense_17_loss: 0.4973 - val_dense_18_loss: 0.9738\n",
      "Epoch 2/40\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5393 - dense_17_loss: 0.4932 - dense_18_loss: 0.9541 - val_loss: 0.5436 - val_dense_17_loss: 0.4937 - val_dense_18_loss: 0.9928\n",
      "Epoch 3/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5411 - dense_17_loss: 0.4949 - dense_18_loss: 0.9569 - val_loss: 0.5466 - val_dense_17_loss: 0.4985 - val_dense_18_loss: 0.9795\n",
      "Epoch 4/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5382 - dense_17_loss: 0.4924 - dense_18_loss: 0.9501 - val_loss: 0.5419 - val_dense_17_loss: 0.4921 - val_dense_18_loss: 0.9899\n",
      "Epoch 5/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5384 - dense_17_loss: 0.4923 - dense_18_loss: 0.9533 - val_loss: 0.5413 - val_dense_17_loss: 0.4903 - val_dense_18_loss: 1.0004\n",
      "Epoch 6/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5336 - dense_17_loss: 0.4873 - dense_18_loss: 0.9500 - val_loss: 0.5612 - val_dense_17_loss: 0.5138 - val_dense_18_loss: 0.9874\n",
      "Epoch 7/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5306 - dense_17_loss: 0.4843 - dense_18_loss: 0.9467 - val_loss: 0.5414 - val_dense_17_loss: 0.4929 - val_dense_18_loss: 0.9776\n",
      "Epoch 8/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5396 - dense_17_loss: 0.4942 - dense_18_loss: 0.9473 - val_loss: 0.5448 - val_dense_17_loss: 0.4961 - val_dense_18_loss: 0.9833\n",
      "Epoch 9/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5316 - dense_17_loss: 0.4860 - dense_18_loss: 0.9427 - val_loss: 0.5413 - val_dense_17_loss: 0.4931 - val_dense_18_loss: 0.9749\n",
      "Epoch 10/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5324 - dense_17_loss: 0.4867 - dense_18_loss: 0.9432 - val_loss: 0.5476 - val_dense_17_loss: 0.5014 - val_dense_18_loss: 0.9635\n",
      "Epoch 11/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5352 - dense_17_loss: 0.4898 - dense_18_loss: 0.9441 - val_loss: 0.5445 - val_dense_17_loss: 0.4967 - val_dense_18_loss: 0.9743\n",
      "Epoch 12/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5326 - dense_17_loss: 0.4867 - dense_18_loss: 0.9449 - val_loss: 0.5433 - val_dense_17_loss: 0.4951 - val_dense_18_loss: 0.9767\n",
      "Epoch 13/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5370 - dense_17_loss: 0.4919 - dense_18_loss: 0.9436 - val_loss: 0.5392 - val_dense_17_loss: 0.4920 - val_dense_18_loss: 0.9646\n",
      "Epoch 14/40\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5309 - dense_17_loss: 0.4853 - dense_18_loss: 0.9416 - val_loss: 0.5380 - val_dense_17_loss: 0.4897 - val_dense_18_loss: 0.9722\n",
      "Epoch 15/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5307 - dense_17_loss: 0.4852 - dense_18_loss: 0.9404 - val_loss: 0.5365 - val_dense_17_loss: 0.4877 - val_dense_18_loss: 0.9766\n",
      "Epoch 16/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5287 - dense_17_loss: 0.4833 - dense_18_loss: 0.9372 - val_loss: 0.5275 - val_dense_17_loss: 0.4795 - val_dense_18_loss: 0.9596\n",
      "Epoch 17/40\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5401 - dense_17_loss: 0.4961 - dense_18_loss: 0.9365 - val_loss: 0.5506 - val_dense_17_loss: 0.5043 - val_dense_18_loss: 0.9680\n",
      "Epoch 18/40\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5400 - dense_17_loss: 0.4952 - dense_18_loss: 0.9436 - val_loss: 0.5423 - val_dense_17_loss: 0.4967 - val_dense_18_loss: 0.9523\n",
      "Epoch 19/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5334 - dense_17_loss: 0.4889 - dense_18_loss: 0.9337 - val_loss: 0.5548 - val_dense_17_loss: 0.5066 - val_dense_18_loss: 0.9887\n",
      "Epoch 20/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5304 - dense_17_loss: 0.4849 - dense_18_loss: 0.9396 - val_loss: 0.5415 - val_dense_17_loss: 0.4930 - val_dense_18_loss: 0.9780\n",
      "Epoch 21/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5296 - dense_17_loss: 0.4846 - dense_18_loss: 0.9345 - val_loss: 0.5446 - val_dense_17_loss: 0.4944 - val_dense_18_loss: 0.9966\n",
      "Epoch 22/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5371 - dense_17_loss: 0.4928 - dense_18_loss: 0.9350 - val_loss: 0.5400 - val_dense_17_loss: 0.4918 - val_dense_18_loss: 0.9729\n",
      "Epoch 23/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5288 - dense_17_loss: 0.4840 - dense_18_loss: 0.9322 - val_loss: 0.5353 - val_dense_17_loss: 0.4868 - val_dense_18_loss: 0.9720\n",
      "Epoch 24/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5308 - dense_17_loss: 0.4857 - dense_18_loss: 0.9370 - val_loss: 0.5505 - val_dense_17_loss: 0.5034 - val_dense_18_loss: 0.9744\n",
      "Epoch 25/40\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5262 - dense_17_loss: 0.4811 - dense_18_loss: 0.9326 - val_loss: 0.5437 - val_dense_17_loss: 0.4963 - val_dense_18_loss: 0.9703\n",
      "Epoch 26/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5279 - dense_17_loss: 0.4831 - dense_18_loss: 0.9314 - val_loss: 0.5405 - val_dense_17_loss: 0.4950 - val_dense_18_loss: 0.9499\n",
      "Epoch 27/40\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.5291 - dense_17_loss: 0.4848 - dense_18_loss: 0.9279 - val_loss: 0.5431 - val_dense_17_loss: 0.4975 - val_dense_18_loss: 0.9533\n",
      "Epoch 28/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5251 - dense_17_loss: 0.4807 - dense_18_loss: 0.9253 - val_loss: 0.5344 - val_dense_17_loss: 0.4892 - val_dense_18_loss: 0.9416\n",
      "Epoch 29/40\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5196 - dense_17_loss: 0.4767 - dense_18_loss: 0.9055 - val_loss: 0.5312 - val_dense_17_loss: 0.4843 - val_dense_18_loss: 0.9535\n",
      "Epoch 30/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5275 - dense_17_loss: 0.4834 - dense_18_loss: 0.9250 - val_loss: 0.5329 - val_dense_17_loss: 0.4852 - val_dense_18_loss: 0.9620\n",
      "Epoch 31/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5243 - dense_17_loss: 0.4796 - dense_18_loss: 0.9269 - val_loss: 0.5399 - val_dense_17_loss: 0.4940 - val_dense_18_loss: 0.9531\n",
      "Epoch 32/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5250 - dense_17_loss: 0.4808 - dense_18_loss: 0.9225 - val_loss: 0.5350 - val_dense_17_loss: 0.4885 - val_dense_18_loss: 0.9533\n",
      "Epoch 33/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5289 - dense_17_loss: 0.4857 - dense_18_loss: 0.9169 - val_loss: 0.5293 - val_dense_17_loss: 0.4838 - val_dense_18_loss: 0.9384\n",
      "Epoch 34/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5143 - dense_17_loss: 0.4718 - dense_18_loss: 0.8974 - val_loss: 0.5393 - val_dense_17_loss: 0.4951 - val_dense_18_loss: 0.9375\n",
      "Epoch 35/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5167 - dense_17_loss: 0.4750 - dense_18_loss: 0.8919 - val_loss: 0.6204 - val_dense_17_loss: 0.5700 - val_dense_18_loss: 1.0736\n",
      "Epoch 36/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5389 - dense_17_loss: 0.4992 - dense_18_loss: 0.8962 - val_loss: 0.5184 - val_dense_17_loss: 0.4748 - val_dense_18_loss: 0.9108\n",
      "Epoch 37/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5082 - dense_17_loss: 0.4672 - dense_18_loss: 0.8772 - val_loss: 0.5217 - val_dense_17_loss: 0.4788 - val_dense_18_loss: 0.9078\n",
      "Epoch 38/40\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5114 - dense_17_loss: 0.4709 - dense_18_loss: 0.8767 - val_loss: 0.5286 - val_dense_17_loss: 0.4871 - val_dense_18_loss: 0.9020\n",
      "Epoch 39/40\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5075 - dense_17_loss: 0.4668 - dense_18_loss: 0.8737 - val_loss: 0.5326 - val_dense_17_loss: 0.4888 - val_dense_18_loss: 0.9268\n",
      "Epoch 40/40\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5045 - dense_17_loss: 0.4649 - dense_18_loss: 0.8616 - val_loss: 0.5154 - val_dense_17_loss: 0.4743 - val_dense_18_loss: 0.8852\n"
     ]
    }
   ],
   "source": [
    "# [...]  Build and compile your model\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=0.03))\n",
    "history = model.fit(\n",
    "        [X_train_A, X_train_B], [y_train, y_train], epochs=40,\n",
    "        validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "        workers=2, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, this will create TensorBoard event logs. To view TB, make sure you are in the Keras/TF environment and run: <br>\n",
    "<code> $ tensorboard --logdir=./my_logs --port=6006 <br>\n",
    "    TensorBoard 2.0.0 at http://mycomputer.local:6006 (Press CTRL+C to quit)\n",
    "</code> <br>\n",
    "Then open up a web browser to <link> http://localhost:6006 </link>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters\n",
    "- How to know the combo of hyperparameters best for your task?\n",
    "    - Try many combinations: use <italics> GridSearchCV </italics> or <italics> RandomizedSearchCV </italics> to explore hyperparameter space\n",
    "        - need to wrap Keras models in objects to modify params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1,n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to provide reasonable defaults for as many hyperparameters as you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xc/zkw390zs49vd6b73myjws_n40000gn/T/ipykernel_1491/1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.4652 - val_loss: 3.1208\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8345 - val_loss: 0.5960\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5545 - val_loss: 0.5434\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5111 - val_loss: 0.5101\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4859 - val_loss: 0.4899\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4705 - val_loss: 0.4799\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4602 - val_loss: 0.4753\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4524 - val_loss: 0.4646\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4456 - val_loss: 0.4595\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4401 - val_loss: 0.4546\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4357 - val_loss: 0.4549\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4419\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4272 - val_loss: 0.4423\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4238 - val_loss: 0.4403\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.4334\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.4276\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4141 - val_loss: 0.4270\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4114 - val_loss: 0.4253\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4088 - val_loss: 0.4205\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4193\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4185\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4140\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4134\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3987 - val_loss: 0.4144\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3969 - val_loss: 0.4108\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3953 - val_loss: 0.4096\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4083\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.4060\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4056\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3900 - val_loss: 0.4050\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4030\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.4009\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3866 - val_loss: 0.3995\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.4032\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3843 - val_loss: 0.3983\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3833 - val_loss: 0.3953\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3826 - val_loss: 0.3989\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.3947\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.3948\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.3946\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3793 - val_loss: 0.3934\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.3915\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3782 - val_loss: 0.3904\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3772 - val_loss: 0.3938\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3765 - val_loss: 0.3889\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3759 - val_loss: 0.3895\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3754 - val_loss: 0.3866\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3748 - val_loss: 0.3889\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3743 - val_loss: 0.3884\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3738 - val_loss: 0.3864\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3728 - val_loss: 0.3854\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.3841\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3721 - val_loss: 0.3875\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.3858\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.3826\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3703 - val_loss: 0.3807\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3698 - val_loss: 0.3838\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3691 - val_loss: 0.3820\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3683 - val_loss: 0.3799\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3682 - val_loss: 0.3814\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3677 - val_loss: 0.3813\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3681 - val_loss: 0.3799\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3665 - val_loss: 0.3784\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3662 - val_loss: 0.3762\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.3768\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3663 - val_loss: 0.3781\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3650 - val_loss: 0.3805\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.3788\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3645 - val_loss: 0.3746\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3735\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.3743\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.3736\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.3773\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3629 - val_loss: 0.3725\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.3722\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.3709\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.3702\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3715\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.3706\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3688\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3680\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.3701\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.3713\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.3683\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3581 - val_loss: 0.3688\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3674\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3661\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.3668\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.3646\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3556 - val_loss: 0.3692\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3651\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.3670\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3645\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3668\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.3643\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.3648\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3531 - val_loss: 0.3629\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3654\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3534 - val_loss: 0.3611\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3522 - val_loss: 0.3620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179ca16d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train_scaled, y_train, epochs=100,\n",
    "              validation_data=(X_valid_scaled, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
    "              workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3390\n",
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test_scaled, y_test)\n",
    "X_new = X_test_scaled[:3]\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train hundreds of variants and see which on performs best on the validation set. It is preferable to use a randomized search due to the amount of hyperparameters compared with a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 4ms/step - loss: 1.2938 - val_loss: 1.0528\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6776 - val_loss: 0.5892\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5595 - val_loss: 0.5236\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5074 - val_loss: 0.4890\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4726 - val_loss: 0.4756\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4505 - val_loss: 0.4406\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4327 - val_loss: 0.4305\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4162\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4111\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4011 - val_loss: 0.4057\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3943 - val_loss: 0.4004\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3891 - val_loss: 0.3965\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3843 - val_loss: 0.3883\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3810 - val_loss: 0.3847\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3767 - val_loss: 0.3867\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3739 - val_loss: 0.3835\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3710 - val_loss: 0.3791\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3691 - val_loss: 0.3769\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3659 - val_loss: 0.3756\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.3746\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3618 - val_loss: 0.3722\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.3694\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.3703\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.3696\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.3645\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3511 - val_loss: 0.3650\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.3629\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3624\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3625\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3459 - val_loss: 0.3597\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3431 - val_loss: 0.3595\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3417 - val_loss: 0.3583\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.3537\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3390 - val_loss: 0.3540\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3375 - val_loss: 0.3542\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.3576\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3354 - val_loss: 0.3543\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3349 - val_loss: 0.3552\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.3498\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.3516\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3291 - val_loss: 0.3471\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3279 - val_loss: 0.3474\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3269 - val_loss: 0.3486\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3258 - val_loss: 0.3589\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3261 - val_loss: 0.3455\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3237 - val_loss: 0.3443\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3224 - val_loss: 0.3414\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3227 - val_loss: 0.3469\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3206 - val_loss: 0.3418\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3187 - val_loss: 0.3387\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3180 - val_loss: 0.3450\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3169 - val_loss: 0.3394\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3163 - val_loss: 0.3369\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3389\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3343\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3345\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3131 - val_loss: 0.3390\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3124 - val_loss: 0.3350\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3119 - val_loss: 0.3434\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3110 - val_loss: 0.3394\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3102 - val_loss: 0.3390\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3323\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3081 - val_loss: 0.3351\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3080 - val_loss: 0.3328\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3063 - val_loss: 0.3318\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3066 - val_loss: 0.3273\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3336\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3046 - val_loss: 0.3269\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3298\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3025 - val_loss: 0.3344\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3022 - val_loss: 0.3311\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3019 - val_loss: 0.3252\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3003 - val_loss: 0.3307\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3011 - val_loss: 0.3234\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2996 - val_loss: 0.3217\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2986 - val_loss: 0.3250\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2987 - val_loss: 0.3222\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2974 - val_loss: 0.3238\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2988 - val_loss: 0.3230\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2962 - val_loss: 0.3253\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2969 - val_loss: 0.3208\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2955 - val_loss: 0.3205\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2943 - val_loss: 0.3176\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2933 - val_loss: 0.3174\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2941 - val_loss: 0.3311\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2923 - val_loss: 0.3184\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2919 - val_loss: 0.3212\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2922 - val_loss: 0.3224\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2914 - val_loss: 0.3238\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2938 - val_loss: 0.3245\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2920 - val_loss: 0.3200\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2917 - val_loss: 0.3298\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2905 - val_loss: 0.3316\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2919 - val_loss: 0.3421\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3190\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 4ms/step - loss: 1.5997 - val_loss: 0.7808\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6774 - val_loss: 0.5967\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5867 - val_loss: 0.5378\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5366 - val_loss: 0.5024\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5016 - val_loss: 0.4741\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4765 - val_loss: 0.4536\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4584 - val_loss: 0.4373\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4433 - val_loss: 0.4318\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4329 - val_loss: 0.4236\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4106\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4028\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.3962\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4033 - val_loss: 0.3933\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3983 - val_loss: 0.3896\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3940 - val_loss: 0.3852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.3815\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.3796\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3824 - val_loss: 0.3764\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3793 - val_loss: 0.3766\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3764 - val_loss: 0.3722\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.3695\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3702 - val_loss: 0.3728\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3684 - val_loss: 0.3645\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3656 - val_loss: 0.3630\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3640 - val_loss: 0.3617\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3611 - val_loss: 0.3615\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3594 - val_loss: 0.3612\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3584 - val_loss: 0.3593\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3564 - val_loss: 0.3560\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.3572\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.3651\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3518 - val_loss: 0.3589\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3507 - val_loss: 0.3669\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.3539\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3474 - val_loss: 0.3573\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3451 - val_loss: 0.3483\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3437 - val_loss: 0.3569\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3425 - val_loss: 0.3514\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3419 - val_loss: 0.3482\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3390 - val_loss: 0.3628\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3388 - val_loss: 0.3424\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3376 - val_loss: 0.3421\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3350 - val_loss: 0.3412\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3339 - val_loss: 0.3439\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3414\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3311 - val_loss: 0.3414\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3302 - val_loss: 0.3416\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3288 - val_loss: 0.3381\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3279 - val_loss: 0.3450\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3273 - val_loss: 0.3460\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3268 - val_loss: 0.3683\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3255 - val_loss: 0.3378\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3244 - val_loss: 0.3321\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3217 - val_loss: 0.3335\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3230 - val_loss: 0.3314\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3207 - val_loss: 0.3320\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3205 - val_loss: 0.3389\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3189 - val_loss: 0.3375\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3178 - val_loss: 0.3282\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3176 - val_loss: 0.3284\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3162 - val_loss: 0.3292\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3151 - val_loss: 0.3329\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3148 - val_loss: 0.3328\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3151 - val_loss: 0.3283\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3134 - val_loss: 0.3258\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3132 - val_loss: 0.3285\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3127 - val_loss: 0.3294\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3135 - val_loss: 0.3230\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3109 - val_loss: 0.3233\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3107 - val_loss: 0.3336\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3098 - val_loss: 0.3202\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3088 - val_loss: 0.3238\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3082 - val_loss: 0.3215\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3079 - val_loss: 0.3250\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3067 - val_loss: 0.3183\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3062 - val_loss: 0.3194\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3057 - val_loss: 0.3217\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3043 - val_loss: 0.3166\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3040 - val_loss: 0.3213\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3028 - val_loss: 0.3171\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3034 - val_loss: 0.3146\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3018 - val_loss: 0.3170\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3017 - val_loss: 0.3164\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3013 - val_loss: 0.3159\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3002 - val_loss: 0.3243\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3007 - val_loss: 0.3185\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2991 - val_loss: 0.3138\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2995 - val_loss: 0.3126\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2979 - val_loss: 0.3212\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2982 - val_loss: 0.3153\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2978 - val_loss: 0.3137\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2974 - val_loss: 0.3128\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2970 - val_loss: 0.3116\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2955 - val_loss: 0.3160\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2963 - val_loss: 0.3171\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2963 - val_loss: 0.3174\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2968 - val_loss: 0.3122\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2948 - val_loss: 0.3144\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2951 - val_loss: 0.3188\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2941 - val_loss: 0.3102\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2930\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.5743 - val_loss: 1.0137\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6444 - val_loss: 0.6486\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5595 - val_loss: 0.5619\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5166 - val_loss: 0.5230\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4874 - val_loss: 0.5008\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4632 - val_loss: 0.4779\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4438 - val_loss: 0.4610\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4283 - val_loss: 0.4546\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4162 - val_loss: 0.4364\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4048 - val_loss: 0.4273\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3959 - val_loss: 0.4234\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3893 - val_loss: 0.4163\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3829 - val_loss: 0.4146\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3771 - val_loss: 0.4076\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3733 - val_loss: 0.3976\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3696 - val_loss: 0.3984\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3652 - val_loss: 0.3918\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3625 - val_loss: 0.3994\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3596 - val_loss: 0.3854\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3569 - val_loss: 0.3832\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3546 - val_loss: 0.3859\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3521 - val_loss: 0.3789\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.3816\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3474 - val_loss: 0.3752\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3462 - val_loss: 0.3765\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3438 - val_loss: 0.3711\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3431 - val_loss: 0.3701\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3416 - val_loss: 0.3691\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3401 - val_loss: 0.3658\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3388 - val_loss: 0.3672\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3383 - val_loss: 0.3661\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3360 - val_loss: 0.3653\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3346 - val_loss: 0.3626\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3333 - val_loss: 0.3604\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3331 - val_loss: 0.3603\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3320 - val_loss: 0.3604\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3298 - val_loss: 0.3633\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3296 - val_loss: 0.3624\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3285 - val_loss: 0.3558\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3274 - val_loss: 0.3550\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3266 - val_loss: 0.3534\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3259 - val_loss: 0.3514\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3244 - val_loss: 0.3562\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3228 - val_loss: 0.3545\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3219 - val_loss: 0.3531\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3210 - val_loss: 0.3514\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3207 - val_loss: 0.3515\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3195 - val_loss: 0.3493\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3200 - val_loss: 0.3481\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3182 - val_loss: 0.3478\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3169 - val_loss: 0.3497\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3164 - val_loss: 0.3465\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3155 - val_loss: 0.3461\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3142 - val_loss: 0.3506\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3128 - val_loss: 0.3497\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3131 - val_loss: 0.3420\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3115 - val_loss: 0.3402\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3116 - val_loss: 0.3428\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3106 - val_loss: 0.3415\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3097 - val_loss: 0.3411\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3092 - val_loss: 0.3390\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3082 - val_loss: 0.3395\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3073 - val_loss: 0.3389\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3062 - val_loss: 0.3450\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3052 - val_loss: 0.3401\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3050 - val_loss: 0.3359\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3035 - val_loss: 0.3388\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3034 - val_loss: 0.3321\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3022 - val_loss: 0.3349\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3010 - val_loss: 0.3347\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3004 - val_loss: 0.3369\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2998 - val_loss: 0.3329\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2986 - val_loss: 0.3312\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2978 - val_loss: 0.3330\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2979 - val_loss: 0.3313\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2974 - val_loss: 0.3315\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2970 - val_loss: 0.3272\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2950 - val_loss: 0.3270\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2947 - val_loss: 0.3296\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2940 - val_loss: 0.3327\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2930 - val_loss: 0.3284\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2917 - val_loss: 0.3286\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2913 - val_loss: 0.3265\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.3238\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2899 - val_loss: 0.3203\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2893 - val_loss: 0.3218\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2884 - val_loss: 0.3245\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.3222\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.3313\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2862 - val_loss: 0.3274\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2864 - val_loss: 0.3243\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2857 - val_loss: 0.3213\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2853 - val_loss: 0.3215\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2838 - val_loss: 0.3180\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2829 - val_loss: 0.3218\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.3165\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2829 - val_loss: 0.3227\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2814 - val_loss: 0.3240\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2819 - val_loss: 0.3182\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2815 - val_loss: 0.3295\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3412\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 3.0035 - val_loss: 2.4558\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.4044 - val_loss: 1.1191\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9464 - val_loss: 0.8608\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8080 - val_loss: 0.7503\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7417 - val_loss: 0.7034\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7048 - val_loss: 0.6771\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6793 - val_loss: 0.6586\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6594 - val_loss: 0.6432\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6422 - val_loss: 0.6281\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6267 - val_loss: 0.6161\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6132 - val_loss: 0.6037\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6007 - val_loss: 0.5922\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5891 - val_loss: 0.5842\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5788 - val_loss: 0.5752\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5693 - val_loss: 0.5651\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5601 - val_loss: 0.5579\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5517 - val_loss: 0.5493\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5435 - val_loss: 0.5444\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5363 - val_loss: 0.5379\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.5313\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5224 - val_loss: 0.5250\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5161 - val_loss: 0.5196\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5102 - val_loss: 0.5140\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5044 - val_loss: 0.5079\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4989 - val_loss: 0.5035\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4938 - val_loss: 0.4998\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4892 - val_loss: 0.4957\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4845 - val_loss: 0.4924\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4801 - val_loss: 0.4869\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4759 - val_loss: 0.4824\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4719 - val_loss: 0.4783\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4681 - val_loss: 0.4763\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4643 - val_loss: 0.4721\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4611 - val_loss: 0.4703\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4579 - val_loss: 0.4672\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4549 - val_loss: 0.4660\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4522 - val_loss: 0.4611\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4494 - val_loss: 0.4579\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4470 - val_loss: 0.4566\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4445 - val_loss: 0.4541\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4424 - val_loss: 0.4525\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4400 - val_loss: 0.4503\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4384 - val_loss: 0.4488\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4364 - val_loss: 0.4471\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4347 - val_loss: 0.4451\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4329 - val_loss: 0.4437\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4312 - val_loss: 0.4418\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4295 - val_loss: 0.4400\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4283 - val_loss: 0.4387\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4266 - val_loss: 0.4370\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4252 - val_loss: 0.4352\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4238 - val_loss: 0.4347\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4225 - val_loss: 0.4331\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4211 - val_loss: 0.4307\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4197 - val_loss: 0.4300\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4188 - val_loss: 0.4297\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4174 - val_loss: 0.4288\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.4264\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4152 - val_loss: 0.4254\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4140 - val_loss: 0.4240\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4129 - val_loss: 0.4227\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4222\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4107 - val_loss: 0.4205\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4099 - val_loss: 0.4199\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4088 - val_loss: 0.4199\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.4080 - val_loss: 0.4181\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4070 - val_loss: 0.4181\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.4062 - val_loss: 0.4160\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4052 - val_loss: 0.4147\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4045 - val_loss: 0.4144\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4036 - val_loss: 0.4139\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4027 - val_loss: 0.4130\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4020 - val_loss: 0.4123\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4012 - val_loss: 0.4102\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4004 - val_loss: 0.4101\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3997 - val_loss: 0.4092\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3989 - val_loss: 0.4080\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3982 - val_loss: 0.4078\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3977 - val_loss: 0.4069\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3969 - val_loss: 0.4065\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3963 - val_loss: 0.4052\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3956 - val_loss: 0.4048\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3948 - val_loss: 0.4045\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3944 - val_loss: 0.4034\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3936 - val_loss: 0.4030\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3931 - val_loss: 0.4021\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3925 - val_loss: 0.4015\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3919 - val_loss: 0.4011\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3912 - val_loss: 0.4004\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.4002\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3901 - val_loss: 0.3995\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3896 - val_loss: 0.3986\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3890 - val_loss: 0.3981\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3883 - val_loss: 0.3982\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3880 - val_loss: 0.3968\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3873 - val_loss: 0.3964\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3868 - val_loss: 0.3962\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.3954\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3856 - val_loss: 0.3950\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3853 - val_loss: 0.3942\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3897\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 3.5276 - val_loss: 1.6729\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.2053 - val_loss: 1.0974\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9451 - val_loss: 0.9122\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8670 - val_loss: 0.8410\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8245 - val_loss: 0.7992\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7949 - val_loss: 0.7696\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7708 - val_loss: 0.7440\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7498 - val_loss: 0.7258\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7303 - val_loss: 0.7041\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7129 - val_loss: 0.6893\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6960 - val_loss: 0.6733\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6801 - val_loss: 0.6574\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6649 - val_loss: 0.6445\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6504 - val_loss: 0.6301\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6366 - val_loss: 0.6178\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6232 - val_loss: 0.6060\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6103 - val_loss: 0.5935\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.5976 - val_loss: 0.5810\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.5854 - val_loss: 0.5697\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.5738 - val_loss: 0.5598\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.5627 - val_loss: 0.5501\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.5516 - val_loss: 0.5398\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.5416 - val_loss: 0.5320\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5317 - val_loss: 0.5247\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5228 - val_loss: 0.5146\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5145 - val_loss: 0.5089\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5068 - val_loss: 0.5018\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4998 - val_loss: 0.4954\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4934 - val_loss: 0.4902\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4876 - val_loss: 0.4851\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4821 - val_loss: 0.4804\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4774 - val_loss: 0.4774\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4728 - val_loss: 0.4741\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4688 - val_loss: 0.4702\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4649 - val_loss: 0.4677\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4616 - val_loss: 0.4650\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4584 - val_loss: 0.4613\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4553 - val_loss: 0.4591\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4526 - val_loss: 0.4560\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4499 - val_loss: 0.4557\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4478 - val_loss: 0.4525\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4452 - val_loss: 0.4493\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4433 - val_loss: 0.4480\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4410 - val_loss: 0.4459\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4392 - val_loss: 0.4447\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4375 - val_loss: 0.4436\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4357 - val_loss: 0.4412\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4340 - val_loss: 0.4402\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4325 - val_loss: 0.4383\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4309 - val_loss: 0.4362\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4294 - val_loss: 0.4356\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4279 - val_loss: 0.4343\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4264 - val_loss: 0.4346\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4250 - val_loss: 0.4307\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4239 - val_loss: 0.4309\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.4302\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4215 - val_loss: 0.4296\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4204 - val_loss: 0.4283\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4272\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4181 - val_loss: 0.4250\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4233\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.4243\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4148 - val_loss: 0.4215\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4140 - val_loss: 0.4218\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4132 - val_loss: 0.4209\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4121 - val_loss: 0.4204\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4112 - val_loss: 0.4207\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.4104 - val_loss: 0.4188\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4096 - val_loss: 0.4167\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4086 - val_loss: 0.4157\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4079 - val_loss: 0.4153\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4071 - val_loss: 0.4149\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4063 - val_loss: 0.4136\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4137\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.4133\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4039 - val_loss: 0.4140\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4033 - val_loss: 0.4119\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4101\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4103\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4013 - val_loss: 0.4091\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4082\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3999 - val_loss: 0.4067\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3992 - val_loss: 0.4078\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3986 - val_loss: 0.4064\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4055\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4046\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3968 - val_loss: 0.4056\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3962 - val_loss: 0.4038\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4032\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.4022\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4025\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3939 - val_loss: 0.4020\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4011\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3928 - val_loss: 0.4010\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4014\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.3995\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3912 - val_loss: 0.3990\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3908 - val_loss: 0.3995\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3902 - val_loss: 0.3978\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.3970\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3685\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 2.5059 - val_loss: 1.2835\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9274 - val_loss: 0.9954\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7862 - val_loss: 0.8796\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7308 - val_loss: 0.8055\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6935 - val_loss: 0.7537\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6644 - val_loss: 0.7083\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6402 - val_loss: 0.6749\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6189 - val_loss: 0.6468\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6000 - val_loss: 0.6253\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5827 - val_loss: 0.6075\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5670 - val_loss: 0.5907\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5526 - val_loss: 0.5792\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5396 - val_loss: 0.5679\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5583\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5163 - val_loss: 0.5485\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5062 - val_loss: 0.5411\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4969 - val_loss: 0.5349\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4885 - val_loss: 0.5285\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4807 - val_loss: 0.5229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4736 - val_loss: 0.5177\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4672 - val_loss: 0.5132\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4611 - val_loss: 0.5087\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4555 - val_loss: 0.5043\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4506 - val_loss: 0.4991\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4459 - val_loss: 0.4944\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4415 - val_loss: 0.4908\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4376 - val_loss: 0.4885\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4338 - val_loss: 0.4850\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4303 - val_loss: 0.4787\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4271 - val_loss: 0.4757\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4710\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4213 - val_loss: 0.4676\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4644\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.4607\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4575\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4549\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4523\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4496\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4471\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4443\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.4402\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.4382\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4372\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3978 - val_loss: 0.4359\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3963 - val_loss: 0.4316\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4305\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3938 - val_loss: 0.4289\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3925 - val_loss: 0.4267\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3913 - val_loss: 0.4238\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3903 - val_loss: 0.4226\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3891 - val_loss: 0.4206\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3882 - val_loss: 0.4213\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3871 - val_loss: 0.4179\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3862 - val_loss: 0.4163\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3853 - val_loss: 0.4160\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3843 - val_loss: 0.4154\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4135\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3827 - val_loss: 0.4133\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3818 - val_loss: 0.4117\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3811 - val_loss: 0.4110\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 0.4120\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3795 - val_loss: 0.4096\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.4081\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4095\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3772 - val_loss: 0.4061\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3764 - val_loss: 0.4034\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 0.4033\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3753 - val_loss: 0.4044\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3747 - val_loss: 0.4043\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3737 - val_loss: 0.4026\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3735 - val_loss: 0.4011\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3727 - val_loss: 0.3996\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3722 - val_loss: 0.4009\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3717 - val_loss: 0.4014\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3710 - val_loss: 0.3983\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3706 - val_loss: 0.3995\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3700 - val_loss: 0.3992\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3694 - val_loss: 0.3963\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3689 - val_loss: 0.3962\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.3977\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3679 - val_loss: 0.3940\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3674 - val_loss: 0.3967\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3669 - val_loss: 0.3933\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.3664 - val_loss: 0.3953\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.3659 - val_loss: 0.3938\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3655 - val_loss: 0.3926\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3650 - val_loss: 0.3913\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3647 - val_loss: 0.3913\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3642 - val_loss: 0.3901\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3638 - val_loss: 0.3896\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3633 - val_loss: 0.3893\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.3631 - val_loss: 0.3901\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.3626 - val_loss: 0.3901\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3622 - val_loss: 0.3899\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3618 - val_loss: 0.3885\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3890\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3611 - val_loss: 0.3883\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3887\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.3877\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3598 - val_loss: 0.3860\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4072\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 0.8497 - val_loss: 4.7108\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0607 - val_loss: 6.5585\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.0691 - val_loss: 13.0140\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.7479 - val_loss: 0.4545\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.3960\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3740 - val_loss: 0.3839\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3613 - val_loss: 0.3735\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3467 - val_loss: 0.3742\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 4s 16ms/step - loss: 0.3416 - val_loss: 0.3601\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3357 - val_loss: 0.3538\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3319 - val_loss: 0.3583\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3286 - val_loss: 0.3445\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3255 - val_loss: 0.3410\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3202 - val_loss: 0.3357\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3210 - val_loss: 0.3371\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3164 - val_loss: 0.3559\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3155 - val_loss: 0.3314\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3127 - val_loss: 0.3455\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3105 - val_loss: 0.3267\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3066 - val_loss: 0.3327\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3039 - val_loss: 0.3243\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3036 - val_loss: 0.3254\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3025 - val_loss: 0.3239\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3025 - val_loss: 0.3289\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2978 - val_loss: 0.3189\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2973 - val_loss: 0.3297\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2966 - val_loss: 0.3158\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2954 - val_loss: 0.3236\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2961 - val_loss: 0.3171\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2941 - val_loss: 0.3554\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2936 - val_loss: 0.3186\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2903 - val_loss: 0.3235\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2941 - val_loss: 0.3239\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2871 - val_loss: 0.3103\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2882 - val_loss: 0.3080\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.3075\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2865 - val_loss: 0.3067\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.3056\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.3093\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2832 - val_loss: 0.3208\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.3057\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2814 - val_loss: 0.3071\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2806 - val_loss: 0.3152\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2790 - val_loss: 0.3018\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2780 - val_loss: 0.3161\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2760 - val_loss: 0.3290\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2765 - val_loss: 0.3066\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2747 - val_loss: 0.3083\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2741 - val_loss: 0.3167\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2746 - val_loss: 0.3072\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2729 - val_loss: 0.2998\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2731 - val_loss: 0.3005\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2720 - val_loss: 0.3006\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2712 - val_loss: 0.2977\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2715 - val_loss: 0.2975\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2697 - val_loss: 0.2994\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2699 - val_loss: 0.3009\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2689 - val_loss: 0.3164\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2695 - val_loss: 0.3073\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2687 - val_loss: 0.3085\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2663 - val_loss: 0.2975\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2653 - val_loss: 0.2965\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2656 - val_loss: 0.2988\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2663 - val_loss: 0.2922\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2651 - val_loss: 0.2959\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2651 - val_loss: 0.2919\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2623 - val_loss: 0.3032\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2643 - val_loss: 0.2925\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2648 - val_loss: 0.2964\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2641 - val_loss: 0.2954\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2618 - val_loss: 0.2942\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2612 - val_loss: 0.2961\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2597 - val_loss: 0.3141\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2604 - val_loss: 0.2963\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2595 - val_loss: 0.2907\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2587 - val_loss: 0.2943\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2593 - val_loss: 0.2959\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2574 - val_loss: 0.2999\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2587 - val_loss: 0.2983\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2573 - val_loss: 0.3006\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2570 - val_loss: 0.3018\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2563 - val_loss: 0.2958\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2550 - val_loss: 0.2965\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2553 - val_loss: 0.2937\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2548 - val_loss: 0.2987\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.3084\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9060 - val_loss: 1.0888\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6675 - val_loss: 0.5459\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4802 - val_loss: 0.4535\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4393 - val_loss: 0.4251\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4206 - val_loss: 0.4302\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4105 - val_loss: 0.3995\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3964 - val_loss: 0.4158\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3907 - val_loss: 0.3947\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3845 - val_loss: 0.4278\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3877 - val_loss: 0.4891\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4453\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3780 - val_loss: 0.3805\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3698 - val_loss: 0.3675\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3648 - val_loss: 0.3655\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3616 - val_loss: 0.3648\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3593 - val_loss: 0.3591\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3550 - val_loss: 0.3534\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3534 - val_loss: 0.3626\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3499 - val_loss: 0.3544\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3466 - val_loss: 0.3473\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3460 - val_loss: 0.3513\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3424 - val_loss: 0.3479\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3400 - val_loss: 0.3710\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3400 - val_loss: 0.3430\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3357 - val_loss: 0.3473\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3508\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3315 - val_loss: 0.3347\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3314 - val_loss: 0.3299\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.3270 - val_loss: 0.3336\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3262 - val_loss: 0.3264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3235 - val_loss: 0.3307\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3218 - val_loss: 0.3357\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3212 - val_loss: 0.3330\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3190 - val_loss: 0.3242\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3203 - val_loss: 0.3208\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3156 - val_loss: 0.3294\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3145 - val_loss: 0.3165\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3130 - val_loss: 0.3130\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3123 - val_loss: 0.3357\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3118 - val_loss: 0.3267\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3116 - val_loss: 0.3403\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3097 - val_loss: 0.3245\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.3112 - val_loss: 0.3448\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3073 - val_loss: 0.3424\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3056 - val_loss: 0.3555\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3065 - val_loss: 0.3203\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3041 - val_loss: 0.3462\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3038 - val_loss: 0.3269\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2975\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 0.8044 - val_loss: 2.9623\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5312 - val_loss: 0.7006\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4322 - val_loss: 0.4491\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4014 - val_loss: 0.4265\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3889 - val_loss: 0.4219\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3746 - val_loss: 0.3922\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3755 - val_loss: 0.3911\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3697 - val_loss: 0.3820\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.3827\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3770\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3461 - val_loss: 0.3764\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.3687\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3548 - val_loss: 0.3684\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3343 - val_loss: 0.3709\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3314 - val_loss: 0.3626\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3292 - val_loss: 0.3607\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3258 - val_loss: 0.3578\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3550\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3204 - val_loss: 0.3596\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3192 - val_loss: 0.3437\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3202 - val_loss: 0.3481\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3154 - val_loss: 0.3358\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3120 - val_loss: 0.3370\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3129 - val_loss: 0.3391\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3117 - val_loss: 0.3424\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3062 - val_loss: 0.3616\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3066 - val_loss: 0.3487\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3036 - val_loss: 0.3441\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3022 - val_loss: 0.3377\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3018 - val_loss: 0.3290\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2998 - val_loss: 0.3272\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3034 - val_loss: 0.3330\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2966 - val_loss: 0.3328\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2965 - val_loss: 0.3249\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2932 - val_loss: 0.3268\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.3223\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2925 - val_loss: 0.3115\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.3376\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2963 - val_loss: 0.3157\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2892 - val_loss: 0.3436\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2897 - val_loss: 0.3139\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2861 - val_loss: 0.3146\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2864 - val_loss: 0.3133\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2840 - val_loss: 0.3091\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2836 - val_loss: 0.3363\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2882 - val_loss: 0.3189\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.3039\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.3294\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2835 - val_loss: 0.3031\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2793 - val_loss: 0.3056\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2787 - val_loss: 0.3996\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3321 - val_loss: 0.3627\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3137 - val_loss: 0.5134\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3383 - val_loss: 0.3859\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.3338\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2802 - val_loss: 0.3504\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2796 - val_loss: 0.3228\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2778 - val_loss: 0.3326\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2770 - val_loss: 0.3166\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3316\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.6741 - val_loss: 0.9769\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6661 - val_loss: 0.7261\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5622 - val_loss: 0.5511\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5002 - val_loss: 0.4696\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4586 - val_loss: 0.4373\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4303 - val_loss: 0.4270\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4084\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4014 - val_loss: 0.3976\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3939 - val_loss: 0.3904\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3886 - val_loss: 0.3903\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3825 - val_loss: 0.3808\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3791 - val_loss: 0.3775\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3732 - val_loss: 0.3773\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3697 - val_loss: 0.3722\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.3725\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3634 - val_loss: 0.3692\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3605 - val_loss: 0.3685\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.3646\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3556 - val_loss: 0.3661\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.3570\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.3570\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3480 - val_loss: 0.3582\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.3548\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3439 - val_loss: 0.3526\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3421 - val_loss: 0.3508\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3407 - val_loss: 0.3504\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3375 - val_loss: 0.3462\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3357 - val_loss: 0.3447\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3349 - val_loss: 0.3435\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3326 - val_loss: 0.3451\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3474\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3297 - val_loss: 0.3402\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3281 - val_loss: 0.3386\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3280 - val_loss: 0.3375\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3252 - val_loss: 0.3409\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3245 - val_loss: 0.3349\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3350\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3210 - val_loss: 0.3341\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3207 - val_loss: 0.3350\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3193 - val_loss: 0.3398\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3184 - val_loss: 0.3330\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3169 - val_loss: 0.3288\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3160 - val_loss: 0.3302\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3147 - val_loss: 0.3308\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3133 - val_loss: 0.3306\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3318\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3109 - val_loss: 0.3305\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3099 - val_loss: 0.3317\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3101 - val_loss: 0.3321\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3092 - val_loss: 0.3332\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3077 - val_loss: 0.3295\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3062 - val_loss: 0.3304\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3313\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 4ms/step - loss: 1.6638 - val_loss: 0.7030\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6386 - val_loss: 0.6503\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5635 - val_loss: 0.8264\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5676 - val_loss: 0.7707\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5020 - val_loss: 0.5815\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4699 - val_loss: 0.4874\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4368 - val_loss: 0.4434\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4202 - val_loss: 0.4075\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4070 - val_loss: 0.3980\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3980 - val_loss: 0.3889\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3911 - val_loss: 0.3862\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3836 - val_loss: 0.3922\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3792 - val_loss: 0.3756\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3747 - val_loss: 0.3710\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3708 - val_loss: 0.3713\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3689 - val_loss: 0.3729\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3652 - val_loss: 0.3686\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3625 - val_loss: 0.3730\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.3641\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3573 - val_loss: 0.3727\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3567 - val_loss: 0.3579\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.3589\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3521 - val_loss: 0.3552\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3504 - val_loss: 0.3642\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3476 - val_loss: 0.3548\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3459 - val_loss: 0.3544\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3462 - val_loss: 0.3916\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3518\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3428 - val_loss: 0.3538\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3393 - val_loss: 0.3502\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3385 - val_loss: 0.3457\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3380 - val_loss: 0.3638\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.3571\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3377 - val_loss: 0.4222\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3365 - val_loss: 0.3708\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3363 - val_loss: 0.4151\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3389 - val_loss: 0.3850\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3945\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3348 - val_loss: 0.3658\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3319 - val_loss: 0.3841\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3285 - val_loss: 0.3494\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3240\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.2601 - val_loss: 1.1017\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6125 - val_loss: 0.5793\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5237 - val_loss: 0.5140\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4742 - val_loss: 0.5047\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4443 - val_loss: 0.4571\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4205 - val_loss: 0.4453\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4042 - val_loss: 0.4388\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3926 - val_loss: 0.4133\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3827 - val_loss: 0.4039\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3757 - val_loss: 0.4015\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.4074\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3637 - val_loss: 0.3932\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.3871\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3542 - val_loss: 0.3789\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3503 - val_loss: 0.3915\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3460 - val_loss: 0.3754\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3432 - val_loss: 0.3874\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3403 - val_loss: 0.3933\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3375 - val_loss: 0.3797\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3346 - val_loss: 0.3787\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3715\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3295 - val_loss: 0.3637\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3275 - val_loss: 0.3645\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3251 - val_loss: 0.3679\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3239 - val_loss: 0.3675\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3202 - val_loss: 0.3510\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3186 - val_loss: 0.3460\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3165 - val_loss: 0.3495\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3158 - val_loss: 0.3554\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3147 - val_loss: 0.3585\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3131 - val_loss: 0.3571\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3112 - val_loss: 0.3491\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.3606\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3086 - val_loss: 0.3374\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3073 - val_loss: 0.3503\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3068 - val_loss: 0.3530\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3053 - val_loss: 0.3331\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3019 - val_loss: 0.3358\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3017 - val_loss: 0.3407\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3014 - val_loss: 0.3361\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3000 - val_loss: 0.3341\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2991 - val_loss: 0.3303\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2979 - val_loss: 0.3845\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2966 - val_loss: 0.3275\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.3324\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.3294\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2944 - val_loss: 0.3305\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2940 - val_loss: 0.3217\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2927 - val_loss: 0.3275\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.3226\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2913 - val_loss: 0.3270\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2901 - val_loss: 0.3229\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.3714\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2887 - val_loss: 0.3128\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2874 - val_loss: 0.3192\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2878 - val_loss: 0.3162\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2857 - val_loss: 0.3183\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2849 - val_loss: 0.3156\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2844 - val_loss: 0.3185\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2836 - val_loss: 0.3087\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2838 - val_loss: 0.3173\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.2825 - val_loss: 0.3134\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2818 - val_loss: 0.3201\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2812 - val_loss: 0.3108\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2805 - val_loss: 0.3128\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2794 - val_loss: 0.3057\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2785 - val_loss: 0.3188\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2780 - val_loss: 0.3180\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2763 - val_loss: 0.3119\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2768 - val_loss: 0.3182\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2766 - val_loss: 0.3083\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2753 - val_loss: 0.3098\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2758 - val_loss: 0.3076\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2743 - val_loss: 0.3092\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2738 - val_loss: 0.3203\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2731 - val_loss: 0.3118\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3290\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.3237 - val_loss: 17.9109\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.0948 - val_loss: 0.5243\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4882 - val_loss: 0.4633\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4470 - val_loss: 0.4419\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4224\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.4177\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4061\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4026\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3917 - val_loss: 0.3987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.4000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.3921\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3816 - val_loss: 0.3894\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.3876\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3790 - val_loss: 0.3972\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3757 - val_loss: 0.3833\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3738 - val_loss: 0.3799\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.3797\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3777 - val_loss: 0.3842\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.3929\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3699 - val_loss: 0.3780\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.3747\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3651 - val_loss: 0.3714\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3646 - val_loss: 0.3723\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.3737\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3604 - val_loss: 0.3761\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.3681\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.3709\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3573 - val_loss: 0.3664\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.3659\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.3684\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3566 - val_loss: 0.3660\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3572 - val_loss: 0.3648\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3521 - val_loss: 0.3698\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3540 - val_loss: 0.3643\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.3627\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3530 - val_loss: 0.3682\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.3670\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3529 - val_loss: 0.3655\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3499 - val_loss: 0.3606\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3621\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3481 - val_loss: 0.3664\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3461 - val_loss: 0.3646\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3469 - val_loss: 0.3606\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3453 - val_loss: 0.3604\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3440 - val_loss: 0.3595\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.3581\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3440 - val_loss: 0.3648\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.3609\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3575\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3402 - val_loss: 0.3576\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3540\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3399 - val_loss: 0.3595\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.3533\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3394 - val_loss: 0.3532\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3509\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.4015\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3477 - val_loss: 0.3536\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3518\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3379 - val_loss: 0.3623\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3378 - val_loss: 0.3556\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3361 - val_loss: 0.3506\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3351 - val_loss: 0.3483\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3337 - val_loss: 0.3558\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.3332 - val_loss: 0.3497\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.3328 - val_loss: 0.3490\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.3351 - val_loss: 0.3570\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3334 - val_loss: 0.3496\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3316 - val_loss: 0.3543\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3301 - val_loss: 0.3450\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3300 - val_loss: 0.3497\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3897 - val_loss: 0.3862\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3483 - val_loss: 0.3646\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.3813 - val_loss: 0.3620\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3439 - val_loss: 0.3582\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3830 - val_loss: 0.3739\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3493 - val_loss: 0.4178\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3498 - val_loss: 0.3562\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3367 - val_loss: 0.3519\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3338 - val_loss: 0.3554\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3532\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9394 - val_loss: 8.2058\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7125 - val_loss: 0.5391\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4924 - val_loss: 0.5021\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4572 - val_loss: 0.5218\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4421 - val_loss: 0.4350\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4281 - val_loss: 0.4277\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4193 - val_loss: 0.4162\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4137 - val_loss: 0.4102\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4065 - val_loss: 0.4020\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.3957\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.3951\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3967 - val_loss: 0.4032\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3949 - val_loss: 0.4001\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3917 - val_loss: 0.4113\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3886 - val_loss: 0.4123\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3895 - val_loss: 0.3880\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.3812\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3815 - val_loss: 0.3837\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3807 - val_loss: 0.3988\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3773 - val_loss: 0.3838\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3762 - val_loss: 0.3774\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3756 - val_loss: 0.3873\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3737 - val_loss: 0.4031\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3726 - val_loss: 0.3719\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.3780\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3682 - val_loss: 0.3776\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3681 - val_loss: 0.3732\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3676 - val_loss: 0.3673\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3647 - val_loss: 0.3711\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.3698\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3631 - val_loss: 0.3634\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3631 - val_loss: 0.3730\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3606 - val_loss: 0.3865\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.3920\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3632 - val_loss: 0.3721\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3672\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3564 - val_loss: 0.3975\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3558 - val_loss: 0.3768\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3600 - val_loss: 0.3903\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.3551\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3513 - val_loss: 0.3756\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3534 - val_loss: 0.3798\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3574 - val_loss: 0.3820\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.3788\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.4033\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3520 - val_loss: 0.4071\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.4153\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3474 - val_loss: 0.3470\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3426 - val_loss: 0.3514\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3431 - val_loss: 0.3454\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.3476\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3406 - val_loss: 0.3552\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.3524\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.3630\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.3499\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3409 - val_loss: 0.3399\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.3424\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3386 - val_loss: 0.4742\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.3540\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3371 - val_loss: 0.3529\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3595\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3354 - val_loss: 0.3466\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3438\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3352 - val_loss: 0.3356\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3335 - val_loss: 0.3440\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3326 - val_loss: 0.3777\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3328 - val_loss: 0.3464\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3328 - val_loss: 0.3418\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3325 - val_loss: 0.3541\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3314 - val_loss: 0.3544\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3311 - val_loss: 0.3646\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3324 - val_loss: 0.3757\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3438\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3326 - val_loss: 0.3491\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3155\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.1256 - val_loss: 0.6913\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5242 - val_loss: 0.6721\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4759 - val_loss: 0.6173\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4515 - val_loss: 0.6314\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4313 - val_loss: 0.4640\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4487\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4142 - val_loss: 0.4274\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4678\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3933 - val_loss: 0.4354\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.4274\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3810 - val_loss: 0.4011\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3778 - val_loss: 0.3961\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3756 - val_loss: 0.8502\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4224 - val_loss: 0.4072\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3727 - val_loss: 0.3987\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3680 - val_loss: 0.3947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.3907\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.3938\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3626 - val_loss: 0.4152\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3576 - val_loss: 0.3858\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3868\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3529 - val_loss: 0.3811\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3780\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3643 - val_loss: 0.3794\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.3744\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3490 - val_loss: 0.3800\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.3702\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.3760\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3672\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3464 - val_loss: 0.3863\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3663\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3610\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3388 - val_loss: 0.3704\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3603\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3932\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3359 - val_loss: 0.3681\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3672\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3582\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3425 - val_loss: 0.3585\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3585\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3315 - val_loss: 0.3591\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3308 - val_loss: 0.3675\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3289 - val_loss: 0.3521\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3275 - val_loss: 0.3551\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3283 - val_loss: 0.3514\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3268 - val_loss: 0.3605\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.6182\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3392 - val_loss: 0.3491\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3250 - val_loss: 0.3564\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3343 - val_loss: 0.4942\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3281 - val_loss: 0.3453\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3300 - val_loss: 0.3642\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3231 - val_loss: 0.3490\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3492\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3193 - val_loss: 0.3552\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3178 - val_loss: 0.3438\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3195 - val_loss: 0.3408\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3164 - val_loss: 0.3842\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3199 - val_loss: 0.3441\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3733\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 0.3425\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3287 - val_loss: 0.8523\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3271 - val_loss: 0.3404\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3185 - val_loss: 0.3913\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3128 - val_loss: 0.3479\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3136 - val_loss: 0.4181\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3148 - val_loss: 0.3417\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.4264\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3245 - val_loss: 0.3343\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3109 - val_loss: 0.4164\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3135 - val_loss: 0.3521\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3122 - val_loss: 0.3682\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3273 - val_loss: 0.3385\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3399\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3468\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3149 - val_loss: 0.3324\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3095 - val_loss: 0.3465\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3073 - val_loss: 0.3366\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3796\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3131 - val_loss: 0.4062\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3084 - val_loss: 0.4223\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3066 - val_loss: 0.3397\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3140 - val_loss: 0.3878\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3149 - val_loss: 0.4741\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3129 - val_loss: 0.4699\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.4285\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3716\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 3.1735 - val_loss: 2.1513\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4021 - val_loss: 1.0867\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9732 - val_loss: 0.8718\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8355 - val_loss: 0.7867\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7675 - val_loss: 0.7359\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7252 - val_loss: 0.7053\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6941 - val_loss: 0.6808\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6702 - val_loss: 0.6603\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6498 - val_loss: 0.6418\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6306 - val_loss: 0.6265\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6161 - val_loss: 0.6112\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6023 - val_loss: 0.5975\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5893 - val_loss: 0.5855\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5791 - val_loss: 0.5794\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5685 - val_loss: 0.5661\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5594 - val_loss: 0.5586\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5509 - val_loss: 0.5504\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5437 - val_loss: 0.5468\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5362 - val_loss: 0.5396\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5298 - val_loss: 0.5306\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5238 - val_loss: 0.5270\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5182 - val_loss: 0.5198\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5141 - val_loss: 0.5174\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5088 - val_loss: 0.5124\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5046 - val_loss: 0.5073\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 0.5043\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4966 - val_loss: 0.4999\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4941 - val_loss: 0.4996\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4903 - val_loss: 0.4940\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4874 - val_loss: 0.4930\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4843 - val_loss: 0.4885\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4820 - val_loss: 0.4846\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4796 - val_loss: 0.4852\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4770 - val_loss: 0.4818\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4746 - val_loss: 0.4787\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4726 - val_loss: 0.4755\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4707 - val_loss: 0.4760\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4685 - val_loss: 0.4740\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4664 - val_loss: 0.4710\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4649 - val_loss: 0.4687\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4630 - val_loss: 0.4677\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4616 - val_loss: 0.4697\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4598 - val_loss: 0.4654\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4583 - val_loss: 0.4643\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4563 - val_loss: 0.4613\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4556 - val_loss: 0.4606\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4536 - val_loss: 0.4592\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4526 - val_loss: 0.4574\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4506 - val_loss: 0.4556\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4500 - val_loss: 0.4565\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4481 - val_loss: 0.4534\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4474 - val_loss: 0.4548\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4458 - val_loss: 0.4509\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4447 - val_loss: 0.4499\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4434 - val_loss: 0.4484\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4422 - val_loss: 0.4484\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4409 - val_loss: 0.4453\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4398 - val_loss: 0.4458\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4388 - val_loss: 0.4440\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4377 - val_loss: 0.4424\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4366 - val_loss: 0.4420\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4355 - val_loss: 0.4409\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4347 - val_loss: 0.4408\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4335 - val_loss: 0.4397\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4325 - val_loss: 0.4377\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4314 - val_loss: 0.4379\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4304 - val_loss: 0.4378\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4295 - val_loss: 0.4348\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4286 - val_loss: 0.4341\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4275 - val_loss: 0.4335\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4265 - val_loss: 0.4317\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4257 - val_loss: 0.4317\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4248 - val_loss: 0.4303\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4239 - val_loss: 0.4299\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.4284\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4221 - val_loss: 0.4280\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4279\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.4278\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4196 - val_loss: 0.4256\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4242\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4180 - val_loss: 0.4240\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4172 - val_loss: 0.4244\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4164 - val_loss: 0.4226\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4157 - val_loss: 0.4222\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4224\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4209\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4134 - val_loss: 0.4205\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4210\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4182\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4112 - val_loss: 0.4181\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4172\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4165\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4091 - val_loss: 0.4167\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4085 - val_loss: 0.4154\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4144\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4071 - val_loss: 0.4140\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4129\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4130\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4119\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4116\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4026\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 3.5713 - val_loss: 2.0584\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1890 - val_loss: 0.9288\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8141 - val_loss: 0.7412\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7353 - val_loss: 0.6970\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7008 - val_loss: 0.6718\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6756 - val_loss: 0.6483\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6535 - val_loss: 0.6301\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6342 - val_loss: 0.6127\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6173 - val_loss: 0.5979\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6020 - val_loss: 0.5846\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5882 - val_loss: 0.5718\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5758 - val_loss: 0.5601\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5645 - val_loss: 0.5511\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5543 - val_loss: 0.5421\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5451 - val_loss: 0.5341\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5369 - val_loss: 0.5275\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5296 - val_loss: 0.5203\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5224 - val_loss: 0.5152\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5163 - val_loss: 0.5099\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5107 - val_loss: 0.5044\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5051 - val_loss: 0.5009\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5004 - val_loss: 0.4973\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4958 - val_loss: 0.4932\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4916 - val_loss: 0.4887\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4879 - val_loss: 0.4861\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4843 - val_loss: 0.4830\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4809 - val_loss: 0.4796\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4778 - val_loss: 0.4780\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4749 - val_loss: 0.4744\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4723 - val_loss: 0.4720\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4696 - val_loss: 0.4706\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4673 - val_loss: 0.4683\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4649 - val_loss: 0.4655\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4629 - val_loss: 0.4643\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4609 - val_loss: 0.4625\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4585 - val_loss: 0.4600\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4570 - val_loss: 0.4602\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4552 - val_loss: 0.4576\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4534 - val_loss: 0.4559\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4517 - val_loss: 0.4546\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4499 - val_loss: 0.4543\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4484 - val_loss: 0.4513\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.4504\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4453 - val_loss: 0.4490\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4439 - val_loss: 0.4481\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4426 - val_loss: 0.4469\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4411 - val_loss: 0.4453\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4398 - val_loss: 0.4449\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4385 - val_loss: 0.4441\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4373 - val_loss: 0.4414\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4361 - val_loss: 0.4399\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4349 - val_loss: 0.4395\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4336 - val_loss: 0.4377\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4327 - val_loss: 0.4377\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4316 - val_loss: 0.4374\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4305 - val_loss: 0.4368\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4294 - val_loss: 0.4365\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4285 - val_loss: 0.4340\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4275 - val_loss: 0.4338\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4264 - val_loss: 0.4329\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4255 - val_loss: 0.4306\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4246 - val_loss: 0.4312\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4297\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4229 - val_loss: 0.4284\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4220 - val_loss: 0.4288\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4286\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4204 - val_loss: 0.4267\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4272\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4259\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4180 - val_loss: 0.4255\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4173 - val_loss: 0.4246\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4166 - val_loss: 0.4234\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4234\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4223\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4226\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4216\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4202\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4123 - val_loss: 0.4212\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4190\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.4194\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4105 - val_loss: 0.4182\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4098 - val_loss: 0.4188\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4093 - val_loss: 0.4175\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4087 - val_loss: 0.4170\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4171\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4076 - val_loss: 0.4163\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4148\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4150\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4147\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4131\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.4123\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4042 - val_loss: 0.4128\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4037 - val_loss: 0.4121\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4031 - val_loss: 0.4122\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4027 - val_loss: 0.4116\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4112\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4012 - val_loss: 0.4087\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.4011 - val_loss: 0.4095\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4005 - val_loss: 0.4084\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3999 - val_loss: 0.4090\n",
      "121/121 [==============================] - 1s 10ms/step - loss: 0.3770\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 3.4194 - val_loss: 2.3076\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1598 - val_loss: 1.6532\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8215 - val_loss: 1.2460\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7247 - val_loss: 1.0088\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6850 - val_loss: 0.8586\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6603 - val_loss: 0.7644\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6417 - val_loss: 0.7062\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.6257 - val_loss: 0.6662\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.6116 - val_loss: 0.6389\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5989 - val_loss: 0.6200\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5870 - val_loss: 0.6075\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5764 - val_loss: 0.5947\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5663 - val_loss: 0.5888\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5572 - val_loss: 0.5796\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5487 - val_loss: 0.5763\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5406 - val_loss: 0.5684\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5332 - val_loss: 0.5644\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5262 - val_loss: 0.5604\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5197 - val_loss: 0.5591\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5135 - val_loss: 0.5527\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5077 - val_loss: 0.5504\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5024 - val_loss: 0.5464\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4973 - val_loss: 0.5435\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4926 - val_loss: 0.5394\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4882 - val_loss: 0.5363\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4841 - val_loss: 0.5331\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4802 - val_loss: 0.5305\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4766 - val_loss: 0.5274\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4732 - val_loss: 0.5247\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4700 - val_loss: 0.5216\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4671 - val_loss: 0.5170\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4641 - val_loss: 0.5145\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4615 - val_loss: 0.5116\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4588 - val_loss: 0.5096\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4564 - val_loss: 0.5066\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4539 - val_loss: 0.5003\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4520 - val_loss: 0.4993\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4497 - val_loss: 0.4987\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4477 - val_loss: 0.4941\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4458 - val_loss: 0.4915\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4439 - val_loss: 0.4897\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4422 - val_loss: 0.4871\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4405 - val_loss: 0.4855\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4389 - val_loss: 0.4840\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4373 - val_loss: 0.4810\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4358 - val_loss: 0.4832\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4342 - val_loss: 0.4785\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4330 - val_loss: 0.4762\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4315 - val_loss: 0.4749\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4302 - val_loss: 0.4729\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4290 - val_loss: 0.4718\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4276 - val_loss: 0.4724\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4265 - val_loss: 0.4700\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4252 - val_loss: 0.4683\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4242 - val_loss: 0.4684\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4228 - val_loss: 0.4649\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4220 - val_loss: 0.4640\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4207 - val_loss: 0.4621\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.4198 - val_loss: 0.4644\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4185 - val_loss: 0.4591\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.4178 - val_loss: 0.4590\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4167 - val_loss: 0.4568\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4157 - val_loss: 0.4567\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4148 - val_loss: 0.4543\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4139 - val_loss: 0.4536\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4129 - val_loss: 0.4518\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4121 - val_loss: 0.4558\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.4516\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4102 - val_loss: 0.4480\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4096 - val_loss: 0.4504\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4086 - val_loss: 0.4494\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4076 - val_loss: 0.4452\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4071 - val_loss: 0.4491\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 4s 16ms/step - loss: 0.4062 - val_loss: 0.4474\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.4053 - val_loss: 0.4428\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4047 - val_loss: 0.4465\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4040 - val_loss: 0.4444\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4031 - val_loss: 0.4419\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4023 - val_loss: 0.4397\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4016 - val_loss: 0.4396\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4010 - val_loss: 0.4386\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.4001 - val_loss: 0.4380\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3994 - val_loss: 0.4373\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3987 - val_loss: 0.4401\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3980 - val_loss: 0.4357\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 4s 16ms/step - loss: 0.3973 - val_loss: 0.4369\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.3966 - val_loss: 0.4370\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3958 - val_loss: 0.4314\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 5s 18ms/step - loss: 0.3953 - val_loss: 0.4326\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.3946 - val_loss: 0.4325\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3939 - val_loss: 0.4292\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.3933 - val_loss: 0.4309\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3924 - val_loss: 0.4268\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3921 - val_loss: 0.4283\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3912 - val_loss: 0.4278\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 5s 19ms/step - loss: 0.3906 - val_loss: 0.4323\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3898 - val_loss: 0.4230\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.3896 - val_loss: 0.4263\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3887 - val_loss: 0.4221\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3884 - val_loss: 0.4229\n",
      "121/121 [==============================] - 1s 6ms/step - loss: 0.4431\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.8020 - val_loss: 0.8706\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7524 - val_loss: 0.8230\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6881 - val_loss: 0.9299\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6763 - val_loss: 1.0676\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.6390 - val_loss: 0.9610\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.6208 - val_loss: 0.8361\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5710 - val_loss: 0.6447\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5416 - val_loss: 0.5455\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5088 - val_loss: 0.5035\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4939 - val_loss: 0.4870\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4822 - val_loss: 0.4793\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4716 - val_loss: 0.4834\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4664 - val_loss: 0.4705\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4572 - val_loss: 0.4619\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4531 - val_loss: 0.4624\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4472 - val_loss: 0.4650\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4440 - val_loss: 0.4457\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4397 - val_loss: 0.4449\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4365 - val_loss: 0.4405\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4348 - val_loss: 0.4392\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4307 - val_loss: 0.4554\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4288 - val_loss: 0.4299\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4261 - val_loss: 0.4334\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4226 - val_loss: 0.4278\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4197 - val_loss: 0.4350\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4188 - val_loss: 0.4240\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4159 - val_loss: 0.4217\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4140 - val_loss: 0.4175\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4137 - val_loss: 0.4206\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4102 - val_loss: 0.4199\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4089 - val_loss: 0.4168\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4073 - val_loss: 0.4129\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4059 - val_loss: 0.4131\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4048 - val_loss: 0.4111\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4030 - val_loss: 0.4191\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4023 - val_loss: 0.4099\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3997 - val_loss: 0.4050\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3986 - val_loss: 0.4150\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3975 - val_loss: 0.4023\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3961 - val_loss: 0.4010\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3948 - val_loss: 0.4009\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3933 - val_loss: 0.3983\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3928 - val_loss: 0.3992\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3913 - val_loss: 0.3976\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3899 - val_loss: 0.3972\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3890 - val_loss: 0.3971\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3889 - val_loss: 0.3956\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3873 - val_loss: 0.3980\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3865 - val_loss: 0.3948\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3859 - val_loss: 0.3963\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3848 - val_loss: 0.3927\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3833 - val_loss: 0.3949\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3830 - val_loss: 0.3907\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3823 - val_loss: 0.3892\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3816 - val_loss: 0.3883\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3806 - val_loss: 0.3867\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3796 - val_loss: 0.3879\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3794 - val_loss: 0.3872\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3787 - val_loss: 0.3854\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3773 - val_loss: 0.3855\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3764 - val_loss: 0.3856\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3758 - val_loss: 0.3861\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3753 - val_loss: 0.3842\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3747 - val_loss: 0.3823\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3741 - val_loss: 0.3826\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3732 - val_loss: 0.3818\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.3819\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3718 - val_loss: 0.3820\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3715 - val_loss: 0.3810\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3705 - val_loss: 0.3801\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3699 - val_loss: 0.3794\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3691 - val_loss: 0.3797\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3687 - val_loss: 0.3778\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3683 - val_loss: 0.3807\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3687 - val_loss: 0.3798\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3676 - val_loss: 0.3781\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3670 - val_loss: 0.3761\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3663 - val_loss: 0.3805\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3655 - val_loss: 0.3754\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3654 - val_loss: 0.3759\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3646 - val_loss: 0.3749\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3644 - val_loss: 0.3743\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3639 - val_loss: 0.3760\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3637 - val_loss: 0.3738\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3630 - val_loss: 0.3766\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3627 - val_loss: 0.3743\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3627 - val_loss: 0.3736\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3621 - val_loss: 0.3720\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3617 - val_loss: 0.3761\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3615 - val_loss: 0.3727\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3611 - val_loss: 0.3734\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3609 - val_loss: 0.3739\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3608 - val_loss: 0.3736\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3598 - val_loss: 0.3731\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3599 - val_loss: 0.3761\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3592 - val_loss: 0.3736\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3597 - val_loss: 0.3816\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3596 - val_loss: 0.3895\n",
      "121/121 [==============================] - 1s 6ms/step - loss: 0.3639\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 7s 9ms/step - loss: 2.0073 - val_loss: 2.2791\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8359 - val_loss: 1.0235\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.6905 - val_loss: 0.6735\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 4s 19ms/step - loss: 0.6275 - val_loss: 0.6020\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.5940 - val_loss: 0.5721\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.5698 - val_loss: 0.5579\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.5504 - val_loss: 0.5374\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.5329 - val_loss: 0.5196\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.5189 - val_loss: 0.5113\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.5075 - val_loss: 0.5048\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4983 - val_loss: 0.4953\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.4896 - val_loss: 0.4891\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4822 - val_loss: 0.4741\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4758 - val_loss: 0.4673\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4707 - val_loss: 0.4686\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4651 - val_loss: 0.4714\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4603 - val_loss: 0.4571\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4567 - val_loss: 0.4505\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4525 - val_loss: 0.4467\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4492 - val_loss: 0.4447\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4450 - val_loss: 0.4446\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4422 - val_loss: 0.4372\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4391 - val_loss: 0.4378\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4366 - val_loss: 0.4339\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4337 - val_loss: 0.4330\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4313 - val_loss: 0.4285\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4290 - val_loss: 0.4285\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4270 - val_loss: 0.4212\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4246 - val_loss: 0.4286\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.4221\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4202 - val_loss: 0.4156\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4183 - val_loss: 0.4150\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4167 - val_loss: 0.4178\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4126\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4135 - val_loss: 0.4109\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4133\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4105 - val_loss: 0.4080\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4088 - val_loss: 0.4053\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4038\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4059 - val_loss: 0.4048\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4114\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4043 - val_loss: 0.4053\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4028 - val_loss: 0.4108\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.4000\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3996 - val_loss: 0.4021\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3992 - val_loss: 0.3967\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3980 - val_loss: 0.3953\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.3953\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3954 - val_loss: 0.3942\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3946 - val_loss: 0.3925\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3936 - val_loss: 0.3922\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3930 - val_loss: 0.3908\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3922 - val_loss: 0.3911\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3911 - val_loss: 0.3960\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.4002\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3910 - val_loss: 0.4136\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3904 - val_loss: 0.4082\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3906 - val_loss: 0.4161\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3895 - val_loss: 0.4565\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3897 - val_loss: 0.4039\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3887 - val_loss: 0.3868\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3851 - val_loss: 0.3841\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.3878\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3834 - val_loss: 0.3861\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.3912\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.3804\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3817 - val_loss: 0.3808\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3804 - val_loss: 0.3810\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3799 - val_loss: 0.3802\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3788 - val_loss: 0.3829\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.3799\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3775 - val_loss: 0.3875\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3777 - val_loss: 0.4105\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3799 - val_loss: 0.4082\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3786 - val_loss: 0.4222\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3814 - val_loss: 0.4493\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3813 - val_loss: 0.4456\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.3985\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3759 - val_loss: 0.4086\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3773 - val_loss: 0.4192\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3766 - val_loss: 0.4452\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3486\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.7691 - val_loss: 1.0596\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7400 - val_loss: 0.7484\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6602 - val_loss: 0.6548\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6129 - val_loss: 0.6164\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5755 - val_loss: 0.6142\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5456 - val_loss: 0.5958\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5208 - val_loss: 0.5777\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5002 - val_loss: 0.5801\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4840 - val_loss: 0.5724\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4707 - val_loss: 0.5490\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4600 - val_loss: 0.5373\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4507 - val_loss: 0.5227\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4429 - val_loss: 0.5161\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4372 - val_loss: 0.5022\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4318 - val_loss: 0.4973\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4270 - val_loss: 0.4939\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4231 - val_loss: 0.4779\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4191 - val_loss: 0.4726\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.4685\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4129 - val_loss: 0.4613\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4535\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4079 - val_loss: 0.4507\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4473\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4446\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4013 - val_loss: 0.4419\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4401\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.4326\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3954 - val_loss: 0.4285\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3945 - val_loss: 0.4273\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.4252\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4248\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3899 - val_loss: 0.4198\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3884 - val_loss: 0.4207\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3872 - val_loss: 0.4171\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3862 - val_loss: 0.4139\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 4s 16ms/step - loss: 0.3848 - val_loss: 0.4149\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 4s 14ms/step - loss: 0.3834 - val_loss: 0.4137\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3823 - val_loss: 0.4109\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3810 - val_loss: 0.4100\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3802 - val_loss: 0.4084\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3790 - val_loss: 0.4065\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3785 - val_loss: 0.4099\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3773 - val_loss: 0.4051\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3761 - val_loss: 0.4038\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3760 - val_loss: 0.4029\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3740 - val_loss: 0.4037\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3738 - val_loss: 0.3996\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 4s 16ms/step - loss: 0.3730 - val_loss: 0.4010\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3717 - val_loss: 0.3982\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3709 - val_loss: 0.3981\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3701 - val_loss: 0.3967\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.3703 - val_loss: 0.3964\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3686 - val_loss: 0.3946\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3687 - val_loss: 0.3954\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3676 - val_loss: 0.3946\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3669 - val_loss: 0.3915\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.3924\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3656 - val_loss: 0.3893\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3649 - val_loss: 0.3889\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3639 - val_loss: 0.3890\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3634 - val_loss: 0.3881\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3633 - val_loss: 0.3966\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3875\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3616 - val_loss: 0.3879\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.3888\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.3851\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.3848\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3591 - val_loss: 0.3853\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.3842\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3586 - val_loss: 0.3845\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3576 - val_loss: 0.3826\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3578 - val_loss: 0.3848\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.3812\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.3804\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.3803\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3555 - val_loss: 0.3826\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.3800\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3547 - val_loss: 0.3789\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.3783\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3531 - val_loss: 0.3786\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.3805\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3530 - val_loss: 0.3770\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.3776\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3513 - val_loss: 0.3774\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3510 - val_loss: 0.3758\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.3755\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.3749\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3496 - val_loss: 0.3773\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3487 - val_loss: 0.3812\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3494 - val_loss: 0.3772\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3488 - val_loss: 0.3742\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.3744\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3479 - val_loss: 0.3722\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.3730\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3471 - val_loss: 0.3732\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.3717\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3457 - val_loss: 0.3726\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3459 - val_loss: 0.3715\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3453 - val_loss: 0.3718\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3449 - val_loss: 0.3747\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3943\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 9ms/step - loss: 0.9133 - val_loss: 0.8217\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.5576 - val_loss: 20.7886\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.7997 - val_loss: 1.0779\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5155 - val_loss: 0.4608\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4129 - val_loss: 0.3852\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3833 - val_loss: 0.3867\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.5033\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3657 - val_loss: 0.3654\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3637 - val_loss: 0.3936\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3488 - val_loss: 0.3540\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3444 - val_loss: 0.3580\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3385 - val_loss: 0.3533\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3364 - val_loss: 0.3386\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3288 - val_loss: 0.3679\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3303 - val_loss: 0.3590\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3253 - val_loss: 0.3316\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3213 - val_loss: 0.3151\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3160 - val_loss: 0.3520\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3147 - val_loss: 0.3241\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3106 - val_loss: 0.3220\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3148 - val_loss: 0.3189\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3101 - val_loss: 0.3194\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3088 - val_loss: 0.3035\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3040 - val_loss: 0.3166\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3034 - val_loss: 0.3420\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3024 - val_loss: 0.3369\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3000 - val_loss: 0.3036\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2973 - val_loss: 0.3193\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3003 - val_loss: 0.3177\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2963 - val_loss: 0.3130\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2927 - val_loss: 0.3098\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2926 - val_loss: 0.3356\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2949 - val_loss: 0.3171\n",
      "121/121 [==============================] - 1s 8ms/step - loss: 0.2865\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 10ms/step - loss: 0.7422 - val_loss: 0.5070\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4345 - val_loss: 0.4295\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3884 - val_loss: 0.4167\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3665 - val_loss: 0.3999\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3555 - val_loss: 0.3867\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3468 - val_loss: 0.3898\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3435 - val_loss: 0.4150\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3342 - val_loss: 0.3954\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3333 - val_loss: 0.3744\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3281 - val_loss: 0.3465\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3230 - val_loss: 0.4971\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3217 - val_loss: 0.3675\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3169 - val_loss: 0.3636\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3150 - val_loss: 0.3615\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3111 - val_loss: 0.4043\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3054 - val_loss: 0.3264\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3031 - val_loss: 0.5192\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3066 - val_loss: 0.3622\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3012 - val_loss: 0.7107\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3008 - val_loss: 0.3445\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2964 - val_loss: 0.5974\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2958 - val_loss: 0.3678\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3004 - val_loss: 0.5483\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2924 - val_loss: 0.3216\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2865 - val_loss: 0.4526\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2855 - val_loss: 0.3078\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2796 - val_loss: 0.4685\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2830 - val_loss: 0.3132\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2814 - val_loss: 0.4999\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.2776 - val_loss: 0.3230\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2770 - val_loss: 0.4681\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2725 - val_loss: 0.3057\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2731 - val_loss: 0.4655\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2736 - val_loss: 0.3463\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2693 - val_loss: 0.3812\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2703 - val_loss: 0.3169\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2689 - val_loss: 0.3371\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2681 - val_loss: 0.3289\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2656 - val_loss: 0.3623\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2661 - val_loss: 0.3284\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2642 - val_loss: 0.3131\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2598 - val_loss: 0.3306\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3416\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 0.7754 - val_loss: 4.0147\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9229 - val_loss: 4.1256\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 1s 5ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6832 - val_loss: 0.4762\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4363 - val_loss: 0.4169\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4079 - val_loss: 0.4258\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3935 - val_loss: 0.3923\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3850 - val_loss: 0.4531\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3878 - val_loss: 0.3811\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3682 - val_loss: 0.3685\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3678 - val_loss: 0.3688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3590 - val_loss: 0.3451\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3545 - val_loss: 0.3447\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3484 - val_loss: 0.3643\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3462 - val_loss: 0.3411\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3376 - val_loss: 0.3396\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3392 - val_loss: 0.3280\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3340 - val_loss: 0.3477\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3348 - val_loss: 0.3236\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3333 - val_loss: 0.3535\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3294 - val_loss: 0.3203\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3259 - val_loss: 0.3308\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3203 - val_loss: 0.3183\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3207 - val_loss: 0.3176\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3182 - val_loss: 0.3279\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3192 - val_loss: 0.3318\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3123 - val_loss: 0.3214\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3133 - val_loss: 0.3360\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3108 - val_loss: 0.3159\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3097 - val_loss: 0.3161\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3066 - val_loss: 0.3368\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3109 - val_loss: 0.3072\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3034 - val_loss: 0.3047\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3052 - val_loss: 0.3086\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3022 - val_loss: 0.3065\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2991 - val_loss: 0.3230\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3020 - val_loss: 0.3082\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3022 - val_loss: 0.3421\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2985 - val_loss: 0.2973\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2984 - val_loss: 0.3306\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2967 - val_loss: 0.3095\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2952 - val_loss: 0.3107\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2920 - val_loss: 0.2940\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2935 - val_loss: 0.3173\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2885 - val_loss: 0.3028\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2889 - val_loss: 0.3019\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2923 - val_loss: 0.3085\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2929 - val_loss: 0.3198\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2916 - val_loss: 0.3160\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2891 - val_loss: 0.2940\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2879 - val_loss: 0.2982\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2880 - val_loss: 0.2921\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2850 - val_loss: 0.2949\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2825 - val_loss: 0.3091\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2827 - val_loss: 0.2951\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2822 - val_loss: 0.2977\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2820 - val_loss: 0.3103\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2798 - val_loss: 0.3006\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2819 - val_loss: 0.2910\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2794 - val_loss: 0.2917\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2784 - val_loss: 0.3172\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2792 - val_loss: 0.2909\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2794 - val_loss: 0.2962\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2785 - val_loss: 0.2965\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2757 - val_loss: 0.3307\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.2785 - val_loss: 0.3376\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2745 - val_loss: 0.3026\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2738 - val_loss: 0.2996\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2720 - val_loss: 0.3140\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2712 - val_loss: 0.2984\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2711 - val_loss: 0.3121\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.2694 - val_loss: 0.2914\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.2801\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 8ms/step - loss: 0.9255 - val_loss: 2.7117\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5353 - val_loss: 0.5312\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4196 - val_loss: 0.4442\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3895 - val_loss: 0.4203\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3651 - val_loss: 0.3768\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3540 - val_loss: 0.4679\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3418 - val_loss: 0.4342\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.3460 - val_loss: 0.3526\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3275 - val_loss: 0.3461\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3225 - val_loss: 0.3311\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.3161 - val_loss: 0.3504\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3108 - val_loss: 0.3472\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3078 - val_loss: 0.3182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3047 - val_loss: 0.3466\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2998 - val_loss: 0.3197\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2973 - val_loss: 0.3199\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2917 - val_loss: 0.3141\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2896 - val_loss: 0.3279\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2867 - val_loss: 0.3233\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2865 - val_loss: 0.3086\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2836 - val_loss: 0.2994\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2827 - val_loss: 0.3037\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2834 - val_loss: 0.3145\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2779 - val_loss: 0.3008\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2791 - val_loss: 0.3210\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2763 - val_loss: 0.2913\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2752 - val_loss: 0.2915\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2741 - val_loss: 0.2954\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2730 - val_loss: 0.3023\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.2702 - val_loss: 0.2893\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.2686 - val_loss: 0.3069\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2700 - val_loss: 0.3033\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2678 - val_loss: 0.3180\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2671 - val_loss: 0.3000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2669 - val_loss: 0.2916\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.2645 - val_loss: 0.3057\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2648 - val_loss: 0.3038\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2642 - val_loss: 0.5760\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.2692 - val_loss: 0.4726\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.2641 - val_loss: 0.4500\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.3611\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 8s 19ms/step - loss: 1.5028 - val_loss: 21.7327\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 3.6317 - val_loss: 319.9529\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 7s 27ms/step - loss: 47.3867 - val_loss: 4320.9561\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 5s 21ms/step - loss: 639.0255 - val_loss: 58032.9648\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 5670.1240 - val_loss: 780533.3750\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 78274.3750 - val_loss: 10479272.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1160875.1250 - val_loss: 140387776.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 16825632.0000 - val_loss: 1885196416.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 251526208.0000 - val_loss: 25298305024.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 2988377344.0000 - val_loss: 340222476288.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 35177611264.0000 - val_loss: 4579961864192.0000\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 166191841280.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.6275 - val_loss: 0.6124\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6192 - val_loss: 1.5687\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8733 - val_loss: 1.8050\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.1403 - val_loss: 1.5808\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7839 - val_loss: 1.4287\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1573 - val_loss: 2.2129\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9835 - val_loss: 1.9627\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6317 - val_loss: 8.0001\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6949 - val_loss: 4.2764\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6916 - val_loss: 9.9421\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7324 - val_loss: 5.3862\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4750\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.4217 - val_loss: 0.5751\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5465 - val_loss: 0.5914\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.6654\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5175 - val_loss: 0.5767\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5194 - val_loss: 0.5849\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5134 - val_loss: 0.6311\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5138 - val_loss: 0.5775\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5089 - val_loss: 0.6493\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5099 - val_loss: 0.6172\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5078 - val_loss: 0.5967\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5130 - val_loss: 0.6342\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.5857\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-3.17744176e-01 -3.88463080e-01 -3.12540660e-01 -3.28074882e-01\n",
      " -3.46751223e-01 -4.07552640e-01 -3.68954092e-01             nan\n",
      "             nan -5.53972804e+10]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 3ms/step - loss: 0.7563 - val_loss: 1.2069\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6139 - val_loss: 0.5102\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4501 - val_loss: 0.6461\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4394 - val_loss: 0.4729\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4034\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3787 - val_loss: 0.3907\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.3728\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.3758\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.3648\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3507 - val_loss: 0.3532\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.3535\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3502\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3828 - val_loss: 0.3515\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3393 - val_loss: 0.3417\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3350 - val_loss: 0.3394\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3287 - val_loss: 0.3392\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3263 - val_loss: 0.3296\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3248 - val_loss: 0.3410\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3202 - val_loss: 0.3295\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3316\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3175 - val_loss: 0.3310\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3116 - val_loss: 0.3442\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3101 - val_loss: 0.3184\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3090 - val_loss: 0.3148\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3056 - val_loss: 0.3397\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3040 - val_loss: 0.3151\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3021 - val_loss: 0.3066\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.2998 - val_loss: 0.3074\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2981 - val_loss: 0.3204\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2964 - val_loss: 0.3119\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2971 - val_loss: 0.3067\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2937 - val_loss: 0.3081\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2933 - val_loss: 0.3021\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2908 - val_loss: 0.3247\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2908 - val_loss: 0.2966\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2887 - val_loss: 0.3020\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2884 - val_loss: 0.3102\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.3041\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2852 - val_loss: 0.3015\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2881 - val_loss: 0.3165\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.3345\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.3663\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.3240\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2872 - val_loss: 0.3398\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.3128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1772c5970&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x1738f8610&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1772c5970&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x1738f8610&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1772c5970&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1772c5970&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1772c5970>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x1738f8610>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train, epochs=100,\n",
    "                  validation_data=(X_valid_scaled, y_valid),\n",
    "                                  callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
    "                                  workers=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that RandomizedSearchCV uses K-fold cross-validation.\n",
    "After the run is finished, the best paramters, score and trained model can be accessed:\n",
    "``` cl\n",
    ">>> rnd_search_cv.best_params_\n",
    "\n",
    ">>> rnd_search_cv.best_score_\n",
    "\n",
    ">>> model = rnd_search_cv.best_estimator_.model\n",
    "```\n",
    "\n",
    "- This method works well for many fairly simple problems\n",
    "- When training is slow, this will only explore a tiny portion of the space\n",
    "- Other methods exist based on the idea of exploring the space, finding good regions and continuing to expore around these regions. Here are a few Python libraries\n",
    "    - Hyperopt\n",
    "    - Hyperas, kopt, or Talos: optimizing hps for Keras model\n",
    "    - Scikit-Optimize (skopt): general purpose optimization library\n",
    "    - Spearmint: a Bayesian optimization library\n",
    "    - Sklearn-Deap: a hp optimization library based on evolutionary algos, also with a GridSearchCV like interface\n",
    "- Several other tools: AutoML, Uber's Deep Neuroevolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_\n",
    "rnd_search_cv.best_score_\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.2825\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "total_loss= model.evaluate(\n",
    "    X_test_scaled, y_test)\n",
    "y_pred_main = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.009678477383068684, 'n_hidden': 2, 'n_neurons': 74}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Hidden Layers\n",
    "- A single hidden layer network can model very complex functions with enough neurons\n",
    "- But, deep networks have a much higher parameter efficiency than shallow ones\n",
    "    - Can model complex functions using exponentially fewer neurons than shallow nets -> much better performance w/ same amount of training data\n",
    "    - DNNs take advantage of hierarchical architecture in data to model different levels of the problem\n",
    "        - Converge faster to a good solution and improves ability to generalize to new datasets\n",
    "    - Transfer learning is the reuse of lower level structures in a DNN to prevent the need to start learning from scratch\n",
    "\n",
    "## Number of Neurons per Hidden Layer\n",
    "- Generally can use the same number of neurons in all layers\n",
    "- Can try increasing the # of neurons gradually until the network starts overfitting\n",
    "- Will generally get more bang for the buck by increasing the # of layers than the # of neurons per layer\n",
    "- Can also use a model w/ more layers and neurons than you need and use early stopping to prevent overfitting\n",
    "\n",
    "## Learning Rate, Batch Size, and Other Hyperparameters\n",
    "Learning rate is arguably the most important hp:\n",
    "- Optimal LR is generally about half of the max LR (the LR above which the training algo diverges)\n",
    "- Start w/ a large value that causes divergence -> divide this by 3 -> iterate until training algo stops diverging <br>\n",
    "Batch size:\n",
    "- Generally, optimal batch size is lower than 32\n",
    "- Small batch ensures each training iteration is very fast\n",
    "- Batch size greater than 10 helps take advantage of hardware and software optimizations, (matrix multiplication) to speed up training <br>\n",
    "Activation Function:\n",
    "-Generally, ReLU will be a good default for hidden layers\n",
    "- Output layer activation function is dependent on task\n",
    "<link> https://arxiv.org/abs/1206.5533 </link> <br>\n",
    "paper w/ recommends for hp parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Exercises\n",
    "\n",
    "3. Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier? <br> <br>\n",
    "A: Classical Perceptrons make predictions based on a hard threshold rather than a class probability. Logistic regression classifiers output a class probability. Multiple layers can be added to a perceptron to improve this limitation <br> <br>\n",
    "\n",
    "4. Why was the logistic activation function (sigmoid) a key ingredient in training the first MLPs? <br> <br>\n",
    "A: The logistic activation function allows gradient descent to be used to adjust weights of the connections as opposed to having a discrete 0 or 1. The sigmoid function is smooth and differentiable allowing a probability-like value to be output. Enables backpropagation <br> <br>\n",
    "\n",
    "6. Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function. \n",
    "- What is the shape of the input matrix X? \n",
    "- What about the shape of the hidden layer’s weight vector W_h, and the shape of its bias vector b_h? \n",
    "- What is the shape of the output layer’s weight vector W_o, and its bias vector b_o?\n",
    "- What is the shape of the network’s output matrix Y?\n",
    "- Write the equation that computes the network’s output matrix Y as a function of X, W_h, b_h, W_o and b_o. <br> <br>\n",
    "\n",
    "A: <br>\n",
    "-  $X - [1 x 10] $<br>\n",
    "$W_h - [10 x 50] $ <br>\n",
    "$B_h - [1 x 50] $ <br>\n",
    "$ W_o [50 x 3] $ <br>\n",
    "$ B_o - [1 x 3] $ <br>\n",
    "$ Y =  \\phi(\\phi(X*W_h + B_h)*W_o + B_o) $ <br> \n",
    "\n",
    "\n",
    "7. How many neurons do you need in the output layer if you want to classify email into spam or ham? What activation function should you use in the output layer? If instead you want to tackle MNIST, how many neurons do you need in the output layer, using what activation function? <br> <br>\n",
    "\n",
    "A: <br>\n",
    "- 1 neuron is needed in the output layer with a logistic activation function to classify email into spam or ham. <br>\n",
    "For MNIST, you'd want 10 output neurons to represent the possibility of each number 0-9 and use a softmax function to make a probability distribution across the output neurons for the numbers that adds to 1.\n",
    "<br> <br>\n",
    "\n",
    "9. Can you list all the hyperparameters you can tweak in an MLP? If the MLP over‐ fits the training data, how could you tweak these hyperparameters to try to solve the problem? <br> <br>\n",
    "A: <br>\n",
    "-Learning rate, number of hidden layers, number of neurons per layer, shape of network, batch size, activation function, training epochs (early stop can mitigate too many), optimizer choice, loss function\n",
    "- Early stopping can help to mitigate overfitting so watching when the validation loss isn't improving more, can also decrease model complexity such as # of layers and # of neurons per layer, regularization can also impact this\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Try adding all the bells and whistles (i.e., save checkpoints, use early stopping, plot learning curves using TensorBoard, and so on).\n",
    "\n",
    "## Training a deep MLP on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a deep MLP on MNIST\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[:5000] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=6, n_neurons=40, learning_rate=3e-3, input_shape=[28, 28]):\n",
    "    num_output_neurons = 10\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layers in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(num_output_neurons, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "model = build_model()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 40)                31400     \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 10)                410       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,010\n",
      "Trainable params: 40,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 3s 8ms/step - loss: 2.3043 - accuracy: 0.1022 - val_loss: 2.2979 - val_accuracy: 0.1252\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2927 - accuracy: 0.1482 - val_loss: 2.2869 - val_accuracy: 0.1652\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2811 - accuracy: 0.1646 - val_loss: 2.2740 - val_accuracy: 0.1688\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2658 - accuracy: 0.1698 - val_loss: 2.2554 - val_accuracy: 0.1694\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2431 - accuracy: 0.1790 - val_loss: 2.2282 - val_accuracy: 0.1848\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2109 - accuracy: 0.1900 - val_loss: 2.1911 - val_accuracy: 0.2014\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1701 - accuracy: 0.2076 - val_loss: 2.1469 - val_accuracy: 0.2120\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1245 - accuracy: 0.2174 - val_loss: 2.1001 - val_accuracy: 0.2284\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.0771 - accuracy: 0.2408 - val_loss: 2.0510 - val_accuracy: 0.2560\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0248 - accuracy: 0.2748 - val_loss: 1.9946 - val_accuracy: 0.2954\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9616 - accuracy: 0.3280 - val_loss: 1.9227 - val_accuracy: 0.3548\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8785 - accuracy: 0.3934 - val_loss: 1.8253 - val_accuracy: 0.4628\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.7640 - accuracy: 0.4960 - val_loss: 1.6927 - val_accuracy: 0.5416\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6113 - accuracy: 0.5724 - val_loss: 1.5188 - val_accuracy: 0.6030\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4218 - accuracy: 0.6260 - val_loss: 1.3113 - val_accuracy: 0.6622\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.2050 - accuracy: 0.6826 - val_loss: 1.0875 - val_accuracy: 0.7220\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.9878 - accuracy: 0.7474 - val_loss: 0.8865 - val_accuracy: 0.7682\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8013 - accuracy: 0.8038 - val_loss: 0.7187 - val_accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6713 - accuracy: 0.8248 - val_loss: 0.6771 - val_accuracy: 0.8046\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5933 - accuracy: 0.8364 - val_loss: 0.5578 - val_accuracy: 0.8496\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.8488 - val_loss: 0.5137 - val_accuracy: 0.8560\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5104 - accuracy: 0.8588 - val_loss: 0.5216 - val_accuracy: 0.8550\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8616 - val_loss: 0.5206 - val_accuracy: 0.8482\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4580 - accuracy: 0.8724 - val_loss: 0.4379 - val_accuracy: 0.8714\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.8750 - val_loss: 0.4498 - val_accuracy: 0.8664\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4207 - accuracy: 0.8816 - val_loss: 0.4168 - val_accuracy: 0.8810\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4078 - accuracy: 0.8878 - val_loss: 0.3962 - val_accuracy: 0.8914\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3937 - accuracy: 0.8910 - val_loss: 0.3704 - val_accuracy: 0.8972\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3787 - accuracy: 0.8942 - val_loss: 0.4099 - val_accuracy: 0.8794\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3741 - accuracy: 0.8952 - val_loss: 0.4238 - val_accuracy: 0.8672\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3596 - accuracy: 0.9008 - val_loss: 0.4548 - val_accuracy: 0.8642\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3521 - accuracy: 0.8998 - val_loss: 0.4394 - val_accuracy: 0.8678\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3428 - accuracy: 0.9008 - val_loss: 0.3457 - val_accuracy: 0.9012\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.9050 - val_loss: 0.3159 - val_accuracy: 0.9080\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3229 - accuracy: 0.9086 - val_loss: 0.3267 - val_accuracy: 0.9040\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3187 - accuracy: 0.9082 - val_loss: 0.3491 - val_accuracy: 0.8966\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3088 - accuracy: 0.9116 - val_loss: 0.3227 - val_accuracy: 0.9036\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3023 - accuracy: 0.9120 - val_loss: 0.3168 - val_accuracy: 0.9074\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.2948 - accuracy: 0.9144 - val_loss: 0.2862 - val_accuracy: 0.9168\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2885 - accuracy: 0.9164 - val_loss: 0.2709 - val_accuracy: 0.9224\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2791 - accuracy: 0.9204 - val_loss: 0.2654 - val_accuracy: 0.9240\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2725 - accuracy: 0.9226 - val_loss: 0.2783 - val_accuracy: 0.9178\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.2678 - accuracy: 0.9248 - val_loss: 0.2539 - val_accuracy: 0.9280\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2602 - accuracy: 0.9242 - val_loss: 0.3118 - val_accuracy: 0.9032\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.2535 - accuracy: 0.9276 - val_loss: 0.3107 - val_accuracy: 0.9120\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2487 - accuracy: 0.9302 - val_loss: 0.2376 - val_accuracy: 0.9326\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2423 - accuracy: 0.9302 - val_loss: 0.2541 - val_accuracy: 0.9218\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2376 - accuracy: 0.9322 - val_loss: 0.2386 - val_accuracy: 0.9288\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2319 - accuracy: 0.9344 - val_loss: 0.2163 - val_accuracy: 0.9384\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2290 - accuracy: 0.9348 - val_loss: 0.2360 - val_accuracy: 0.9302\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2235 - accuracy: 0.9332 - val_loss: 0.3219 - val_accuracy: 0.8956\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2185 - accuracy: 0.9384 - val_loss: 0.2064 - val_accuracy: 0.9402\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2092 - accuracy: 0.9424 - val_loss: 0.2034 - val_accuracy: 0.9400\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.2068 - accuracy: 0.9386 - val_loss: 0.2269 - val_accuracy: 0.9330\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2038 - accuracy: 0.9404 - val_loss: 0.2564 - val_accuracy: 0.9212\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1957 - accuracy: 0.9452 - val_loss: 0.1887 - val_accuracy: 0.9470\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1924 - accuracy: 0.9462 - val_loss: 0.1846 - val_accuracy: 0.9488\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1866 - accuracy: 0.9476 - val_loss: 0.1998 - val_accuracy: 0.9378\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1847 - accuracy: 0.9440 - val_loss: 0.1970 - val_accuracy: 0.9410\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1795 - accuracy: 0.9480 - val_loss: 0.1656 - val_accuracy: 0.9520\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1728 - accuracy: 0.9518 - val_loss: 0.1662 - val_accuracy: 0.9534\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1698 - accuracy: 0.9516 - val_loss: 0.1610 - val_accuracy: 0.9538\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1680 - accuracy: 0.9528 - val_loss: 0.2111 - val_accuracy: 0.9332\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.1632 - accuracy: 0.9504 - val_loss: 0.1528 - val_accuracy: 0.9578\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.9572 - val_loss: 0.1497 - val_accuracy: 0.9586\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1531 - accuracy: 0.9570 - val_loss: 0.1503 - val_accuracy: 0.9560\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1519 - accuracy: 0.9574 - val_loss: 0.1439 - val_accuracy: 0.9606\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1452 - accuracy: 0.9624 - val_loss: 0.1356 - val_accuracy: 0.9624\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1412 - accuracy: 0.9616 - val_loss: 0.1317 - val_accuracy: 0.9652\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1388 - accuracy: 0.9620 - val_loss: 0.3051 - val_accuracy: 0.8992\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1365 - accuracy: 0.9628 - val_loss: 0.1697 - val_accuracy: 0.9466\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1324 - accuracy: 0.9634 - val_loss: 0.1329 - val_accuracy: 0.9620\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9648 - val_loss: 0.1233 - val_accuracy: 0.9654\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1235 - accuracy: 0.9658 - val_loss: 0.1496 - val_accuracy: 0.9548\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.9676 - val_loss: 0.1421 - val_accuracy: 0.9550\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.9654 - val_loss: 0.1125 - val_accuracy: 0.9690\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1147 - accuracy: 0.9690 - val_loss: 0.1149 - val_accuracy: 0.9694\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9700 - val_loss: 0.1086 - val_accuracy: 0.9702\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9694 - val_loss: 0.1106 - val_accuracy: 0.9678\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9732 - val_loss: 0.1008 - val_accuracy: 0.9738\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9732 - val_loss: 0.0969 - val_accuracy: 0.9756\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1007 - accuracy: 0.9738 - val_loss: 0.0962 - val_accuracy: 0.9744\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9744 - val_loss: 0.1006 - val_accuracy: 0.9740\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9736 - val_loss: 0.0918 - val_accuracy: 0.9778\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0954 - accuracy: 0.9758 - val_loss: 0.0917 - val_accuracy: 0.9770\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0911 - accuracy: 0.9788 - val_loss: 0.0864 - val_accuracy: 0.9810\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0905 - accuracy: 0.9774 - val_loss: 0.0849 - val_accuracy: 0.9798\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9780 - val_loss: 0.3935 - val_accuracy: 0.8828\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9772 - val_loss: 0.0793 - val_accuracy: 0.9814\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9794 - val_loss: 0.0806 - val_accuracy: 0.9798\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0805 - accuracy: 0.9804 - val_loss: 0.0789 - val_accuracy: 0.9806\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0777 - accuracy: 0.9820 - val_loss: 0.0731 - val_accuracy: 0.9830\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0751 - accuracy: 0.9834 - val_loss: 0.0693 - val_accuracy: 0.9840\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0722 - accuracy: 0.9842 - val_loss: 0.0680 - val_accuracy: 0.9846\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9826 - val_loss: 0.0803 - val_accuracy: 0.9780\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0699 - accuracy: 0.9852 - val_loss: 0.1012 - val_accuracy: 0.9672\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0699 - accuracy: 0.9838 - val_loss: 0.0644 - val_accuracy: 0.9856\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0660 - accuracy: 0.9854 - val_loss: 0.0672 - val_accuracy: 0.9852\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0649 - accuracy: 0.9864 - val_loss: 0.0593 - val_accuracy: 0.9876\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9864 - val_loss: 0.0638 - val_accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data= (X_valid, y_valid),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
    "                    workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 79.6227 - accuracy: 0.8988\n"
     ]
    }
   ],
   "source": [
    "total_loss= model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0623 - accuracy: 0.9858 - val_loss: 0.0648 - val_accuracy: 0.9840\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0602 - accuracy: 0.9876 - val_loss: 0.0606 - val_accuracy: 0.9868\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0579 - accuracy: 0.9884 - val_loss: 0.0667 - val_accuracy: 0.9838\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0576 - accuracy: 0.9882 - val_loss: 0.0544 - val_accuracy: 0.9894\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0559 - accuracy: 0.9898 - val_loss: 0.0758 - val_accuracy: 0.9784\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0539 - accuracy: 0.9900 - val_loss: 0.0497 - val_accuracy: 0.9912\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0521 - accuracy: 0.9910 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0502 - accuracy: 0.9914 - val_loss: 0.0465 - val_accuracy: 0.9926\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0492 - accuracy: 0.9910 - val_loss: 0.0449 - val_accuracy: 0.9936\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0480 - accuracy: 0.9918 - val_loss: 0.0564 - val_accuracy: 0.9868\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0478 - accuracy: 0.9922 - val_loss: 0.0422 - val_accuracy: 0.9946\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0456 - accuracy: 0.9920 - val_loss: 0.0434 - val_accuracy: 0.9934\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0448 - accuracy: 0.9932 - val_loss: 0.0403 - val_accuracy: 0.9942\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0429 - accuracy: 0.9936 - val_loss: 0.0418 - val_accuracy: 0.9942\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9932 - val_loss: 0.0399 - val_accuracy: 0.9936\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0410 - accuracy: 0.9942 - val_loss: 0.0410 - val_accuracy: 0.9934\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9938 - val_loss: 0.0369 - val_accuracy: 0.9954\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0392 - accuracy: 0.9944 - val_loss: 0.0387 - val_accuracy: 0.9946\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9950 - val_loss: 0.0427 - val_accuracy: 0.9928\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9952 - val_loss: 0.0343 - val_accuracy: 0.9956\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0359 - accuracy: 0.9952 - val_loss: 0.0338 - val_accuracy: 0.9948\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9942 - val_loss: 0.0337 - val_accuracy: 0.9952\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0343 - accuracy: 0.9950 - val_loss: 0.0311 - val_accuracy: 0.9966\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0337 - accuracy: 0.9954 - val_loss: 0.0301 - val_accuracy: 0.9968\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9958 - val_loss: 0.0310 - val_accuracy: 0.9962\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0326 - accuracy: 0.9956 - val_loss: 0.0287 - val_accuracy: 0.9964\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9960 - val_loss: 0.0878 - val_accuracy: 0.9698\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9968 - val_loss: 0.0275 - val_accuracy: 0.9972\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0293 - accuracy: 0.9962 - val_loss: 0.0301 - val_accuracy: 0.9964\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.9958 - val_loss: 0.0285 - val_accuracy: 0.9962\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0281 - accuracy: 0.9966 - val_loss: 0.0441 - val_accuracy: 0.9896\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9966 - val_loss: 0.0252 - val_accuracy: 0.9974\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9970 - val_loss: 0.0402 - val_accuracy: 0.9902\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0268 - accuracy: 0.9972 - val_loss: 0.0266 - val_accuracy: 0.9972\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0252 - accuracy: 0.9968 - val_loss: 0.0257 - val_accuracy: 0.9964\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0250 - accuracy: 0.9970 - val_loss: 0.0246 - val_accuracy: 0.9972\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.0229 - val_accuracy: 0.9978\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9976 - val_loss: 0.0257 - val_accuracy: 0.9958\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9974 - val_loss: 0.0217 - val_accuracy: 0.9978\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0225 - accuracy: 0.9974 - val_loss: 0.0202 - val_accuracy: 0.9978\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9978 - val_loss: 0.0218 - val_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0220 - accuracy: 0.9974 - val_loss: 0.0202 - val_accuracy: 0.9982\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0211 - accuracy: 0.9974 - val_loss: 0.0218 - val_accuracy: 0.9976\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9978 - val_loss: 0.0194 - val_accuracy: 0.9980\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0199 - accuracy: 0.9976 - val_loss: 0.0185 - val_accuracy: 0.9982\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0197 - accuracy: 0.9978 - val_loss: 0.0184 - val_accuracy: 0.9984\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9982 - val_loss: 0.0188 - val_accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9978 - val_loss: 0.0166 - val_accuracy: 0.9982\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9980 - val_loss: 0.0169 - val_accuracy: 0.9984\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.0165 - val_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.0163 - val_accuracy: 0.9986\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9982 - val_loss: 0.0163 - val_accuracy: 0.9984\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9986 - val_loss: 0.0163 - val_accuracy: 0.9982\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9980 - val_loss: 0.0160 - val_accuracy: 0.9986\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9982 - val_loss: 0.0154 - val_accuracy: 0.9986\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9988 - val_loss: 0.0142 - val_accuracy: 0.9986\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9982 - val_loss: 0.0141 - val_accuracy: 0.9986\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.9982 - val_loss: 0.0136 - val_accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9986 - val_loss: 0.0134 - val_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9986 - val_loss: 0.0144 - val_accuracy: 0.9982\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0138 - accuracy: 0.9988 - val_loss: 0.0137 - val_accuracy: 0.9990\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9986 - val_loss: 0.0142 - val_accuracy: 0.9986\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.0129 - val_accuracy: 0.9990\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0129 - accuracy: 0.9988 - val_loss: 0.0117 - val_accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 0.0117 - val_accuracy: 0.9992\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 0.0116 - val_accuracy: 0.9990\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0121 - accuracy: 0.9990 - val_loss: 0.0110 - val_accuracy: 0.9992\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 4s 22ms/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 0.0109 - val_accuracy: 0.9992\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 0.0114 - val_accuracy: 0.9990\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 0.0102 - val_accuracy: 0.9992\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9992\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.0101 - val_accuracy: 0.9994\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.0126 - val_accuracy: 0.9990\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0105 - accuracy: 0.9992 - val_loss: 0.0097 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0100 - accuracy: 0.9992 - val_loss: 0.0097 - val_accuracy: 0.9994\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 0.0104 - val_accuracy: 0.9994\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9994\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9994\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9994 - val_loss: 0.0087 - val_accuracy: 0.9994\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9994\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.0081 - val_accuracy: 0.9994\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0086 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9994\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9994\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0075 - val_accuracy: 0.9994\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.0071 - val_accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.0074 - val_accuracy: 0.9994\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9996\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.0065 - val_accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.0067 - val_accuracy: 0.9998\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9998\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9996\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9998\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data= (X_valid, y_valid),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                               tensorboard_cb],\n",
    "                    workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xc/zkw390zs49vd6b73myjws_n40000gn/T/ipykernel_1491/2409665360.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 9ms/step - loss: 2.3040 - accuracy: 0.1032 - val_loss: 2.2982 - val_accuracy: 0.1264\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.2930 - accuracy: 0.1518 - val_loss: 2.2871 - val_accuracy: 0.1796\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2813 - accuracy: 0.1988 - val_loss: 2.2743 - val_accuracy: 0.2144\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2662 - accuracy: 0.2352 - val_loss: 2.2561 - val_accuracy: 0.2572\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2431 - accuracy: 0.2740 - val_loss: 2.2268 - val_accuracy: 0.2930\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 2.2049 - accuracy: 0.3088 - val_loss: 2.1774 - val_accuracy: 0.3294\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.1417 - accuracy: 0.3492 - val_loss: 2.0980 - val_accuracy: 0.3626\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.0436 - accuracy: 0.3810 - val_loss: 1.9801 - val_accuracy: 0.4004\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.9069 - accuracy: 0.4116 - val_loss: 1.8235 - val_accuracy: 0.4320\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.7327 - accuracy: 0.4642 - val_loss: 1.6311 - val_accuracy: 0.4960\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.5288 - accuracy: 0.5332 - val_loss: 1.4227 - val_accuracy: 0.5616\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.3298 - accuracy: 0.5940 - val_loss: 1.2388 - val_accuracy: 0.6294\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.1647 - accuracy: 0.6498 - val_loss: 1.1028 - val_accuracy: 0.6546\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.0371 - accuracy: 0.6914 - val_loss: 0.9710 - val_accuracy: 0.7168\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.9325 - accuracy: 0.7242 - val_loss: 0.9135 - val_accuracy: 0.7162\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.8514 - accuracy: 0.7464 - val_loss: 0.8047 - val_accuracy: 0.7652\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.7827 - accuracy: 0.7654 - val_loss: 0.7474 - val_accuracy: 0.7792\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.7316 - accuracy: 0.7822 - val_loss: 0.6967 - val_accuracy: 0.7962\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.7902 - val_loss: 0.6623 - val_accuracy: 0.7992\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.8078 - val_loss: 0.6729 - val_accuracy: 0.7874\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.6130 - accuracy: 0.8130 - val_loss: 0.5929 - val_accuracy: 0.8246\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.5815 - accuracy: 0.8268 - val_loss: 0.5596 - val_accuracy: 0.8370\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5556 - accuracy: 0.8338 - val_loss: 0.5385 - val_accuracy: 0.8440\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5279 - accuracy: 0.8442 - val_loss: 0.5283 - val_accuracy: 0.8446\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.8554 - val_loss: 0.4788 - val_accuracy: 0.8664\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4819 - accuracy: 0.8640 - val_loss: 0.4721 - val_accuracy: 0.8646\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4612 - accuracy: 0.8706 - val_loss: 0.4648 - val_accuracy: 0.8660\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4449 - accuracy: 0.8754 - val_loss: 0.4344 - val_accuracy: 0.8780\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4282 - accuracy: 0.8814 - val_loss: 0.4184 - val_accuracy: 0.8842\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4129 - accuracy: 0.8850 - val_loss: 0.3951 - val_accuracy: 0.8918\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3992 - accuracy: 0.8884 - val_loss: 0.3939 - val_accuracy: 0.8890\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3877 - accuracy: 0.8950 - val_loss: 0.3669 - val_accuracy: 0.8984\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8936 - val_loss: 0.4445 - val_accuracy: 0.8670\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3636 - accuracy: 0.8950 - val_loss: 0.3412 - val_accuracy: 0.9054\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3516 - accuracy: 0.9040 - val_loss: 0.3783 - val_accuracy: 0.8896\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3394 - accuracy: 0.9056 - val_loss: 0.3368 - val_accuracy: 0.9070\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3324 - accuracy: 0.9056 - val_loss: 0.3116 - val_accuracy: 0.9134\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3211 - accuracy: 0.9104 - val_loss: 0.3130 - val_accuracy: 0.9132\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.3122 - accuracy: 0.9148 - val_loss: 0.2931 - val_accuracy: 0.9220\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.3041 - accuracy: 0.9152 - val_loss: 0.2870 - val_accuracy: 0.9234\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2946 - accuracy: 0.9196 - val_loss: 0.2776 - val_accuracy: 0.9224\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2853 - accuracy: 0.9216 - val_loss: 0.3028 - val_accuracy: 0.9116\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2795 - accuracy: 0.9238 - val_loss: 0.2781 - val_accuracy: 0.9260\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2704 - accuracy: 0.9264 - val_loss: 0.2608 - val_accuracy: 0.9276\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2653 - accuracy: 0.9290 - val_loss: 0.2564 - val_accuracy: 0.9304\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2598 - accuracy: 0.9296 - val_loss: 0.2633 - val_accuracy: 0.9276\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.2499 - accuracy: 0.9294 - val_loss: 0.2432 - val_accuracy: 0.9338\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2439 - accuracy: 0.9348 - val_loss: 0.2298 - val_accuracy: 0.9396\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2386 - accuracy: 0.9358 - val_loss: 0.2314 - val_accuracy: 0.9380\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2303 - accuracy: 0.9364 - val_loss: 0.2435 - val_accuracy: 0.9318\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.2252 - accuracy: 0.9406 - val_loss: 0.2111 - val_accuracy: 0.9452\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.2188 - accuracy: 0.9424 - val_loss: 0.2654 - val_accuracy: 0.9180\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.2142 - accuracy: 0.9416 - val_loss: 0.1999 - val_accuracy: 0.9468\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.2095 - accuracy: 0.9438 - val_loss: 0.1971 - val_accuracy: 0.9454\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.2017 - accuracy: 0.9464 - val_loss: 0.2237 - val_accuracy: 0.9380\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1943 - accuracy: 0.9500 - val_loss: 0.1891 - val_accuracy: 0.9520\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1926 - accuracy: 0.9510 - val_loss: 0.1832 - val_accuracy: 0.9522\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.1854 - accuracy: 0.9494 - val_loss: 0.2718 - val_accuracy: 0.9162\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.1851 - accuracy: 0.9524 - val_loss: 0.1690 - val_accuracy: 0.9588\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.1783 - accuracy: 0.9538 - val_loss: 0.1626 - val_accuracy: 0.9608\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1743 - accuracy: 0.9558 - val_loss: 0.1600 - val_accuracy: 0.9600\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1678 - accuracy: 0.9564 - val_loss: 0.1719 - val_accuracy: 0.9536\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.1637 - accuracy: 0.9590 - val_loss: 0.1628 - val_accuracy: 0.9590\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1591 - accuracy: 0.9602 - val_loss: 0.1570 - val_accuracy: 0.9584\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1536 - accuracy: 0.9596 - val_loss: 0.1434 - val_accuracy: 0.9638\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1498 - accuracy: 0.9618 - val_loss: 0.1581 - val_accuracy: 0.9574\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1476 - accuracy: 0.9614 - val_loss: 0.1357 - val_accuracy: 0.9646\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1441 - accuracy: 0.9636 - val_loss: 0.2361 - val_accuracy: 0.9208\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1394 - accuracy: 0.9684 - val_loss: 0.1286 - val_accuracy: 0.9686\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1361 - accuracy: 0.9666 - val_loss: 0.1337 - val_accuracy: 0.9662\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.1329 - accuracy: 0.9662 - val_loss: 0.1556 - val_accuracy: 0.9572\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1281 - accuracy: 0.9682 - val_loss: 0.1530 - val_accuracy: 0.9536\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.1262 - accuracy: 0.9674 - val_loss: 0.1239 - val_accuracy: 0.9694\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1204 - accuracy: 0.9696 - val_loss: 0.1297 - val_accuracy: 0.9670\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9702 - val_loss: 0.1084 - val_accuracy: 0.9754\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1153 - accuracy: 0.9710 - val_loss: 0.1061 - val_accuracy: 0.9742\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1110 - accuracy: 0.9734 - val_loss: 0.1068 - val_accuracy: 0.9740\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1078 - accuracy: 0.9738 - val_loss: 0.0975 - val_accuracy: 0.9774\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9752 - val_loss: 0.1083 - val_accuracy: 0.9728\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.1024 - accuracy: 0.9760 - val_loss: 0.0950 - val_accuracy: 0.9784\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1003 - accuracy: 0.9762 - val_loss: 0.1403 - val_accuracy: 0.9546\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0965 - accuracy: 0.9788 - val_loss: 0.0933 - val_accuracy: 0.9764\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0941 - accuracy: 0.9780 - val_loss: 0.0872 - val_accuracy: 0.9802\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.0913 - accuracy: 0.9762 - val_loss: 0.0822 - val_accuracy: 0.9808\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0901 - accuracy: 0.9766 - val_loss: 0.0807 - val_accuracy: 0.9832\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.0864 - accuracy: 0.9786 - val_loss: 0.0814 - val_accuracy: 0.9802\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0834 - accuracy: 0.9794 - val_loss: 0.0754 - val_accuracy: 0.9838\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0805 - accuracy: 0.9814 - val_loss: 0.0826 - val_accuracy: 0.9800\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0778 - accuracy: 0.9818 - val_loss: 0.0768 - val_accuracy: 0.9826\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0750 - accuracy: 0.9844 - val_loss: 0.0700 - val_accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0746 - accuracy: 0.9828 - val_loss: 0.0982 - val_accuracy: 0.9688\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0708 - accuracy: 0.9844 - val_loss: 0.0643 - val_accuracy: 0.9880\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0698 - accuracy: 0.9842 - val_loss: 0.0652 - val_accuracy: 0.9856\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0669 - accuracy: 0.9870 - val_loss: 0.0817 - val_accuracy: 0.9784\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0657 - accuracy: 0.9866 - val_loss: 0.0687 - val_accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0637 - accuracy: 0.9876 - val_loss: 0.0582 - val_accuracy: 0.9894\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0618 - accuracy: 0.9868 - val_loss: 0.0555 - val_accuracy: 0.9894\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0611 - accuracy: 0.9872 - val_loss: 0.1040 - val_accuracy: 0.9658\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0582 - accuracy: 0.9902 - val_loss: 0.0548 - val_accuracy: 0.9892\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0560 - accuracy: 0.9888 - val_loss: 0.0621 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a6e8d90>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_class.fit(X_train, y_train, epochs=100,\n",
    "                validation_data=(X_valid, y_valid),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                           tensorboard_cb],\n",
    "                workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 3s 11ms/step - loss: 2.3002 - accuracy: 0.0903 - val_loss: 2.2982 - val_accuracy: 0.0892\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2971 - accuracy: 0.0969 - val_loss: 2.2953 - val_accuracy: 0.0948\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2941 - accuracy: 0.1032 - val_loss: 2.2925 - val_accuracy: 0.1010\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2913 - accuracy: 0.1074 - val_loss: 2.2897 - val_accuracy: 0.1080\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.2885 - accuracy: 0.1131 - val_loss: 2.2871 - val_accuracy: 0.1116\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.2857 - accuracy: 0.1176 - val_loss: 2.2844 - val_accuracy: 0.1196\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 4s 35ms/step - loss: 2.2830 - accuracy: 0.1245 - val_loss: 2.2818 - val_accuracy: 0.1226\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 2.2804 - accuracy: 0.1281 - val_loss: 2.2792 - val_accuracy: 0.1254\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2776 - accuracy: 0.1332 - val_loss: 2.2766 - val_accuracy: 0.1308\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2749 - accuracy: 0.1368 - val_loss: 2.2739 - val_accuracy: 0.1346\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2720 - accuracy: 0.1416 - val_loss: 2.2711 - val_accuracy: 0.1404\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 2.2691 - accuracy: 0.1473 - val_loss: 2.2682 - val_accuracy: 0.1446\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.2660 - accuracy: 0.1527 - val_loss: 2.2651 - val_accuracy: 0.1500\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.2628 - accuracy: 0.1578 - val_loss: 2.2619 - val_accuracy: 0.1586\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2595 - accuracy: 0.1695 - val_loss: 2.2585 - val_accuracy: 0.1662\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 2.2559 - accuracy: 0.1746 - val_loss: 2.2550 - val_accuracy: 0.1766\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.2521 - accuracy: 0.1872 - val_loss: 2.2512 - val_accuracy: 0.1846\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 3s 27ms/step - loss: 2.2481 - accuracy: 0.1953 - val_loss: 2.2472 - val_accuracy: 0.1928\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.2439 - accuracy: 0.2010 - val_loss: 2.2430 - val_accuracy: 0.2014\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 2.2394 - accuracy: 0.2127 - val_loss: 2.2385 - val_accuracy: 0.2128\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 2.2347 - accuracy: 0.2232 - val_loss: 2.2338 - val_accuracy: 0.2194\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2297 - accuracy: 0.2283 - val_loss: 2.2288 - val_accuracy: 0.2278\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2245 - accuracy: 0.2379 - val_loss: 2.2235 - val_accuracy: 0.2402\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2188 - accuracy: 0.2478 - val_loss: 2.2178 - val_accuracy: 0.2472\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2129 - accuracy: 0.2586 - val_loss: 2.2118 - val_accuracy: 0.2536\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2066 - accuracy: 0.2646 - val_loss: 2.2055 - val_accuracy: 0.2598\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1999 - accuracy: 0.2703 - val_loss: 2.1987 - val_accuracy: 0.2684\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.1927 - accuracy: 0.2814 - val_loss: 2.1914 - val_accuracy: 0.2794\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1850 - accuracy: 0.2910 - val_loss: 2.1836 - val_accuracy: 0.2876\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1767 - accuracy: 0.2985 - val_loss: 2.1752 - val_accuracy: 0.2984\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1678 - accuracy: 0.3117 - val_loss: 2.1662 - val_accuracy: 0.3054\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1582 - accuracy: 0.3165 - val_loss: 2.1565 - val_accuracy: 0.3170\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1479 - accuracy: 0.3294 - val_loss: 2.1460 - val_accuracy: 0.3264\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1367 - accuracy: 0.3375 - val_loss: 2.1349 - val_accuracy: 0.3334\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1248 - accuracy: 0.3450 - val_loss: 2.1228 - val_accuracy: 0.3410\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1119 - accuracy: 0.3519 - val_loss: 2.1099 - val_accuracy: 0.3482\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0981 - accuracy: 0.3585 - val_loss: 2.0959 - val_accuracy: 0.3568\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0832 - accuracy: 0.3678 - val_loss: 2.0807 - val_accuracy: 0.3662\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0670 - accuracy: 0.3756 - val_loss: 2.0644 - val_accuracy: 0.3732\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0495 - accuracy: 0.3810 - val_loss: 2.0465 - val_accuracy: 0.3788\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0305 - accuracy: 0.3906 - val_loss: 2.0275 - val_accuracy: 0.3846\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0102 - accuracy: 0.3966 - val_loss: 2.0071 - val_accuracy: 0.3936\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.9885 - accuracy: 0.4062 - val_loss: 1.9853 - val_accuracy: 0.4034\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.9653 - accuracy: 0.4146 - val_loss: 1.9617 - val_accuracy: 0.4084\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.9404 - accuracy: 0.4185 - val_loss: 1.9369 - val_accuracy: 0.4132\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9143 - accuracy: 0.4239 - val_loss: 1.9106 - val_accuracy: 0.4218\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8865 - accuracy: 0.4347 - val_loss: 1.8829 - val_accuracy: 0.4266\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8573 - accuracy: 0.4383 - val_loss: 1.8537 - val_accuracy: 0.4342\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8268 - accuracy: 0.4449 - val_loss: 1.8235 - val_accuracy: 0.4466\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7953 - accuracy: 0.4614 - val_loss: 1.7920 - val_accuracy: 0.4626\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.7623 - accuracy: 0.4803 - val_loss: 1.7592 - val_accuracy: 0.4734\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7282 - accuracy: 0.4875 - val_loss: 1.7255 - val_accuracy: 0.4860\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.6931 - accuracy: 0.5035 - val_loss: 1.6904 - val_accuracy: 0.5028\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.6566 - accuracy: 0.5182 - val_loss: 1.6544 - val_accuracy: 0.5134\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.6191 - accuracy: 0.5290 - val_loss: 1.6173 - val_accuracy: 0.5318\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.5806 - accuracy: 0.5488 - val_loss: 1.5791 - val_accuracy: 0.5438\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.5411 - accuracy: 0.5665 - val_loss: 1.5401 - val_accuracy: 0.5592\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5006 - accuracy: 0.5743 - val_loss: 1.5007 - val_accuracy: 0.5788\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4597 - accuracy: 0.5947 - val_loss: 1.4604 - val_accuracy: 0.5932\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4188 - accuracy: 0.6094 - val_loss: 1.4199 - val_accuracy: 0.6090\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.3775 - accuracy: 0.6226 - val_loss: 1.3798 - val_accuracy: 0.6212\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.3362 - accuracy: 0.6403 - val_loss: 1.3390 - val_accuracy: 0.6346\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2954 - accuracy: 0.6502 - val_loss: 1.2994 - val_accuracy: 0.6530\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2551 - accuracy: 0.6748 - val_loss: 1.2606 - val_accuracy: 0.6620\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2159 - accuracy: 0.6820 - val_loss: 1.2223 - val_accuracy: 0.6788\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1774 - accuracy: 0.6943 - val_loss: 1.1853 - val_accuracy: 0.6894\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1402 - accuracy: 0.7063 - val_loss: 1.1499 - val_accuracy: 0.6950\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1043 - accuracy: 0.7129 - val_loss: 1.1160 - val_accuracy: 0.7080\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0705 - accuracy: 0.7225 - val_loss: 1.0838 - val_accuracy: 0.7268\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0379 - accuracy: 0.7423 - val_loss: 1.0524 - val_accuracy: 0.7280\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0070 - accuracy: 0.7402 - val_loss: 1.0240 - val_accuracy: 0.7396\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9781 - accuracy: 0.7546 - val_loss: 0.9974 - val_accuracy: 0.7418\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9507 - accuracy: 0.7600 - val_loss: 0.9709 - val_accuracy: 0.7544\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.9249 - accuracy: 0.7675 - val_loss: 0.9445 - val_accuracy: 0.7544\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8997 - accuracy: 0.7726 - val_loss: 0.9212 - val_accuracy: 0.7652\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8762 - accuracy: 0.7747 - val_loss: 0.8988 - val_accuracy: 0.7628\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8538 - accuracy: 0.7825 - val_loss: 0.8775 - val_accuracy: 0.7656\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8329 - accuracy: 0.7885 - val_loss: 0.8587 - val_accuracy: 0.7714\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8129 - accuracy: 0.7912 - val_loss: 0.8390 - val_accuracy: 0.7762\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7942 - accuracy: 0.7921 - val_loss: 0.8209 - val_accuracy: 0.7772\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7759 - accuracy: 0.7954 - val_loss: 0.8038 - val_accuracy: 0.7796\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7586 - accuracy: 0.7984 - val_loss: 0.7881 - val_accuracy: 0.7870\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7423 - accuracy: 0.8035 - val_loss: 0.7743 - val_accuracy: 0.7916\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7274 - accuracy: 0.8059 - val_loss: 0.7573 - val_accuracy: 0.7914\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7119 - accuracy: 0.8089 - val_loss: 0.7439 - val_accuracy: 0.8004\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6980 - accuracy: 0.8155 - val_loss: 0.7313 - val_accuracy: 0.7960\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6843 - accuracy: 0.8146 - val_loss: 0.7181 - val_accuracy: 0.7974\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6715 - accuracy: 0.8194 - val_loss: 0.7049 - val_accuracy: 0.8090\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6592 - accuracy: 0.8239 - val_loss: 0.6946 - val_accuracy: 0.8060\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6471 - accuracy: 0.8230 - val_loss: 0.6825 - val_accuracy: 0.8128\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6366 - accuracy: 0.8263 - val_loss: 0.6713 - val_accuracy: 0.8142\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6247 - accuracy: 0.8299 - val_loss: 0.6625 - val_accuracy: 0.8090\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6147 - accuracy: 0.8260 - val_loss: 0.6511 - val_accuracy: 0.8234\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6043 - accuracy: 0.8365 - val_loss: 0.6416 - val_accuracy: 0.8242\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5951 - accuracy: 0.8365 - val_loss: 0.6344 - val_accuracy: 0.8228\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5860 - accuracy: 0.8377 - val_loss: 0.6247 - val_accuracy: 0.8272\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5766 - accuracy: 0.8425 - val_loss: 0.6177 - val_accuracy: 0.8282\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5687 - accuracy: 0.8449 - val_loss: 0.6080 - val_accuracy: 0.8332\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.5595 - accuracy: 0.8464 - val_loss: 0.6005 - val_accuracy: 0.8338\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5524 - accuracy: 0.8479 - val_loss: 0.5916 - val_accuracy: 0.8390\n",
      "53/53 [==============================] - 1s 4ms/step - loss: 0.6828 - accuracy: 0.8152\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.2941 - accuracy: 0.0885 - val_loss: 2.2918 - val_accuracy: 0.0896\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2898 - accuracy: 0.0948 - val_loss: 2.2873 - val_accuracy: 0.0950\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2852 - accuracy: 0.0993 - val_loss: 2.2829 - val_accuracy: 0.1030\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2807 - accuracy: 0.1101 - val_loss: 2.2782 - val_accuracy: 0.1156\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2760 - accuracy: 0.1281 - val_loss: 2.2735 - val_accuracy: 0.1346\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2713 - accuracy: 0.1464 - val_loss: 2.2687 - val_accuracy: 0.1572\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2664 - accuracy: 0.1695 - val_loss: 2.2638 - val_accuracy: 0.1812\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2614 - accuracy: 0.1905 - val_loss: 2.2587 - val_accuracy: 0.1988\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2561 - accuracy: 0.2109 - val_loss: 2.2533 - val_accuracy: 0.2224\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2506 - accuracy: 0.2364 - val_loss: 2.2476 - val_accuracy: 0.2430\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2447 - accuracy: 0.2553 - val_loss: 2.2416 - val_accuracy: 0.2606\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2386 - accuracy: 0.2775 - val_loss: 2.2351 - val_accuracy: 0.2798\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2319 - accuracy: 0.2940 - val_loss: 2.2284 - val_accuracy: 0.2982\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2250 - accuracy: 0.3138 - val_loss: 2.2212 - val_accuracy: 0.3188\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2175 - accuracy: 0.3336 - val_loss: 2.2133 - val_accuracy: 0.3378\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2095 - accuracy: 0.3516 - val_loss: 2.2051 - val_accuracy: 0.3540\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2011 - accuracy: 0.3624 - val_loss: 2.1963 - val_accuracy: 0.3688\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1919 - accuracy: 0.3792 - val_loss: 2.1868 - val_accuracy: 0.3794\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1821 - accuracy: 0.3867 - val_loss: 2.1765 - val_accuracy: 0.3900\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1715 - accuracy: 0.3888 - val_loss: 2.1653 - val_accuracy: 0.3962\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1600 - accuracy: 0.3954 - val_loss: 2.1535 - val_accuracy: 0.4002\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1478 - accuracy: 0.4035 - val_loss: 2.1406 - val_accuracy: 0.4058\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1346 - accuracy: 0.4059 - val_loss: 2.1268 - val_accuracy: 0.4114\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1204 - accuracy: 0.4128 - val_loss: 2.1119 - val_accuracy: 0.4154\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1051 - accuracy: 0.4158 - val_loss: 2.0958 - val_accuracy: 0.4184\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.0885 - accuracy: 0.4185 - val_loss: 2.0784 - val_accuracy: 0.4250\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.0706 - accuracy: 0.4251 - val_loss: 2.0598 - val_accuracy: 0.4302\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0517 - accuracy: 0.4329 - val_loss: 2.0400 - val_accuracy: 0.4412\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0314 - accuracy: 0.4425 - val_loss: 2.0188 - val_accuracy: 0.4488\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0096 - accuracy: 0.4521 - val_loss: 1.9963 - val_accuracy: 0.4562\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9866 - accuracy: 0.4620 - val_loss: 1.9724 - val_accuracy: 0.4670\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9623 - accuracy: 0.4701 - val_loss: 1.9471 - val_accuracy: 0.4780\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9364 - accuracy: 0.4809 - val_loss: 1.9204 - val_accuracy: 0.4940\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9091 - accuracy: 0.4968 - val_loss: 1.8919 - val_accuracy: 0.5060\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8800 - accuracy: 0.5056 - val_loss: 1.8618 - val_accuracy: 0.5144\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8492 - accuracy: 0.5179 - val_loss: 1.8299 - val_accuracy: 0.5280\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8165 - accuracy: 0.5332 - val_loss: 1.7962 - val_accuracy: 0.5368\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7822 - accuracy: 0.5389 - val_loss: 1.7609 - val_accuracy: 0.5478\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7459 - accuracy: 0.5545 - val_loss: 1.7235 - val_accuracy: 0.5586\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7077 - accuracy: 0.5611 - val_loss: 1.6839 - val_accuracy: 0.5740\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.6674 - accuracy: 0.5767 - val_loss: 1.6427 - val_accuracy: 0.5850\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.6254 - accuracy: 0.5860 - val_loss: 1.5994 - val_accuracy: 0.5932\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5815 - accuracy: 0.5992 - val_loss: 1.5547 - val_accuracy: 0.6080\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.5361 - accuracy: 0.6115 - val_loss: 1.5084 - val_accuracy: 0.6214\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4894 - accuracy: 0.6256 - val_loss: 1.4610 - val_accuracy: 0.6296\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4417 - accuracy: 0.6307 - val_loss: 1.4130 - val_accuracy: 0.6472\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.3939 - accuracy: 0.6469 - val_loss: 1.3642 - val_accuracy: 0.6538\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.3456 - accuracy: 0.6550 - val_loss: 1.3169 - val_accuracy: 0.6640\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2983 - accuracy: 0.6709 - val_loss: 1.2691 - val_accuracy: 0.6822\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.2518 - accuracy: 0.6889 - val_loss: 1.2236 - val_accuracy: 0.6966\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2066 - accuracy: 0.6979 - val_loss: 1.1783 - val_accuracy: 0.7096\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1631 - accuracy: 0.7096 - val_loss: 1.1355 - val_accuracy: 0.7176\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.1210 - accuracy: 0.7261 - val_loss: 1.0945 - val_accuracy: 0.7248\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0807 - accuracy: 0.7321 - val_loss: 1.0559 - val_accuracy: 0.7310\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0429 - accuracy: 0.7411 - val_loss: 1.0187 - val_accuracy: 0.7394\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0066 - accuracy: 0.7495 - val_loss: 0.9833 - val_accuracy: 0.7532\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9729 - accuracy: 0.7576 - val_loss: 0.9511 - val_accuracy: 0.7602\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9414 - accuracy: 0.7639 - val_loss: 0.9198 - val_accuracy: 0.7622\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9118 - accuracy: 0.7675 - val_loss: 0.8909 - val_accuracy: 0.7746\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8836 - accuracy: 0.7765 - val_loss: 0.8651 - val_accuracy: 0.7786\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8577 - accuracy: 0.7846 - val_loss: 0.8394 - val_accuracy: 0.7866\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8328 - accuracy: 0.7903 - val_loss: 0.8156 - val_accuracy: 0.7946\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8099 - accuracy: 0.7957 - val_loss: 0.7933 - val_accuracy: 0.7954\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7887 - accuracy: 0.7990 - val_loss: 0.7728 - val_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7684 - accuracy: 0.8023 - val_loss: 0.7530 - val_accuracy: 0.8052\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.7497 - accuracy: 0.8101 - val_loss: 0.7341 - val_accuracy: 0.8082\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7312 - accuracy: 0.8128 - val_loss: 0.7172 - val_accuracy: 0.8142\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7141 - accuracy: 0.8161 - val_loss: 0.7025 - val_accuracy: 0.8176\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6988 - accuracy: 0.8203 - val_loss: 0.6850 - val_accuracy: 0.8218\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6837 - accuracy: 0.8281 - val_loss: 0.6698 - val_accuracy: 0.8226\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6692 - accuracy: 0.8281 - val_loss: 0.6591 - val_accuracy: 0.8264\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6564 - accuracy: 0.8320 - val_loss: 0.6437 - val_accuracy: 0.8284\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6432 - accuracy: 0.8353 - val_loss: 0.6319 - val_accuracy: 0.8332\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6304 - accuracy: 0.8389 - val_loss: 0.6203 - val_accuracy: 0.8306\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6191 - accuracy: 0.8389 - val_loss: 0.6119 - val_accuracy: 0.8356\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6088 - accuracy: 0.8413 - val_loss: 0.6068 - val_accuracy: 0.8374\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5989 - accuracy: 0.8464 - val_loss: 0.5888 - val_accuracy: 0.8418\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5880 - accuracy: 0.8449 - val_loss: 0.5803 - val_accuracy: 0.8460\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5782 - accuracy: 0.8482 - val_loss: 0.5699 - val_accuracy: 0.8496\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5700 - accuracy: 0.8533 - val_loss: 0.5592 - val_accuracy: 0.8490\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5606 - accuracy: 0.8518 - val_loss: 0.5514 - val_accuracy: 0.8528\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5519 - accuracy: 0.8578 - val_loss: 0.5446 - val_accuracy: 0.8526\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5440 - accuracy: 0.8581 - val_loss: 0.5377 - val_accuracy: 0.8550\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5363 - accuracy: 0.8560 - val_loss: 0.5289 - val_accuracy: 0.8586\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.8590 - val_loss: 0.5204 - val_accuracy: 0.8570\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.8596 - val_loss: 0.5156 - val_accuracy: 0.8612\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5146 - accuracy: 0.8638 - val_loss: 0.5092 - val_accuracy: 0.8606\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5072 - accuracy: 0.8632 - val_loss: 0.5008 - val_accuracy: 0.8658\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5012 - accuracy: 0.8668 - val_loss: 0.4942 - val_accuracy: 0.8688\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4947 - accuracy: 0.8701 - val_loss: 0.4888 - val_accuracy: 0.8680\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4890 - accuracy: 0.8701 - val_loss: 0.4833 - val_accuracy: 0.8714\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4825 - accuracy: 0.8722 - val_loss: 0.4775 - val_accuracy: 0.8704\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4770 - accuracy: 0.8731 - val_loss: 0.4748 - val_accuracy: 0.8708\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4716 - accuracy: 0.8731 - val_loss: 0.4674 - val_accuracy: 0.8716\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4663 - accuracy: 0.8731 - val_loss: 0.4657 - val_accuracy: 0.8744\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.8767 - val_loss: 0.4562 - val_accuracy: 0.8764\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4558 - accuracy: 0.8773 - val_loss: 0.4542 - val_accuracy: 0.8758\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4515 - accuracy: 0.8782 - val_loss: 0.4495 - val_accuracy: 0.8780\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4467 - accuracy: 0.8824 - val_loss: 0.4441 - val_accuracy: 0.8774\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4426 - accuracy: 0.8803 - val_loss: 0.4394 - val_accuracy: 0.8778\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8764\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.2995 - accuracy: 0.0678 - val_loss: 2.2971 - val_accuracy: 0.0710\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2956 - accuracy: 0.0720 - val_loss: 2.2934 - val_accuracy: 0.0782\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2918 - accuracy: 0.0813 - val_loss: 2.2897 - val_accuracy: 0.0850\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2881 - accuracy: 0.0819 - val_loss: 2.2860 - val_accuracy: 0.0878\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2843 - accuracy: 0.0885 - val_loss: 2.2823 - val_accuracy: 0.0944\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.2805 - accuracy: 0.0951 - val_loss: 2.2785 - val_accuracy: 0.0998\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2767 - accuracy: 0.1020 - val_loss: 2.2747 - val_accuracy: 0.1086\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2728 - accuracy: 0.1128 - val_loss: 2.2707 - val_accuracy: 0.1198\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2687 - accuracy: 0.1224 - val_loss: 2.2666 - val_accuracy: 0.1292\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2644 - accuracy: 0.1290 - val_loss: 2.2623 - val_accuracy: 0.1428\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2600 - accuracy: 0.1416 - val_loss: 2.2579 - val_accuracy: 0.1578\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2554 - accuracy: 0.1593 - val_loss: 2.2532 - val_accuracy: 0.1742\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2506 - accuracy: 0.1764 - val_loss: 2.2482 - val_accuracy: 0.1916\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2454 - accuracy: 0.1923 - val_loss: 2.2429 - val_accuracy: 0.2050\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2399 - accuracy: 0.2070 - val_loss: 2.2372 - val_accuracy: 0.2172\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2341 - accuracy: 0.2172 - val_loss: 2.2313 - val_accuracy: 0.2278\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2280 - accuracy: 0.2304 - val_loss: 2.2251 - val_accuracy: 0.2400\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2215 - accuracy: 0.2415 - val_loss: 2.2184 - val_accuracy: 0.2468\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2147 - accuracy: 0.2487 - val_loss: 2.2114 - val_accuracy: 0.2526\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2074 - accuracy: 0.2579 - val_loss: 2.2039 - val_accuracy: 0.2600\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1996 - accuracy: 0.2645 - val_loss: 2.1958 - val_accuracy: 0.2676\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1913 - accuracy: 0.2690 - val_loss: 2.1873 - val_accuracy: 0.2740\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1825 - accuracy: 0.2723 - val_loss: 2.1783 - val_accuracy: 0.2782\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1732 - accuracy: 0.2795 - val_loss: 2.1688 - val_accuracy: 0.2842\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1634 - accuracy: 0.2852 - val_loss: 2.1586 - val_accuracy: 0.2926\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1530 - accuracy: 0.2930 - val_loss: 2.1480 - val_accuracy: 0.2994\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1421 - accuracy: 0.3017 - val_loss: 2.1367 - val_accuracy: 0.3052\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1305 - accuracy: 0.3071 - val_loss: 2.1248 - val_accuracy: 0.3116\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1184 - accuracy: 0.3131 - val_loss: 2.1125 - val_accuracy: 0.3172\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1057 - accuracy: 0.3218 - val_loss: 2.0994 - val_accuracy: 0.3238\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0923 - accuracy: 0.3284 - val_loss: 2.0856 - val_accuracy: 0.3304\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0782 - accuracy: 0.3344 - val_loss: 2.0713 - val_accuracy: 0.3404\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0635 - accuracy: 0.3440 - val_loss: 2.0563 - val_accuracy: 0.3484\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0481 - accuracy: 0.3494 - val_loss: 2.0406 - val_accuracy: 0.3570\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0320 - accuracy: 0.3575 - val_loss: 2.0241 - val_accuracy: 0.3614\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0152 - accuracy: 0.3650 - val_loss: 2.0072 - val_accuracy: 0.3680\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.9977 - accuracy: 0.3707 - val_loss: 1.9893 - val_accuracy: 0.3744\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.9793 - accuracy: 0.3755 - val_loss: 1.9705 - val_accuracy: 0.3774\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9601 - accuracy: 0.3803 - val_loss: 1.9509 - val_accuracy: 0.3846\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9399 - accuracy: 0.3884 - val_loss: 1.9304 - val_accuracy: 0.3956\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.9188 - accuracy: 0.3977 - val_loss: 1.9088 - val_accuracy: 0.4014\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8966 - accuracy: 0.4079 - val_loss: 1.8862 - val_accuracy: 0.4076\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8735 - accuracy: 0.4163 - val_loss: 1.8625 - val_accuracy: 0.4184\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8491 - accuracy: 0.4271 - val_loss: 1.8377 - val_accuracy: 0.4260\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8237 - accuracy: 0.4349 - val_loss: 1.8120 - val_accuracy: 0.4366\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7974 - accuracy: 0.4442 - val_loss: 1.7853 - val_accuracy: 0.4496\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.7701 - accuracy: 0.4568 - val_loss: 1.7579 - val_accuracy: 0.4592\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7422 - accuracy: 0.4652 - val_loss: 1.7296 - val_accuracy: 0.4744\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7134 - accuracy: 0.4841 - val_loss: 1.7006 - val_accuracy: 0.4852\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.6840 - accuracy: 0.4922 - val_loss: 1.6711 - val_accuracy: 0.5022\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.6540 - accuracy: 0.5111 - val_loss: 1.6409 - val_accuracy: 0.5144\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.6233 - accuracy: 0.5204 - val_loss: 1.6102 - val_accuracy: 0.5288\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5921 - accuracy: 0.5348 - val_loss: 1.5790 - val_accuracy: 0.5360\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.5605 - accuracy: 0.5426 - val_loss: 1.5474 - val_accuracy: 0.5520\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.5283 - accuracy: 0.5546 - val_loss: 1.5151 - val_accuracy: 0.5662\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4956 - accuracy: 0.5699 - val_loss: 1.4825 - val_accuracy: 0.5722\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4626 - accuracy: 0.5789 - val_loss: 1.4492 - val_accuracy: 0.5844\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.4288 - accuracy: 0.5867 - val_loss: 1.4158 - val_accuracy: 0.5970\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.3951 - accuracy: 0.5990 - val_loss: 1.3823 - val_accuracy: 0.6030\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.3612 - accuracy: 0.6074 - val_loss: 1.3490 - val_accuracy: 0.6102\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.3278 - accuracy: 0.6140 - val_loss: 1.3157 - val_accuracy: 0.6224\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2946 - accuracy: 0.6263 - val_loss: 1.2830 - val_accuracy: 0.6308\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2618 - accuracy: 0.6365 - val_loss: 1.2515 - val_accuracy: 0.6384\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2303 - accuracy: 0.6440 - val_loss: 1.2201 - val_accuracy: 0.6484\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1991 - accuracy: 0.6551 - val_loss: 1.1898 - val_accuracy: 0.6558\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1690 - accuracy: 0.6590 - val_loss: 1.1605 - val_accuracy: 0.6592\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1402 - accuracy: 0.6695 - val_loss: 1.1323 - val_accuracy: 0.6690\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1122 - accuracy: 0.6755 - val_loss: 1.1050 - val_accuracy: 0.6802\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0852 - accuracy: 0.6872 - val_loss: 1.0787 - val_accuracy: 0.6896\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0593 - accuracy: 0.6974 - val_loss: 1.0534 - val_accuracy: 0.6968\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0343 - accuracy: 0.7046 - val_loss: 1.0296 - val_accuracy: 0.7004\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0106 - accuracy: 0.7136 - val_loss: 1.0060 - val_accuracy: 0.7118\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9876 - accuracy: 0.7250 - val_loss: 0.9837 - val_accuracy: 0.7198\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.9655 - accuracy: 0.7307 - val_loss: 0.9627 - val_accuracy: 0.7236\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9447 - accuracy: 0.7289 - val_loss: 0.9424 - val_accuracy: 0.7352\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9244 - accuracy: 0.7382 - val_loss: 0.9238 - val_accuracy: 0.7404\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9056 - accuracy: 0.7442 - val_loss: 0.9049 - val_accuracy: 0.7398\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8869 - accuracy: 0.7490 - val_loss: 0.8873 - val_accuracy: 0.7416\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8694 - accuracy: 0.7507 - val_loss: 0.8701 - val_accuracy: 0.7542\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8523 - accuracy: 0.7597 - val_loss: 0.8540 - val_accuracy: 0.7642\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8363 - accuracy: 0.7624 - val_loss: 0.8391 - val_accuracy: 0.7712\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8207 - accuracy: 0.7780 - val_loss: 0.8229 - val_accuracy: 0.7636\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8057 - accuracy: 0.7690 - val_loss: 0.8084 - val_accuracy: 0.7690\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7910 - accuracy: 0.7774 - val_loss: 0.7963 - val_accuracy: 0.7714\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7775 - accuracy: 0.7792 - val_loss: 0.7815 - val_accuracy: 0.7758\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7639 - accuracy: 0.7831 - val_loss: 0.7690 - val_accuracy: 0.7848\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7511 - accuracy: 0.7861 - val_loss: 0.7590 - val_accuracy: 0.7910\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7387 - accuracy: 0.7951 - val_loss: 0.7448 - val_accuracy: 0.7878\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7272 - accuracy: 0.7981 - val_loss: 0.7352 - val_accuracy: 0.7844\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7153 - accuracy: 0.7969 - val_loss: 0.7231 - val_accuracy: 0.7990\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7046 - accuracy: 0.8017 - val_loss: 0.7128 - val_accuracy: 0.7960\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6938 - accuracy: 0.8074 - val_loss: 0.7026 - val_accuracy: 0.8006\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6835 - accuracy: 0.8113 - val_loss: 0.6926 - val_accuracy: 0.8004\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6735 - accuracy: 0.8104 - val_loss: 0.6841 - val_accuracy: 0.8068\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6644 - accuracy: 0.8158 - val_loss: 0.6745 - val_accuracy: 0.8080\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6548 - accuracy: 0.8212 - val_loss: 0.6663 - val_accuracy: 0.8102\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.8206 - val_loss: 0.6573 - val_accuracy: 0.8132\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6378 - accuracy: 0.8230 - val_loss: 0.6481 - val_accuracy: 0.8164\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6290 - accuracy: 0.8278 - val_loss: 0.6432 - val_accuracy: 0.8128\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6208 - accuracy: 0.8260 - val_loss: 0.6343 - val_accuracy: 0.8246\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.8085\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 2.2334 - accuracy: 0.2517 - val_loss: 2.1526 - val_accuracy: 0.3260\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0182 - accuracy: 0.4116 - val_loss: 1.8454 - val_accuracy: 0.4846\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5860 - accuracy: 0.5548 - val_loss: 1.3501 - val_accuracy: 0.5958\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1255 - accuracy: 0.6775 - val_loss: 0.9886 - val_accuracy: 0.7154\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8426 - accuracy: 0.7591 - val_loss: 0.7869 - val_accuracy: 0.7686\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6700 - accuracy: 0.8113 - val_loss: 0.6962 - val_accuracy: 0.7848\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5555 - accuracy: 0.8428 - val_loss: 0.5514 - val_accuracy: 0.8406\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4833 - accuracy: 0.8641 - val_loss: 0.5276 - val_accuracy: 0.8356\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4354 - accuracy: 0.8680 - val_loss: 0.4764 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3931 - accuracy: 0.8836 - val_loss: 0.4562 - val_accuracy: 0.8574\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3624 - accuracy: 0.8938 - val_loss: 0.3958 - val_accuracy: 0.8866\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3418 - accuracy: 0.8989 - val_loss: 0.4239 - val_accuracy: 0.8698\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3182 - accuracy: 0.9121 - val_loss: 0.5150 - val_accuracy: 0.8428\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3050 - accuracy: 0.9160 - val_loss: 0.3583 - val_accuracy: 0.8944\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2823 - accuracy: 0.9202 - val_loss: 0.3342 - val_accuracy: 0.9044\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2685 - accuracy: 0.9223 - val_loss: 0.3417 - val_accuracy: 0.9030\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2578 - accuracy: 0.9274 - val_loss: 0.3395 - val_accuracy: 0.9018\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2392 - accuracy: 0.9343 - val_loss: 0.3156 - val_accuracy: 0.9070\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2276 - accuracy: 0.9352 - val_loss: 0.7512 - val_accuracy: 0.7746\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2230 - accuracy: 0.9370 - val_loss: 0.3057 - val_accuracy: 0.9130\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2087 - accuracy: 0.9439 - val_loss: 0.2812 - val_accuracy: 0.9210\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1961 - accuracy: 0.9457 - val_loss: 0.2732 - val_accuracy: 0.9232\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1857 - accuracy: 0.9520 - val_loss: 0.2736 - val_accuracy: 0.9238\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.9547 - val_loss: 0.2618 - val_accuracy: 0.9312\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1684 - accuracy: 0.9547 - val_loss: 0.2506 - val_accuracy: 0.9348\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1610 - accuracy: 0.9556 - val_loss: 0.2612 - val_accuracy: 0.9292\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1546 - accuracy: 0.9595 - val_loss: 0.2443 - val_accuracy: 0.9356\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1478 - accuracy: 0.9610 - val_loss: 0.2287 - val_accuracy: 0.9426\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1417 - accuracy: 0.9649 - val_loss: 0.2593 - val_accuracy: 0.9302\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1325 - accuracy: 0.9682 - val_loss: 0.2228 - val_accuracy: 0.9450\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1268 - accuracy: 0.9691 - val_loss: 0.2508 - val_accuracy: 0.9296\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1231 - accuracy: 0.9703 - val_loss: 0.2190 - val_accuracy: 0.9462\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1160 - accuracy: 0.9736 - val_loss: 0.2340 - val_accuracy: 0.9390\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1112 - accuracy: 0.9715 - val_loss: 0.2409 - val_accuracy: 0.9342\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1083 - accuracy: 0.9727 - val_loss: 0.2084 - val_accuracy: 0.9486\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1016 - accuracy: 0.9775 - val_loss: 0.2041 - val_accuracy: 0.9508\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0944 - accuracy: 0.9781 - val_loss: 0.2179 - val_accuracy: 0.9448\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0898 - accuracy: 0.9802 - val_loss: 0.2017 - val_accuracy: 0.9506\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0844 - accuracy: 0.9826 - val_loss: 0.2070 - val_accuracy: 0.9498\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0816 - accuracy: 0.9829 - val_loss: 0.1933 - val_accuracy: 0.9544\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9823 - val_loss: 0.2113 - val_accuracy: 0.9466\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0740 - accuracy: 0.9856 - val_loss: 0.2909 - val_accuracy: 0.9164\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0729 - accuracy: 0.9835 - val_loss: 0.1916 - val_accuracy: 0.9556\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0670 - accuracy: 0.9865 - val_loss: 0.1892 - val_accuracy: 0.9558\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0660 - accuracy: 0.9874 - val_loss: 0.1956 - val_accuracy: 0.9554\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0608 - accuracy: 0.9883 - val_loss: 0.1897 - val_accuracy: 0.9560\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0573 - accuracy: 0.9898 - val_loss: 0.1867 - val_accuracy: 0.9580\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0535 - accuracy: 0.9910 - val_loss: 0.1942 - val_accuracy: 0.9554\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0514 - accuracy: 0.9913 - val_loss: 0.1919 - val_accuracy: 0.9564\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0477 - accuracy: 0.9913 - val_loss: 0.1883 - val_accuracy: 0.9578\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0461 - accuracy: 0.9922 - val_loss: 0.1864 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0438 - accuracy: 0.9922 - val_loss: 0.1829 - val_accuracy: 0.9592\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0414 - accuracy: 0.9934 - val_loss: 0.1852 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0379 - accuracy: 0.9937 - val_loss: 0.1988 - val_accuracy: 0.9552\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0375 - accuracy: 0.9955 - val_loss: 0.1838 - val_accuracy: 0.9584\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0345 - accuracy: 0.9949 - val_loss: 0.2005 - val_accuracy: 0.9558\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0334 - accuracy: 0.9949 - val_loss: 0.1801 - val_accuracy: 0.9616\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0310 - accuracy: 0.9952 - val_loss: 0.1940 - val_accuracy: 0.9564\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0297 - accuracy: 0.9952 - val_loss: 0.2010 - val_accuracy: 0.9532\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9958 - val_loss: 0.1881 - val_accuracy: 0.9612\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0262 - accuracy: 0.9979 - val_loss: 0.1985 - val_accuracy: 0.9590\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0253 - accuracy: 0.9973 - val_loss: 0.1838 - val_accuracy: 0.9622\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0239 - accuracy: 0.9976 - val_loss: 0.1875 - val_accuracy: 0.9608\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.1824 - val_accuracy: 0.9634\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0216 - accuracy: 0.9976 - val_loss: 0.1902 - val_accuracy: 0.9622\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0202 - accuracy: 0.9985 - val_loss: 0.1838 - val_accuracy: 0.9628\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9982 - val_loss: 0.1865 - val_accuracy: 0.9632\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8920\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.2633 - accuracy: 0.1683 - val_loss: 2.2039 - val_accuracy: 0.2428\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1041 - accuracy: 0.3216 - val_loss: 1.9457 - val_accuracy: 0.4452\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7108 - accuracy: 0.5353 - val_loss: 1.4220 - val_accuracy: 0.6264\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1972 - accuracy: 0.6931 - val_loss: 1.0921 - val_accuracy: 0.6438\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8670 - accuracy: 0.7684 - val_loss: 0.7776 - val_accuracy: 0.7642\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6864 - accuracy: 0.8077 - val_loss: 0.6741 - val_accuracy: 0.7966\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5824 - accuracy: 0.8293 - val_loss: 0.5208 - val_accuracy: 0.8532\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5146 - accuracy: 0.8557 - val_loss: 0.7058 - val_accuracy: 0.7644\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4666 - accuracy: 0.8695 - val_loss: 0.5655 - val_accuracy: 0.8156\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4298 - accuracy: 0.8818 - val_loss: 0.4897 - val_accuracy: 0.8556\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4019 - accuracy: 0.8908 - val_loss: 0.4127 - val_accuracy: 0.8806\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3806 - accuracy: 0.8926 - val_loss: 0.6473 - val_accuracy: 0.8050\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3618 - accuracy: 0.8983 - val_loss: 0.3712 - val_accuracy: 0.8940\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3373 - accuracy: 0.9055 - val_loss: 0.3566 - val_accuracy: 0.8984\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3246 - accuracy: 0.9142 - val_loss: 0.3146 - val_accuracy: 0.9136\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3069 - accuracy: 0.9151 - val_loss: 0.3005 - val_accuracy: 0.9210\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2956 - accuracy: 0.9187 - val_loss: 0.3144 - val_accuracy: 0.9108\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2806 - accuracy: 0.9202 - val_loss: 0.4297 - val_accuracy: 0.8642\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2694 - accuracy: 0.9259 - val_loss: 0.2848 - val_accuracy: 0.9188\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2579 - accuracy: 0.9271 - val_loss: 0.3455 - val_accuracy: 0.8920\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2483 - accuracy: 0.9334 - val_loss: 0.2717 - val_accuracy: 0.9250\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2393 - accuracy: 0.9355 - val_loss: 0.2567 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2296 - accuracy: 0.9409 - val_loss: 0.2691 - val_accuracy: 0.9248\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2186 - accuracy: 0.9442 - val_loss: 0.2553 - val_accuracy: 0.9300\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2069 - accuracy: 0.9445 - val_loss: 0.5570 - val_accuracy: 0.8114\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2081 - accuracy: 0.9466 - val_loss: 0.2248 - val_accuracy: 0.9412\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1941 - accuracy: 0.9457 - val_loss: 0.2278 - val_accuracy: 0.9360\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1907 - accuracy: 0.9508 - val_loss: 0.2296 - val_accuracy: 0.9362\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1787 - accuracy: 0.9493 - val_loss: 0.2391 - val_accuracy: 0.9302\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1722 - accuracy: 0.9538 - val_loss: 0.2600 - val_accuracy: 0.9236\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1688 - accuracy: 0.9550 - val_loss: 0.2130 - val_accuracy: 0.9398\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1601 - accuracy: 0.9598 - val_loss: 0.4306 - val_accuracy: 0.8580\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1562 - accuracy: 0.9601 - val_loss: 0.1952 - val_accuracy: 0.9476\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1499 - accuracy: 0.9619 - val_loss: 0.1986 - val_accuracy: 0.9498\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1388 - accuracy: 0.9631 - val_loss: 0.1894 - val_accuracy: 0.9494\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1350 - accuracy: 0.9679 - val_loss: 0.2034 - val_accuracy: 0.9446\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1331 - accuracy: 0.9673 - val_loss: 0.5408 - val_accuracy: 0.8312\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1317 - accuracy: 0.9640 - val_loss: 0.1765 - val_accuracy: 0.9530\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1231 - accuracy: 0.9658 - val_loss: 0.1688 - val_accuracy: 0.9588\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1150 - accuracy: 0.9730 - val_loss: 0.2247 - val_accuracy: 0.9380\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1129 - accuracy: 0.9703 - val_loss: 0.2629 - val_accuracy: 0.9184\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1069 - accuracy: 0.9724 - val_loss: 0.2009 - val_accuracy: 0.9462\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1005 - accuracy: 0.9772 - val_loss: 0.1868 - val_accuracy: 0.9500\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0959 - accuracy: 0.9766 - val_loss: 0.1801 - val_accuracy: 0.9546\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0931 - accuracy: 0.9793 - val_loss: 0.1534 - val_accuracy: 0.9606\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0882 - accuracy: 0.9799 - val_loss: 0.1616 - val_accuracy: 0.9612\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0849 - accuracy: 0.9808 - val_loss: 0.1539 - val_accuracy: 0.9596\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0778 - accuracy: 0.9841 - val_loss: 0.1735 - val_accuracy: 0.9514\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0781 - accuracy: 0.9823 - val_loss: 0.1620 - val_accuracy: 0.9620\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9841 - val_loss: 0.1497 - val_accuracy: 0.9636\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0673 - accuracy: 0.9859 - val_loss: 0.1575 - val_accuracy: 0.9610\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0668 - accuracy: 0.9862 - val_loss: 0.2206 - val_accuracy: 0.9372\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0643 - accuracy: 0.9856 - val_loss: 0.2981 - val_accuracy: 0.9078\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0618 - accuracy: 0.9862 - val_loss: 0.1409 - val_accuracy: 0.9682\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9901 - val_loss: 0.1528 - val_accuracy: 0.9650\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0535 - accuracy: 0.9901 - val_loss: 0.1535 - val_accuracy: 0.9620\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0501 - accuracy: 0.9910 - val_loss: 0.1355 - val_accuracy: 0.9698\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9913 - val_loss: 0.1419 - val_accuracy: 0.9682\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0460 - accuracy: 0.9907 - val_loss: 0.1436 - val_accuracy: 0.9672\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0441 - accuracy: 0.9934 - val_loss: 0.6188 - val_accuracy: 0.8480\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9907 - val_loss: 0.1853 - val_accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0401 - accuracy: 0.9934 - val_loss: 0.2213 - val_accuracy: 0.9412\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0391 - accuracy: 0.9937 - val_loss: 0.1413 - val_accuracy: 0.9682\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0348 - accuracy: 0.9940 - val_loss: 0.1586 - val_accuracy: 0.9588\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9943 - val_loss: 0.1326 - val_accuracy: 0.9726\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0309 - accuracy: 0.9955 - val_loss: 0.1327 - val_accuracy: 0.9712\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0290 - accuracy: 0.9979 - val_loss: 0.1354 - val_accuracy: 0.9708\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9976 - val_loss: 0.1355 - val_accuracy: 0.9718\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0250 - accuracy: 0.9985 - val_loss: 0.1624 - val_accuracy: 0.9624\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0258 - accuracy: 0.9973 - val_loss: 0.1376 - val_accuracy: 0.9710\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0239 - accuracy: 0.9973 - val_loss: 0.1335 - val_accuracy: 0.9706\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0223 - accuracy: 0.9988 - val_loss: 0.1332 - val_accuracy: 0.9708\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0216 - accuracy: 0.9991 - val_loss: 0.1385 - val_accuracy: 0.9718\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0201 - accuracy: 0.9994 - val_loss: 0.1317 - val_accuracy: 0.9724\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.0194 - accuracy: 0.9985 - val_loss: 0.1321 - val_accuracy: 0.9744\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0179 - accuracy: 0.9991 - val_loss: 0.1439 - val_accuracy: 0.9706\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0183 - accuracy: 0.9988 - val_loss: 0.1344 - val_accuracy: 0.9720\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0164 - accuracy: 0.9991 - val_loss: 0.1330 - val_accuracy: 0.9724\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.1486 - val_accuracy: 0.9694\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0151 - accuracy: 0.9994 - val_loss: 0.1327 - val_accuracy: 0.9732\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0147 - accuracy: 0.9994 - val_loss: 0.1342 - val_accuracy: 0.9722\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0138 - accuracy: 0.9994 - val_loss: 0.1423 - val_accuracy: 0.9714\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0132 - accuracy: 0.9997 - val_loss: 0.1530 - val_accuracy: 0.9696\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9994 - val_loss: 0.1446 - val_accuracy: 0.9704\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.9124\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2700 - accuracy: 0.2013 - val_loss: 2.2228 - val_accuracy: 0.2812\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1536 - accuracy: 0.3272 - val_loss: 2.0631 - val_accuracy: 0.3270\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 1.9199 - accuracy: 0.4100 - val_loss: 1.7362 - val_accuracy: 0.5102\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4975 - accuracy: 0.6065 - val_loss: 1.2606 - val_accuracy: 0.6718\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0677 - accuracy: 0.7145 - val_loss: 0.9210 - val_accuracy: 0.7344\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8208 - accuracy: 0.7669 - val_loss: 0.7708 - val_accuracy: 0.7718\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.8041 - val_loss: 0.6486 - val_accuracy: 0.8132\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5981 - accuracy: 0.8218 - val_loss: 0.6012 - val_accuracy: 0.8108\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.8446 - val_loss: 0.5482 - val_accuracy: 0.8434\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4809 - accuracy: 0.8590 - val_loss: 0.4685 - val_accuracy: 0.8722\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.8698 - val_loss: 0.4391 - val_accuracy: 0.8728\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4035 - accuracy: 0.8818 - val_loss: 0.4250 - val_accuracy: 0.8838\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3789 - accuracy: 0.8926 - val_loss: 0.3917 - val_accuracy: 0.8894\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3502 - accuracy: 0.8977 - val_loss: 0.3798 - val_accuracy: 0.8902\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3285 - accuracy: 0.9040 - val_loss: 0.3393 - val_accuracy: 0.9076\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3087 - accuracy: 0.9106 - val_loss: 0.3284 - val_accuracy: 0.9104\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2899 - accuracy: 0.9157 - val_loss: 0.3781 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2736 - accuracy: 0.9238 - val_loss: 0.3125 - val_accuracy: 0.9110\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2678 - accuracy: 0.9241 - val_loss: 0.2844 - val_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2508 - accuracy: 0.9301 - val_loss: 0.4302 - val_accuracy: 0.8662\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2437 - accuracy: 0.9268 - val_loss: 0.2697 - val_accuracy: 0.9276\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2294 - accuracy: 0.9355 - val_loss: 0.2513 - val_accuracy: 0.9316\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2173 - accuracy: 0.9391 - val_loss: 0.3155 - val_accuracy: 0.9016\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2102 - accuracy: 0.9415 - val_loss: 0.2469 - val_accuracy: 0.9308\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2030 - accuracy: 0.9445 - val_loss: 0.2304 - val_accuracy: 0.9366\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1916 - accuracy: 0.9487 - val_loss: 0.2639 - val_accuracy: 0.9242\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1846 - accuracy: 0.9478 - val_loss: 0.2325 - val_accuracy: 0.9334\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1796 - accuracy: 0.9508 - val_loss: 0.2211 - val_accuracy: 0.9384\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1708 - accuracy: 0.9529 - val_loss: 0.2655 - val_accuracy: 0.9200\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1632 - accuracy: 0.9565 - val_loss: 0.2565 - val_accuracy: 0.9244\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1562 - accuracy: 0.9568 - val_loss: 0.2078 - val_accuracy: 0.9428\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1508 - accuracy: 0.9598 - val_loss: 0.1941 - val_accuracy: 0.9490\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1408 - accuracy: 0.9625 - val_loss: 0.4450 - val_accuracy: 0.8686\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.1391 - accuracy: 0.9616 - val_loss: 0.2041 - val_accuracy: 0.9454\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1349 - accuracy: 0.9655 - val_loss: 0.2389 - val_accuracy: 0.9320\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1274 - accuracy: 0.9652 - val_loss: 0.1814 - val_accuracy: 0.9540\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1187 - accuracy: 0.9712 - val_loss: 0.2513 - val_accuracy: 0.9224\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1159 - accuracy: 0.9718 - val_loss: 0.1771 - val_accuracy: 0.9560\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1084 - accuracy: 0.9712 - val_loss: 0.2111 - val_accuracy: 0.9408\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.1065 - accuracy: 0.9760 - val_loss: 0.1710 - val_accuracy: 0.9566\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9766 - val_loss: 0.1689 - val_accuracy: 0.9550\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0932 - accuracy: 0.9796 - val_loss: 0.1623 - val_accuracy: 0.9600\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9784 - val_loss: 0.1915 - val_accuracy: 0.9500\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9799 - val_loss: 0.1676 - val_accuracy: 0.9588\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0810 - accuracy: 0.9805 - val_loss: 0.1544 - val_accuracy: 0.9624\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0767 - accuracy: 0.9838 - val_loss: 0.1553 - val_accuracy: 0.9626\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.9844 - val_loss: 0.2248 - val_accuracy: 0.9320\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0716 - accuracy: 0.9868 - val_loss: 0.1487 - val_accuracy: 0.9660\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0673 - accuracy: 0.9853 - val_loss: 0.1569 - val_accuracy: 0.9624\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0623 - accuracy: 0.9895 - val_loss: 0.1569 - val_accuracy: 0.9620\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9880 - val_loss: 0.1920 - val_accuracy: 0.9510\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0585 - accuracy: 0.9916 - val_loss: 0.1439 - val_accuracy: 0.9682\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0540 - accuracy: 0.9925 - val_loss: 0.1516 - val_accuracy: 0.9650\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0508 - accuracy: 0.9925 - val_loss: 0.1389 - val_accuracy: 0.9690\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0491 - accuracy: 0.9931 - val_loss: 0.1409 - val_accuracy: 0.9676\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0472 - accuracy: 0.9925 - val_loss: 0.1435 - val_accuracy: 0.9682\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0430 - accuracy: 0.9958 - val_loss: 0.1450 - val_accuracy: 0.9664\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0417 - accuracy: 0.9946 - val_loss: 0.2525 - val_accuracy: 0.9286\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0415 - accuracy: 0.9949 - val_loss: 0.1409 - val_accuracy: 0.9692\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0378 - accuracy: 0.9952 - val_loss: 0.1378 - val_accuracy: 0.9692\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0354 - accuracy: 0.9970 - val_loss: 0.1382 - val_accuracy: 0.9698\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0347 - accuracy: 0.9958 - val_loss: 0.1388 - val_accuracy: 0.9692\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0321 - accuracy: 0.9970 - val_loss: 0.1420 - val_accuracy: 0.9694\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0304 - accuracy: 0.9967 - val_loss: 0.1426 - val_accuracy: 0.9696\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0296 - accuracy: 0.9973 - val_loss: 0.1360 - val_accuracy: 0.9708\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9985 - val_loss: 0.1360 - val_accuracy: 0.9706\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0263 - accuracy: 0.9967 - val_loss: 0.1386 - val_accuracy: 0.9706\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9982 - val_loss: 0.1399 - val_accuracy: 0.9694\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0239 - accuracy: 0.9979 - val_loss: 0.1383 - val_accuracy: 0.9700\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9991 - val_loss: 0.9753 - val_accuracy: 0.7674\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0377 - accuracy: 0.9949 - val_loss: 0.1384 - val_accuracy: 0.9696\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0204 - accuracy: 0.9994 - val_loss: 0.1418 - val_accuracy: 0.9718\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0195 - accuracy: 0.9985 - val_loss: 0.1386 - val_accuracy: 0.9700\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0182 - accuracy: 0.9991 - val_loss: 0.1377 - val_accuracy: 0.9716\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0172 - accuracy: 0.9994 - val_loss: 0.1376 - val_accuracy: 0.9706\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9991 - val_loss: 0.1478 - val_accuracy: 0.9686\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.9118\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 5s 12ms/step - loss: 2.2963 - accuracy: 0.0975 - val_loss: 2.2914 - val_accuracy: 0.1006\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2859 - accuracy: 0.1065 - val_loss: 2.2804 - val_accuracy: 0.1108\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 5s 51ms/step - loss: 2.2734 - accuracy: 0.1185 - val_loss: 2.2662 - val_accuracy: 0.1336\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 2.2563 - accuracy: 0.1512 - val_loss: 2.2462 - val_accuracy: 0.1656\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 2.2314 - accuracy: 0.1965 - val_loss: 2.2165 - val_accuracy: 0.2034\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 2.1943 - accuracy: 0.2229 - val_loss: 2.1738 - val_accuracy: 0.2366\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 3s 32ms/step - loss: 2.1423 - accuracy: 0.2535 - val_loss: 2.1155 - val_accuracy: 0.2732\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 4s 32ms/step - loss: 2.0773 - accuracy: 0.2883 - val_loss: 2.0474 - val_accuracy: 0.3008\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 4s 42ms/step - loss: 2.0054 - accuracy: 0.3240 - val_loss: 1.9731 - val_accuracy: 0.3416\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.9214 - accuracy: 0.3684 - val_loss: 1.8808 - val_accuracy: 0.3988\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.8130 - accuracy: 0.4302 - val_loss: 1.7607 - val_accuracy: 0.4744\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 1.6667 - accuracy: 0.4884 - val_loss: 1.5893 - val_accuracy: 0.5280\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.4770 - accuracy: 0.5626 - val_loss: 1.3960 - val_accuracy: 0.5894\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.2602 - accuracy: 0.6457 - val_loss: 1.1755 - val_accuracy: 0.6762\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0478 - accuracy: 0.7084 - val_loss: 0.9903 - val_accuracy: 0.7202\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8831 - accuracy: 0.7438 - val_loss: 0.9216 - val_accuracy: 0.7350\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7719 - accuracy: 0.7726 - val_loss: 1.0358 - val_accuracy: 0.6278\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6917 - accuracy: 0.7963 - val_loss: 0.7371 - val_accuracy: 0.7430\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6317 - accuracy: 0.8122 - val_loss: 0.7108 - val_accuracy: 0.7728\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.5858 - accuracy: 0.8284 - val_loss: 0.6222 - val_accuracy: 0.8184\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.5464 - accuracy: 0.8395 - val_loss: 0.6298 - val_accuracy: 0.7998\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5060 - accuracy: 0.8545 - val_loss: 0.5714 - val_accuracy: 0.8252\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4741 - accuracy: 0.8638 - val_loss: 0.5042 - val_accuracy: 0.8542\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4500 - accuracy: 0.8713 - val_loss: 0.5959 - val_accuracy: 0.8140\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.8728 - val_loss: 0.5048 - val_accuracy: 0.8494\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4078 - accuracy: 0.8830 - val_loss: 0.5712 - val_accuracy: 0.8188\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.3898 - accuracy: 0.8875 - val_loss: 0.4757 - val_accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3733 - accuracy: 0.8962 - val_loss: 0.4220 - val_accuracy: 0.8816\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3532 - accuracy: 0.8995 - val_loss: 0.4260 - val_accuracy: 0.8778\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3347 - accuracy: 0.9043 - val_loss: 0.7308 - val_accuracy: 0.7726\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3278 - accuracy: 0.9049 - val_loss: 0.3936 - val_accuracy: 0.8852\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3102 - accuracy: 0.9115 - val_loss: 0.3656 - val_accuracy: 0.8988\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2951 - accuracy: 0.9175 - val_loss: 0.3703 - val_accuracy: 0.8940\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2847 - accuracy: 0.9166 - val_loss: 0.5352 - val_accuracy: 0.8382\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2756 - accuracy: 0.9211 - val_loss: 0.4697 - val_accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.2627 - accuracy: 0.9259 - val_loss: 0.3652 - val_accuracy: 0.8892\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2507 - accuracy: 0.9298 - val_loss: 0.3489 - val_accuracy: 0.8974\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.2468 - accuracy: 0.9256 - val_loss: 0.3306 - val_accuracy: 0.9036\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2336 - accuracy: 0.9328 - val_loss: 0.3051 - val_accuracy: 0.9158\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2252 - accuracy: 0.9334 - val_loss: 0.3954 - val_accuracy: 0.8842\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2124 - accuracy: 0.9367 - val_loss: 0.3204 - val_accuracy: 0.9072\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 0.2064 - accuracy: 0.9415 - val_loss: 0.2892 - val_accuracy: 0.9182\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.1950 - accuracy: 0.9418 - val_loss: 0.2805 - val_accuracy: 0.9220\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 0.1889 - accuracy: 0.9454 - val_loss: 0.2924 - val_accuracy: 0.9164\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1844 - accuracy: 0.9451 - val_loss: 0.3106 - val_accuracy: 0.9096\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.1782 - accuracy: 0.9484 - val_loss: 0.2657 - val_accuracy: 0.9248\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.1706 - accuracy: 0.9496 - val_loss: 0.2946 - val_accuracy: 0.9106\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.1631 - accuracy: 0.9511 - val_loss: 0.2509 - val_accuracy: 0.9304\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.1574 - accuracy: 0.9517 - val_loss: 0.3183 - val_accuracy: 0.9108\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.1523 - accuracy: 0.9589 - val_loss: 0.2839 - val_accuracy: 0.9204\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1455 - accuracy: 0.9574 - val_loss: 0.2478 - val_accuracy: 0.9328\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9613 - val_loss: 0.2334 - val_accuracy: 0.9364\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 0.1353 - accuracy: 0.9604 - val_loss: 0.2615 - val_accuracy: 0.9236\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1297 - accuracy: 0.9640 - val_loss: 0.2341 - val_accuracy: 0.9348\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9670 - val_loss: 0.6419 - val_accuracy: 0.7964\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1261 - accuracy: 0.9670 - val_loss: 0.2229 - val_accuracy: 0.9416\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1164 - accuracy: 0.9712 - val_loss: 0.2219 - val_accuracy: 0.9406\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1080 - accuracy: 0.9733 - val_loss: 0.2269 - val_accuracy: 0.9370\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.1053 - accuracy: 0.9703 - val_loss: 0.2179 - val_accuracy: 0.9424\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1003 - accuracy: 0.9751 - val_loss: 0.2372 - val_accuracy: 0.9374\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0977 - accuracy: 0.9751 - val_loss: 0.2699 - val_accuracy: 0.9228\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0935 - accuracy: 0.9766 - val_loss: 0.2300 - val_accuracy: 0.9376\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0912 - accuracy: 0.9763 - val_loss: 0.2123 - val_accuracy: 0.9448\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0853 - accuracy: 0.9796 - val_loss: 0.2049 - val_accuracy: 0.9476\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9823 - val_loss: 0.3256 - val_accuracy: 0.9032\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.0829 - accuracy: 0.9787 - val_loss: 0.1951 - val_accuracy: 0.9496\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 0.0746 - accuracy: 0.9835 - val_loss: 0.2270 - val_accuracy: 0.9364\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0733 - accuracy: 0.9829 - val_loss: 0.1947 - val_accuracy: 0.9516\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0688 - accuracy: 0.9829 - val_loss: 0.2190 - val_accuracy: 0.9426\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0644 - accuracy: 0.9859 - val_loss: 0.2122 - val_accuracy: 0.9480\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0628 - accuracy: 0.9865 - val_loss: 0.1962 - val_accuracy: 0.9538\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0622 - accuracy: 0.9859 - val_loss: 0.1932 - val_accuracy: 0.9534\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0582 - accuracy: 0.9880 - val_loss: 0.2007 - val_accuracy: 0.9512\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.0570 - accuracy: 0.9883 - val_loss: 0.1875 - val_accuracy: 0.9540\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0520 - accuracy: 0.9901 - val_loss: 0.2068 - val_accuracy: 0.9450\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0491 - accuracy: 0.9901 - val_loss: 0.1940 - val_accuracy: 0.9542\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 0.0474 - accuracy: 0.9895 - val_loss: 0.1877 - val_accuracy: 0.9548\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0464 - accuracy: 0.9913 - val_loss: 1.7529 - val_accuracy: 0.6984\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0718 - accuracy: 0.9847 - val_loss: 0.1859 - val_accuracy: 0.9570\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0433 - accuracy: 0.9934 - val_loss: 0.2154 - val_accuracy: 0.9474\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0416 - accuracy: 0.9934 - val_loss: 0.1865 - val_accuracy: 0.9584\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.0387 - accuracy: 0.9931 - val_loss: 0.1893 - val_accuracy: 0.9570\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.1990 - val_accuracy: 0.9542\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.0341 - accuracy: 0.9955 - val_loss: 0.1852 - val_accuracy: 0.9594\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0340 - accuracy: 0.9952 - val_loss: 0.2032 - val_accuracy: 0.9530\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.0319 - accuracy: 0.9955 - val_loss: 0.1886 - val_accuracy: 0.9598\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0305 - accuracy: 0.9973 - val_loss: 0.1855 - val_accuracy: 0.9606\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.0291 - accuracy: 0.9967 - val_loss: 0.1946 - val_accuracy: 0.9578\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0276 - accuracy: 0.9976 - val_loss: 0.1904 - val_accuracy: 0.9586\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0259 - accuracy: 0.9973 - val_loss: 0.1875 - val_accuracy: 0.9602\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0260 - accuracy: 0.9973 - val_loss: 0.1862 - val_accuracy: 0.9610\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0240 - accuracy: 0.9976 - val_loss: 0.1943 - val_accuracy: 0.9594\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0229 - accuracy: 0.9979 - val_loss: 0.1912 - val_accuracy: 0.9586\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0216 - accuracy: 0.9979 - val_loss: 0.1919 - val_accuracy: 0.9596\n",
      "53/53 [==============================] - 2s 10ms/step - loss: 0.5359 - accuracy: 0.8842\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 3s 18ms/step - loss: 2.2998 - accuracy: 0.1206 - val_loss: 2.2979 - val_accuracy: 0.1194\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2962 - accuracy: 0.1236 - val_loss: 2.2942 - val_accuracy: 0.1240\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 2.2921 - accuracy: 0.1287 - val_loss: 2.2899 - val_accuracy: 0.1322\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 2s 13ms/step - loss: 2.2872 - accuracy: 0.1368 - val_loss: 2.2845 - val_accuracy: 0.1454\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2812 - accuracy: 0.1584 - val_loss: 2.2780 - val_accuracy: 0.1690\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2737 - accuracy: 0.1743 - val_loss: 2.2693 - val_accuracy: 0.1926\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2633 - accuracy: 0.2130 - val_loss: 2.2569 - val_accuracy: 0.2214\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2486 - accuracy: 0.2364 - val_loss: 2.2394 - val_accuracy: 0.2512\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2279 - accuracy: 0.2667 - val_loss: 2.2152 - val_accuracy: 0.2894\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1991 - accuracy: 0.2952 - val_loss: 2.1809 - val_accuracy: 0.2890\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1589 - accuracy: 0.2988 - val_loss: 2.1336 - val_accuracy: 0.3148\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1050 - accuracy: 0.3222 - val_loss: 2.0729 - val_accuracy: 0.3248\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.0388 - accuracy: 0.3363 - val_loss: 2.0007 - val_accuracy: 0.3404\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9637 - accuracy: 0.3492 - val_loss: 1.9268 - val_accuracy: 0.3644\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8861 - accuracy: 0.3576 - val_loss: 1.8439 - val_accuracy: 0.3660\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8089 - accuracy: 0.3723 - val_loss: 1.7690 - val_accuracy: 0.3828\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7310 - accuracy: 0.3786 - val_loss: 1.6858 - val_accuracy: 0.3890\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.6453 - accuracy: 0.3882 - val_loss: 1.5943 - val_accuracy: 0.3808\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5477 - accuracy: 0.4134 - val_loss: 1.4968 - val_accuracy: 0.4562\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.4409 - accuracy: 0.4737 - val_loss: 1.3750 - val_accuracy: 0.5480\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.3349 - accuracy: 0.5479 - val_loss: 1.2795 - val_accuracy: 0.5508\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2287 - accuracy: 0.5926 - val_loss: 1.1756 - val_accuracy: 0.6210\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1314 - accuracy: 0.6097 - val_loss: 1.0968 - val_accuracy: 0.5804\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0337 - accuracy: 0.6424 - val_loss: 1.0801 - val_accuracy: 0.6168\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.9438 - accuracy: 0.6715 - val_loss: 0.8874 - val_accuracy: 0.7070\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8581 - accuracy: 0.7012 - val_loss: 0.9146 - val_accuracy: 0.6550\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.7860 - accuracy: 0.7249 - val_loss: 0.8196 - val_accuracy: 0.7070\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7325 - accuracy: 0.7576 - val_loss: 0.7855 - val_accuracy: 0.7388\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6811 - accuracy: 0.7768 - val_loss: 0.6543 - val_accuracy: 0.7870\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6414 - accuracy: 0.7954 - val_loss: 0.6354 - val_accuracy: 0.7920\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6057 - accuracy: 0.8074 - val_loss: 0.6137 - val_accuracy: 0.8060\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5752 - accuracy: 0.8224 - val_loss: 0.7170 - val_accuracy: 0.7358\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.8323 - val_loss: 0.5357 - val_accuracy: 0.8266\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.5246 - accuracy: 0.8374 - val_loss: 0.6968 - val_accuracy: 0.7820\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5064 - accuracy: 0.8473 - val_loss: 0.6535 - val_accuracy: 0.7664\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4820 - accuracy: 0.8548 - val_loss: 0.7070 - val_accuracy: 0.7556\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.4613 - accuracy: 0.8653 - val_loss: 0.6453 - val_accuracy: 0.7712\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4492 - accuracy: 0.8653 - val_loss: 0.5160 - val_accuracy: 0.8364\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4233 - accuracy: 0.8746 - val_loss: 0.4686 - val_accuracy: 0.8568\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4049 - accuracy: 0.8800 - val_loss: 0.4509 - val_accuracy: 0.8616\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3996 - accuracy: 0.8824 - val_loss: 0.5683 - val_accuracy: 0.8102\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3807 - accuracy: 0.8929 - val_loss: 0.5147 - val_accuracy: 0.8292\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3702 - accuracy: 0.8923 - val_loss: 0.3817 - val_accuracy: 0.8866\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3488 - accuracy: 0.8998 - val_loss: 0.3585 - val_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3432 - accuracy: 0.8962 - val_loss: 0.5421 - val_accuracy: 0.8268\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3244 - accuracy: 0.9070 - val_loss: 0.3757 - val_accuracy: 0.8946\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3182 - accuracy: 0.9097 - val_loss: 0.3347 - val_accuracy: 0.9042\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3008 - accuracy: 0.9151 - val_loss: 0.3374 - val_accuracy: 0.9032\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2924 - accuracy: 0.9214 - val_loss: 0.5338 - val_accuracy: 0.8272\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2864 - accuracy: 0.9172 - val_loss: 0.3096 - val_accuracy: 0.9100\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2780 - accuracy: 0.9211 - val_loss: 0.3253 - val_accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2657 - accuracy: 0.9262 - val_loss: 0.3070 - val_accuracy: 0.9092\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2543 - accuracy: 0.9277 - val_loss: 0.3421 - val_accuracy: 0.8954\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2482 - accuracy: 0.9334 - val_loss: 2.3379 - val_accuracy: 0.4730\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2731 - accuracy: 0.9214 - val_loss: 0.2793 - val_accuracy: 0.9214\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2279 - accuracy: 0.9391 - val_loss: 0.4540 - val_accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2245 - accuracy: 0.9352 - val_loss: 0.2614 - val_accuracy: 0.9262\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2113 - accuracy: 0.9415 - val_loss: 0.3949 - val_accuracy: 0.8668\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2064 - accuracy: 0.9430 - val_loss: 0.2508 - val_accuracy: 0.9288\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2051 - accuracy: 0.9457 - val_loss: 0.2308 - val_accuracy: 0.9386\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1970 - accuracy: 0.9469 - val_loss: 0.8655 - val_accuracy: 0.7152\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1933 - accuracy: 0.9454 - val_loss: 0.2549 - val_accuracy: 0.9272\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1783 - accuracy: 0.9502 - val_loss: 0.2257 - val_accuracy: 0.9390\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1728 - accuracy: 0.9550 - val_loss: 0.2233 - val_accuracy: 0.9398\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1688 - accuracy: 0.9553 - val_loss: 0.2148 - val_accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1562 - accuracy: 0.9571 - val_loss: 0.2383 - val_accuracy: 0.9304\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1615 - accuracy: 0.9550 - val_loss: 0.2148 - val_accuracy: 0.9418\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1503 - accuracy: 0.9622 - val_loss: 0.7184 - val_accuracy: 0.7896\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1452 - accuracy: 0.9610 - val_loss: 0.2061 - val_accuracy: 0.9442\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1387 - accuracy: 0.9658 - val_loss: 0.3300 - val_accuracy: 0.9026\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1350 - accuracy: 0.9622 - val_loss: 0.1888 - val_accuracy: 0.9490\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1298 - accuracy: 0.9646 - val_loss: 0.1833 - val_accuracy: 0.9522\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1237 - accuracy: 0.9679 - val_loss: 0.1813 - val_accuracy: 0.9522\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1212 - accuracy: 0.9703 - val_loss: 0.2218 - val_accuracy: 0.9362\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1136 - accuracy: 0.9715 - val_loss: 0.3200 - val_accuracy: 0.8990\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1112 - accuracy: 0.9724 - val_loss: 2.0156 - val_accuracy: 0.5950\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1367 - accuracy: 0.9709 - val_loss: 0.1788 - val_accuracy: 0.9536\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0966 - accuracy: 0.9778 - val_loss: 0.1910 - val_accuracy: 0.9466\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.9748 - val_loss: 0.1724 - val_accuracy: 0.9550\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0922 - accuracy: 0.9796 - val_loss: 0.1933 - val_accuracy: 0.9460\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0914 - accuracy: 0.9772 - val_loss: 0.1692 - val_accuracy: 0.9574\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9796 - val_loss: 0.2103 - val_accuracy: 0.9438\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0847 - accuracy: 0.9793 - val_loss: 0.1664 - val_accuracy: 0.9558\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0785 - accuracy: 0.9826 - val_loss: 0.1560 - val_accuracy: 0.9620\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0745 - accuracy: 0.9832 - val_loss: 0.1610 - val_accuracy: 0.9606\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0716 - accuracy: 0.9838 - val_loss: 0.1537 - val_accuracy: 0.9610\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0648 - accuracy: 0.9862 - val_loss: 0.1745 - val_accuracy: 0.9548\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0668 - accuracy: 0.9853 - val_loss: 0.2189 - val_accuracy: 0.9370\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0633 - accuracy: 0.9856 - val_loss: 0.1668 - val_accuracy: 0.9568\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0605 - accuracy: 0.9874 - val_loss: 0.2341 - val_accuracy: 0.9302\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0593 - accuracy: 0.9880 - val_loss: 0.1615 - val_accuracy: 0.9614\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0549 - accuracy: 0.9901 - val_loss: 0.1517 - val_accuracy: 0.9636\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0552 - accuracy: 0.9883 - val_loss: 0.2043 - val_accuracy: 0.9412\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0538 - accuracy: 0.9892 - val_loss: 0.1548 - val_accuracy: 0.9636\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0489 - accuracy: 0.9904 - val_loss: 0.1446 - val_accuracy: 0.9664\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9922 - val_loss: 0.2124 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0470 - accuracy: 0.9904 - val_loss: 0.1481 - val_accuracy: 0.9672\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0428 - accuracy: 0.9928 - val_loss: 0.1462 - val_accuracy: 0.9676\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0407 - accuracy: 0.9922 - val_loss: 0.1467 - val_accuracy: 0.9680\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0410 - accuracy: 0.9916 - val_loss: 0.1503 - val_accuracy: 0.9668\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.9130\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 2.3002 - accuracy: 0.1104 - val_loss: 2.2979 - val_accuracy: 0.1154\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2960 - accuracy: 0.1305 - val_loss: 2.2937 - val_accuracy: 0.1398\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2916 - accuracy: 0.1497 - val_loss: 2.2890 - val_accuracy: 0.1582\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2864 - accuracy: 0.1647 - val_loss: 2.2832 - val_accuracy: 0.1680\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2799 - accuracy: 0.1713 - val_loss: 2.2762 - val_accuracy: 0.1778\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2720 - accuracy: 0.1830 - val_loss: 2.2673 - val_accuracy: 0.1912\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2616 - accuracy: 0.2004 - val_loss: 2.2554 - val_accuracy: 0.2222\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2477 - accuracy: 0.2430 - val_loss: 2.2393 - val_accuracy: 0.2612\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2283 - accuracy: 0.2699 - val_loss: 2.2164 - val_accuracy: 0.2928\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2005 - accuracy: 0.2987 - val_loss: 2.1834 - val_accuracy: 0.3418\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1597 - accuracy: 0.3464 - val_loss: 2.1333 - val_accuracy: 0.3768\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0979 - accuracy: 0.3947 - val_loss: 2.0584 - val_accuracy: 0.3988\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0077 - accuracy: 0.4166 - val_loss: 1.9525 - val_accuracy: 0.4462\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.8851 - accuracy: 0.4652 - val_loss: 1.8123 - val_accuracy: 0.4764\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7266 - accuracy: 0.5045 - val_loss: 1.6395 - val_accuracy: 0.5556\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5322 - accuracy: 0.5858 - val_loss: 1.4556 - val_accuracy: 0.5832\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.3191 - accuracy: 0.6296 - val_loss: 1.2202 - val_accuracy: 0.6374\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.1297 - accuracy: 0.6617 - val_loss: 1.1231 - val_accuracy: 0.6286\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9821 - accuracy: 0.6989 - val_loss: 0.9433 - val_accuracy: 0.6900\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8736 - accuracy: 0.7253 - val_loss: 0.8454 - val_accuracy: 0.7478\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7945 - accuracy: 0.7579 - val_loss: 0.7682 - val_accuracy: 0.7678\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7276 - accuracy: 0.7849 - val_loss: 0.7158 - val_accuracy: 0.7860\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6645 - accuracy: 0.7948 - val_loss: 0.7143 - val_accuracy: 0.7974\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6155 - accuracy: 0.8194 - val_loss: 0.7764 - val_accuracy: 0.7294\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5721 - accuracy: 0.8320 - val_loss: 0.8252 - val_accuracy: 0.7406\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5337 - accuracy: 0.8464 - val_loss: 0.5574 - val_accuracy: 0.8334\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5010 - accuracy: 0.8551 - val_loss: 0.6135 - val_accuracy: 0.8022\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4707 - accuracy: 0.8602 - val_loss: 0.4765 - val_accuracy: 0.8626\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4447 - accuracy: 0.8728 - val_loss: 0.5388 - val_accuracy: 0.8342\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8776 - val_loss: 0.4778 - val_accuracy: 0.8556\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.4125 - accuracy: 0.8854 - val_loss: 0.5546 - val_accuracy: 0.8220\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3954 - accuracy: 0.8899 - val_loss: 0.4928 - val_accuracy: 0.8450\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3793 - accuracy: 0.8863 - val_loss: 0.3969 - val_accuracy: 0.8874\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3670 - accuracy: 0.8899 - val_loss: 0.3998 - val_accuracy: 0.8886\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3521 - accuracy: 0.8992 - val_loss: 0.4676 - val_accuracy: 0.8490\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3416 - accuracy: 0.9007 - val_loss: 0.4197 - val_accuracy: 0.8776\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3364 - accuracy: 0.9037 - val_loss: 0.3851 - val_accuracy: 0.8864\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3225 - accuracy: 0.9076 - val_loss: 0.3441 - val_accuracy: 0.9024\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3080 - accuracy: 0.9169 - val_loss: 0.4112 - val_accuracy: 0.8752\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3010 - accuracy: 0.9148 - val_loss: 0.3449 - val_accuracy: 0.8986\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2917 - accuracy: 0.9175 - val_loss: 0.3260 - val_accuracy: 0.9064\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2817 - accuracy: 0.9193 - val_loss: 0.3149 - val_accuracy: 0.9088\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2737 - accuracy: 0.9244 - val_loss: 0.3261 - val_accuracy: 0.9002\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2697 - accuracy: 0.9232 - val_loss: 0.2916 - val_accuracy: 0.9196\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.2585 - accuracy: 0.9283 - val_loss: 0.3014 - val_accuracy: 0.9154\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2505 - accuracy: 0.9310 - val_loss: 0.2990 - val_accuracy: 0.9178\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 0.2484 - accuracy: 0.9292 - val_loss: 0.3580 - val_accuracy: 0.8924\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.2337 - accuracy: 0.9364 - val_loss: 0.2885 - val_accuracy: 0.9166\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2351 - accuracy: 0.9328 - val_loss: 0.3026 - val_accuracy: 0.9134\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.2250 - accuracy: 0.9358 - val_loss: 0.2763 - val_accuracy: 0.9224\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.2190 - accuracy: 0.9391 - val_loss: 0.3054 - val_accuracy: 0.9082\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.2111 - accuracy: 0.9403 - val_loss: 0.2830 - val_accuracy: 0.9180\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.2076 - accuracy: 0.9409 - val_loss: 0.2822 - val_accuracy: 0.9198\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.2027 - accuracy: 0.9406 - val_loss: 0.2400 - val_accuracy: 0.9338\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.1952 - accuracy: 0.9481 - val_loss: 0.2471 - val_accuracy: 0.9328\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1876 - accuracy: 0.9508 - val_loss: 0.2565 - val_accuracy: 0.9266\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1845 - accuracy: 0.9487 - val_loss: 0.2626 - val_accuracy: 0.9230\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.1803 - accuracy: 0.9508 - val_loss: 0.2507 - val_accuracy: 0.9282\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.1741 - accuracy: 0.9481 - val_loss: 0.2699 - val_accuracy: 0.9220\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.1707 - accuracy: 0.9529 - val_loss: 0.2459 - val_accuracy: 0.9296\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.1676 - accuracy: 0.9532 - val_loss: 0.2547 - val_accuracy: 0.9254\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.1616 - accuracy: 0.9565 - val_loss: 0.2740 - val_accuracy: 0.9160\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.1560 - accuracy: 0.9607 - val_loss: 0.2237 - val_accuracy: 0.9388\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.1493 - accuracy: 0.9598 - val_loss: 0.2220 - val_accuracy: 0.9386\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.1426 - accuracy: 0.9622 - val_loss: 0.2246 - val_accuracy: 0.9336\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.1465 - accuracy: 0.9607 - val_loss: 0.2130 - val_accuracy: 0.9428\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1358 - accuracy: 0.9634 - val_loss: 0.2405 - val_accuracy: 0.9326\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1349 - accuracy: 0.9610 - val_loss: 0.2297 - val_accuracy: 0.9356\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1293 - accuracy: 0.9640 - val_loss: 0.1977 - val_accuracy: 0.9482\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1266 - accuracy: 0.9670 - val_loss: 0.3064 - val_accuracy: 0.9100\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1237 - accuracy: 0.9673 - val_loss: 0.1920 - val_accuracy: 0.9532\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.1190 - accuracy: 0.9703 - val_loss: 0.2152 - val_accuracy: 0.9424\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1156 - accuracy: 0.9709 - val_loss: 0.1905 - val_accuracy: 0.9516\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1082 - accuracy: 0.9718 - val_loss: 0.1905 - val_accuracy: 0.9506\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1070 - accuracy: 0.9742 - val_loss: 0.2700 - val_accuracy: 0.9184\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1034 - accuracy: 0.9733 - val_loss: 0.1972 - val_accuracy: 0.9494\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0986 - accuracy: 0.9775 - val_loss: 0.2180 - val_accuracy: 0.9390\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0991 - accuracy: 0.9757 - val_loss: 0.2288 - val_accuracy: 0.9336\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0930 - accuracy: 0.9790 - val_loss: 0.1928 - val_accuracy: 0.9498\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0915 - accuracy: 0.9784 - val_loss: 0.1754 - val_accuracy: 0.9590\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0875 - accuracy: 0.9781 - val_loss: 0.1929 - val_accuracy: 0.9510\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0837 - accuracy: 0.9808 - val_loss: 0.1721 - val_accuracy: 0.9582\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0787 - accuracy: 0.9835 - val_loss: 0.1821 - val_accuracy: 0.9578\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0772 - accuracy: 0.9826 - val_loss: 0.1674 - val_accuracy: 0.9632\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9841 - val_loss: 0.1779 - val_accuracy: 0.9550\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0718 - accuracy: 0.9832 - val_loss: 0.2090 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9838 - val_loss: 0.1686 - val_accuracy: 0.9624\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0672 - accuracy: 0.9856 - val_loss: 0.1622 - val_accuracy: 0.9638\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0658 - accuracy: 0.9868 - val_loss: 0.1681 - val_accuracy: 0.9594\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0614 - accuracy: 0.9892 - val_loss: 0.1791 - val_accuracy: 0.9562\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0612 - accuracy: 0.9883 - val_loss: 0.2571 - val_accuracy: 0.9260\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0594 - accuracy: 0.9874 - val_loss: 0.1636 - val_accuracy: 0.9652\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0553 - accuracy: 0.9910 - val_loss: 0.1606 - val_accuracy: 0.9640\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0548 - accuracy: 0.9901 - val_loss: 0.1578 - val_accuracy: 0.9648\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0523 - accuracy: 0.9901 - val_loss: 0.1567 - val_accuracy: 0.9658\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0499 - accuracy: 0.9904 - val_loss: 0.1776 - val_accuracy: 0.9554\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0490 - accuracy: 0.9913 - val_loss: 0.1559 - val_accuracy: 0.9668\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0477 - accuracy: 0.9922 - val_loss: 0.1556 - val_accuracy: 0.9672\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0440 - accuracy: 0.9934 - val_loss: 0.1564 - val_accuracy: 0.9658\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9937 - val_loss: 0.1611 - val_accuracy: 0.9676\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.9106\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.2989 - accuracy: 0.0870 - val_loss: 2.2769 - val_accuracy: 0.1688\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2231 - accuracy: 0.2310 - val_loss: 2.1468 - val_accuracy: 0.2908\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0378 - accuracy: 0.3018 - val_loss: 1.9385 - val_accuracy: 0.3286\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.8453 - accuracy: 0.3516 - val_loss: 1.7821 - val_accuracy: 0.3612\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.6998 - accuracy: 0.3885 - val_loss: 1.6528 - val_accuracy: 0.3992\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5712 - accuracy: 0.4452 - val_loss: 1.5827 - val_accuracy: 0.4574\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.4670 - accuracy: 0.5083 - val_loss: 1.4467 - val_accuracy: 0.4976\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.3841 - accuracy: 0.5143 - val_loss: 1.3765 - val_accuracy: 0.5048\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.3142 - accuracy: 0.5308 - val_loss: 1.3184 - val_accuracy: 0.5390\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.2573 - accuracy: 0.5431 - val_loss: 1.2655 - val_accuracy: 0.5380\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2087 - accuracy: 0.5623 - val_loss: 1.2220 - val_accuracy: 0.5486\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1670 - accuracy: 0.5737 - val_loss: 1.1949 - val_accuracy: 0.5602\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1290 - accuracy: 0.5929 - val_loss: 1.1572 - val_accuracy: 0.5818\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0890 - accuracy: 0.6181 - val_loss: 1.1151 - val_accuracy: 0.6160\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0503 - accuracy: 0.6280 - val_loss: 1.0765 - val_accuracy: 0.6202\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0120 - accuracy: 0.6436 - val_loss: 1.0547 - val_accuracy: 0.6430\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9736 - accuracy: 0.6754 - val_loss: 1.0208 - val_accuracy: 0.6636\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9362 - accuracy: 0.6982 - val_loss: 0.9939 - val_accuracy: 0.6584\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9043 - accuracy: 0.7033 - val_loss: 0.9494 - val_accuracy: 0.6854\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8673 - accuracy: 0.7270 - val_loss: 0.9296 - val_accuracy: 0.7214\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8361 - accuracy: 0.7408 - val_loss: 0.8923 - val_accuracy: 0.7136\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8075 - accuracy: 0.7492 - val_loss: 0.8989 - val_accuracy: 0.7072\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7820 - accuracy: 0.7591 - val_loss: 0.8419 - val_accuracy: 0.7412\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7605 - accuracy: 0.7609 - val_loss: 0.8746 - val_accuracy: 0.7162\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7423 - accuracy: 0.7666 - val_loss: 0.8414 - val_accuracy: 0.7566\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7259 - accuracy: 0.7828 - val_loss: 0.8264 - val_accuracy: 0.7524\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7047 - accuracy: 0.7894 - val_loss: 0.7824 - val_accuracy: 0.7702\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6883 - accuracy: 0.7924 - val_loss: 0.8808 - val_accuracy: 0.7156\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6795 - accuracy: 0.7942 - val_loss: 0.7891 - val_accuracy: 0.7752\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6599 - accuracy: 0.8077 - val_loss: 1.1302 - val_accuracy: 0.6472\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6585 - accuracy: 0.7999 - val_loss: 0.7374 - val_accuracy: 0.7822\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6290 - accuracy: 0.8173 - val_loss: 0.7927 - val_accuracy: 0.7602\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6207 - accuracy: 0.8143 - val_loss: 0.7112 - val_accuracy: 0.7960\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.6082 - accuracy: 0.8221 - val_loss: 0.9503 - val_accuracy: 0.7060\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5954 - accuracy: 0.8218 - val_loss: 0.8260 - val_accuracy: 0.7470\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5918 - accuracy: 0.8269 - val_loss: 0.6820 - val_accuracy: 0.8094\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.8338 - val_loss: 0.8396 - val_accuracy: 0.7380\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5717 - accuracy: 0.8320 - val_loss: 1.1999 - val_accuracy: 0.6518\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5671 - accuracy: 0.8380 - val_loss: 0.8163 - val_accuracy: 0.7496\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5528 - accuracy: 0.8356 - val_loss: 1.0084 - val_accuracy: 0.7100\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5502 - accuracy: 0.8389 - val_loss: 0.7360 - val_accuracy: 0.8020\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5372 - accuracy: 0.8434 - val_loss: 0.6763 - val_accuracy: 0.8132\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5314 - accuracy: 0.8455 - val_loss: 0.7808 - val_accuracy: 0.7702\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.5269 - accuracy: 0.8485 - val_loss: 0.9016 - val_accuracy: 0.7276\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5285 - accuracy: 0.8437 - val_loss: 0.7428 - val_accuracy: 0.7694\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5211 - accuracy: 0.8530 - val_loss: 0.6935 - val_accuracy: 0.8142\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5079 - accuracy: 0.8497 - val_loss: 1.1815 - val_accuracy: 0.7274\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5081 - accuracy: 0.8563 - val_loss: 0.7747 - val_accuracy: 0.7732\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.8590 - val_loss: 0.6987 - val_accuracy: 0.8044\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5022 - accuracy: 0.8590 - val_loss: 0.6652 - val_accuracy: 0.8262\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4902 - accuracy: 0.8584 - val_loss: 0.6765 - val_accuracy: 0.8140\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4846 - accuracy: 0.8632 - val_loss: 0.6346 - val_accuracy: 0.8330\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4790 - accuracy: 0.8638 - val_loss: 0.7446 - val_accuracy: 0.7948\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4775 - accuracy: 0.8629 - val_loss: 0.7664 - val_accuracy: 0.7908\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4756 - accuracy: 0.8698 - val_loss: 0.7008 - val_accuracy: 0.8046\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4699 - accuracy: 0.8650 - val_loss: 2.1148 - val_accuracy: 0.5536\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4861 - accuracy: 0.8620 - val_loss: 0.6223 - val_accuracy: 0.8422\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4651 - accuracy: 0.8674 - val_loss: 0.8242 - val_accuracy: 0.7556\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4622 - accuracy: 0.8641 - val_loss: 1.5230 - val_accuracy: 0.6648\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4652 - accuracy: 0.8689 - val_loss: 0.7758 - val_accuracy: 0.7872\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4563 - accuracy: 0.8716 - val_loss: 0.6841 - val_accuracy: 0.8138\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4564 - accuracy: 0.8722 - val_loss: 0.7390 - val_accuracy: 0.8014\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4484 - accuracy: 0.8719 - val_loss: 0.6796 - val_accuracy: 0.8296\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.8752 - val_loss: 0.8948 - val_accuracy: 0.7496\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4446 - accuracy: 0.8677 - val_loss: 0.8409 - val_accuracy: 0.7830\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4402 - accuracy: 0.8722 - val_loss: 0.6234 - val_accuracy: 0.8426\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4276 - accuracy: 0.8788 - val_loss: 0.9923 - val_accuracy: 0.7070\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.3830 - accuracy: 0.6527\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.2273 - accuracy: 0.1836 - val_loss: 2.1169 - val_accuracy: 0.2138\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0262 - accuracy: 0.2070 - val_loss: 1.9528 - val_accuracy: 0.2122\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8787 - accuracy: 0.2235 - val_loss: 1.8015 - val_accuracy: 0.2692\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7486 - accuracy: 0.3027 - val_loss: 1.6779 - val_accuracy: 0.3320\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.6327 - accuracy: 0.3375 - val_loss: 1.6651 - val_accuracy: 0.3042\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.5495 - accuracy: 0.3657 - val_loss: 1.5036 - val_accuracy: 0.3736\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4855 - accuracy: 0.3717 - val_loss: 1.5088 - val_accuracy: 0.3854\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4428 - accuracy: 0.3879 - val_loss: 1.4147 - val_accuracy: 0.4104\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.4037 - accuracy: 0.4077 - val_loss: 1.3915 - val_accuracy: 0.3984\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.3639 - accuracy: 0.4269 - val_loss: 1.3704 - val_accuracy: 0.4050\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.3309 - accuracy: 0.4590 - val_loss: 1.6305 - val_accuracy: 0.3924\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.3090 - accuracy: 0.4827 - val_loss: 1.2759 - val_accuracy: 0.5154\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2657 - accuracy: 0.5041 - val_loss: 1.3036 - val_accuracy: 0.5056\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2327 - accuracy: 0.5338 - val_loss: 1.2582 - val_accuracy: 0.5186\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.2092 - accuracy: 0.5533 - val_loss: 1.2873 - val_accuracy: 0.5192\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.1646 - accuracy: 0.5857 - val_loss: 1.3164 - val_accuracy: 0.5092\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1304 - accuracy: 0.5989 - val_loss: 1.4131 - val_accuracy: 0.4726\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.0465 - accuracy: 0.6397 - val_loss: 1.0330 - val_accuracy: 0.6646\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9649 - accuracy: 0.6805 - val_loss: 1.0483 - val_accuracy: 0.5916\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9044 - accuracy: 0.6943 - val_loss: 0.9127 - val_accuracy: 0.6596\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8393 - accuracy: 0.7111 - val_loss: 0.8266 - val_accuracy: 0.7232\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.8079 - accuracy: 0.7321 - val_loss: 0.8644 - val_accuracy: 0.6908\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7751 - accuracy: 0.7384 - val_loss: 1.0289 - val_accuracy: 0.6436\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7554 - accuracy: 0.7537 - val_loss: 0.9767 - val_accuracy: 0.6354\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7203 - accuracy: 0.7687 - val_loss: 0.7384 - val_accuracy: 0.7562\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7186 - accuracy: 0.7726 - val_loss: 0.7889 - val_accuracy: 0.7322\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7095 - accuracy: 0.7678 - val_loss: 0.7079 - val_accuracy: 0.7766\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6757 - accuracy: 0.7894 - val_loss: 0.8189 - val_accuracy: 0.7320\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6630 - accuracy: 0.7990 - val_loss: 0.7250 - val_accuracy: 0.7640\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6437 - accuracy: 0.8032 - val_loss: 0.8883 - val_accuracy: 0.6946\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.6377 - accuracy: 0.8017 - val_loss: 0.6724 - val_accuracy: 0.7932\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6220 - accuracy: 0.8161 - val_loss: 0.7367 - val_accuracy: 0.7614\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.6155 - accuracy: 0.8095 - val_loss: 0.9117 - val_accuracy: 0.7010\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6073 - accuracy: 0.8158 - val_loss: 0.6815 - val_accuracy: 0.7870\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5967 - accuracy: 0.8215 - val_loss: 0.7960 - val_accuracy: 0.7692\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5761 - accuracy: 0.8242 - val_loss: 0.6239 - val_accuracy: 0.8152\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5603 - accuracy: 0.8326 - val_loss: 0.6811 - val_accuracy: 0.7898\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5609 - accuracy: 0.8290 - val_loss: 0.6357 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5507 - accuracy: 0.8413 - val_loss: 0.6214 - val_accuracy: 0.8052\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5370 - accuracy: 0.8386 - val_loss: 0.6610 - val_accuracy: 0.7818\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5349 - accuracy: 0.8389 - val_loss: 1.4992 - val_accuracy: 0.6028\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5333 - accuracy: 0.8374 - val_loss: 0.8985 - val_accuracy: 0.6896\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5325 - accuracy: 0.8386 - val_loss: 0.5719 - val_accuracy: 0.8356\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5140 - accuracy: 0.8401 - val_loss: 0.5620 - val_accuracy: 0.8386\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5079 - accuracy: 0.8527 - val_loss: 0.6610 - val_accuracy: 0.7940\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4994 - accuracy: 0.8491 - val_loss: 0.5739 - val_accuracy: 0.8342\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5001 - accuracy: 0.8434 - val_loss: 0.8900 - val_accuracy: 0.7332\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4980 - accuracy: 0.8527 - val_loss: 0.5848 - val_accuracy: 0.8226\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8551 - val_loss: 1.3698 - val_accuracy: 0.6012\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4968 - accuracy: 0.8506 - val_loss: 0.6743 - val_accuracy: 0.7760\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4655 - accuracy: 0.8596 - val_loss: 0.5778 - val_accuracy: 0.8234\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.8608 - val_loss: 0.5372 - val_accuracy: 0.8416\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4619 - accuracy: 0.8530 - val_loss: 0.6129 - val_accuracy: 0.8182\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4602 - accuracy: 0.8617 - val_loss: 0.5408 - val_accuracy: 0.8446\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4591 - accuracy: 0.8623 - val_loss: 0.7308 - val_accuracy: 0.7774\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4568 - accuracy: 0.8569 - val_loss: 0.5050 - val_accuracy: 0.8576\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4585 - accuracy: 0.8566 - val_loss: 0.6125 - val_accuracy: 0.8174\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4366 - accuracy: 0.8623 - val_loss: 1.0848 - val_accuracy: 0.6848\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4347 - accuracy: 0.8650 - val_loss: 0.5088 - val_accuracy: 0.8590\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4304 - accuracy: 0.8728 - val_loss: 0.7441 - val_accuracy: 0.7832\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4492 - accuracy: 0.8584 - val_loss: 0.6762 - val_accuracy: 0.7956\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4297 - accuracy: 0.8674 - val_loss: 0.7574 - val_accuracy: 0.7848\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4220 - accuracy: 0.8743 - val_loss: 0.5250 - val_accuracy: 0.8508\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4207 - accuracy: 0.8644 - val_loss: 0.5095 - val_accuracy: 0.8582\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8725 - val_loss: 1.0028 - val_accuracy: 0.7052\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4047 - accuracy: 0.8749 - val_loss: 0.8962 - val_accuracy: 0.7454\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.1394 - accuracy: 0.7121\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 2.2988 - accuracy: 0.1128 - val_loss: 2.2913 - val_accuracy: 0.1146\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2740 - accuracy: 0.1209 - val_loss: 2.2409 - val_accuracy: 0.1186\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1848 - accuracy: 0.1803 - val_loss: 2.1259 - val_accuracy: 0.1948\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0860 - accuracy: 0.2052 - val_loss: 2.0401 - val_accuracy: 0.2196\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0082 - accuracy: 0.2457 - val_loss: 1.9597 - val_accuracy: 0.2844\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9058 - accuracy: 0.3137 - val_loss: 1.8324 - val_accuracy: 0.3382\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.7565 - accuracy: 0.3590 - val_loss: 1.6740 - val_accuracy: 0.3660\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.5914 - accuracy: 0.3986 - val_loss: 1.5384 - val_accuracy: 0.4422\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4416 - accuracy: 0.4538 - val_loss: 1.4076 - val_accuracy: 0.4664\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 1.3224 - accuracy: 0.5108 - val_loss: 1.3527 - val_accuracy: 0.4888\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.2181 - accuracy: 0.5549 - val_loss: 1.2242 - val_accuracy: 0.5598\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 1.1367 - accuracy: 0.6080 - val_loss: 1.0910 - val_accuracy: 0.6126\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0715 - accuracy: 0.6281 - val_loss: 1.1620 - val_accuracy: 0.5742\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0268 - accuracy: 0.6494 - val_loss: 1.0019 - val_accuracy: 0.6456\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9897 - accuracy: 0.6512 - val_loss: 0.9749 - val_accuracy: 0.6616\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9537 - accuracy: 0.6683 - val_loss: 1.0957 - val_accuracy: 0.6026\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.9314 - accuracy: 0.6764 - val_loss: 0.9826 - val_accuracy: 0.6452\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.9074 - accuracy: 0.6884 - val_loss: 0.9231 - val_accuracy: 0.6766\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8845 - accuracy: 0.7028 - val_loss: 0.9060 - val_accuracy: 0.6876\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8653 - accuracy: 0.7103 - val_loss: 1.0038 - val_accuracy: 0.6334\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.8400 - accuracy: 0.7208 - val_loss: 0.8716 - val_accuracy: 0.7036\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8201 - accuracy: 0.7223 - val_loss: 0.8207 - val_accuracy: 0.7256\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7991 - accuracy: 0.7367 - val_loss: 0.9591 - val_accuracy: 0.6676\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7800 - accuracy: 0.7448 - val_loss: 0.9076 - val_accuracy: 0.6674\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7665 - accuracy: 0.7496 - val_loss: 0.9761 - val_accuracy: 0.6874\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7484 - accuracy: 0.7564 - val_loss: 0.8070 - val_accuracy: 0.7386\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7298 - accuracy: 0.7645 - val_loss: 0.7447 - val_accuracy: 0.7596\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7228 - accuracy: 0.7681 - val_loss: 0.8275 - val_accuracy: 0.7362\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7084 - accuracy: 0.7732 - val_loss: 0.8126 - val_accuracy: 0.7332\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7783 - val_loss: 1.1826 - val_accuracy: 0.6256\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6895 - accuracy: 0.7852 - val_loss: 0.7803 - val_accuracy: 0.7394\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.6719 - accuracy: 0.7873 - val_loss: 0.7549 - val_accuracy: 0.7582\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6621 - accuracy: 0.7966 - val_loss: 0.8283 - val_accuracy: 0.7336\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.6546 - accuracy: 0.7978 - val_loss: 0.7474 - val_accuracy: 0.7658\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6485 - accuracy: 0.7960 - val_loss: 1.0593 - val_accuracy: 0.6580\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6490 - accuracy: 0.7984 - val_loss: 0.7732 - val_accuracy: 0.7510\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6333 - accuracy: 0.8020 - val_loss: 0.7334 - val_accuracy: 0.7652\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6261 - accuracy: 0.8140 - val_loss: 0.6941 - val_accuracy: 0.7826\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6178 - accuracy: 0.8134 - val_loss: 0.7087 - val_accuracy: 0.7804\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6053 - accuracy: 0.8167 - val_loss: 0.6975 - val_accuracy: 0.7830\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6016 - accuracy: 0.8239 - val_loss: 0.6308 - val_accuracy: 0.8138\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5956 - accuracy: 0.8122 - val_loss: 0.6572 - val_accuracy: 0.7978\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5812 - accuracy: 0.8266 - val_loss: 1.1222 - val_accuracy: 0.6602\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5783 - accuracy: 0.8266 - val_loss: 1.5262 - val_accuracy: 0.5724\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5938 - accuracy: 0.8218 - val_loss: 0.6560 - val_accuracy: 0.8018\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5696 - accuracy: 0.8269 - val_loss: 0.7841 - val_accuracy: 0.7516\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5603 - accuracy: 0.8290 - val_loss: 0.6076 - val_accuracy: 0.8166\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5464 - accuracy: 0.8374 - val_loss: 0.9073 - val_accuracy: 0.7246\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5571 - accuracy: 0.8341 - val_loss: 0.7138 - val_accuracy: 0.7738\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5399 - accuracy: 0.8338 - val_loss: 0.6276 - val_accuracy: 0.8108\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.8407 - val_loss: 0.6484 - val_accuracy: 0.8044\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5283 - accuracy: 0.8437 - val_loss: 0.7089 - val_accuracy: 0.7708\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.8452 - val_loss: 0.8660 - val_accuracy: 0.7392\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5167 - accuracy: 0.8488 - val_loss: 0.6096 - val_accuracy: 0.8130\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5109 - accuracy: 0.8482 - val_loss: 0.5782 - val_accuracy: 0.8352\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5121 - accuracy: 0.8530 - val_loss: 0.5909 - val_accuracy: 0.8284\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5034 - accuracy: 0.8497 - val_loss: 0.5484 - val_accuracy: 0.8466\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4891 - accuracy: 0.8593 - val_loss: 1.0290 - val_accuracy: 0.6924\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4881 - accuracy: 0.8560 - val_loss: 0.6729 - val_accuracy: 0.7922\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4742 - accuracy: 0.8590 - val_loss: 1.9837 - val_accuracy: 0.5390\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4931 - accuracy: 0.8500 - val_loss: 0.5782 - val_accuracy: 0.8288\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4733 - accuracy: 0.8593 - val_loss: 0.6984 - val_accuracy: 0.7956\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.8671 - val_loss: 0.8101 - val_accuracy: 0.7556\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4634 - accuracy: 0.8617 - val_loss: 0.8457 - val_accuracy: 0.7474\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4488 - accuracy: 0.8683 - val_loss: 0.5256 - val_accuracy: 0.8554\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4428 - accuracy: 0.8701 - val_loss: 0.5610 - val_accuracy: 0.8370\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.4404 - accuracy: 0.8680 - val_loss: 0.7519 - val_accuracy: 0.7602\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.4412 - accuracy: 0.8725 - val_loss: 0.6451 - val_accuracy: 0.8178\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.4365 - accuracy: 0.8689 - val_loss: 0.6453 - val_accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.4278 - accuracy: 0.8704 - val_loss: 0.5258 - val_accuracy: 0.8550\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8725 - val_loss: 0.5739 - val_accuracy: 0.8326\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.4198 - accuracy: 0.8764 - val_loss: 0.5671 - val_accuracy: 0.8310\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4125 - accuracy: 0.8800 - val_loss: 0.6562 - val_accuracy: 0.8030\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 3s 27ms/step - loss: 0.4183 - accuracy: 0.8797 - val_loss: 0.5120 - val_accuracy: 0.8536\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4099 - accuracy: 0.8833 - val_loss: 0.8627 - val_accuracy: 0.7536\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.4063 - accuracy: 0.8806 - val_loss: 0.5019 - val_accuracy: 0.8594\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.3955 - accuracy: 0.8884 - val_loss: 0.5035 - val_accuracy: 0.8606\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3914 - accuracy: 0.8845 - val_loss: 0.5404 - val_accuracy: 0.8426\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3965 - accuracy: 0.8755 - val_loss: 0.5188 - val_accuracy: 0.8512\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3835 - accuracy: 0.8860 - val_loss: 0.6452 - val_accuracy: 0.8018\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3921 - accuracy: 0.8860 - val_loss: 0.6255 - val_accuracy: 0.8174\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3825 - accuracy: 0.8821 - val_loss: 0.5164 - val_accuracy: 0.8592\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.3766 - accuracy: 0.8914 - val_loss: 0.4981 - val_accuracy: 0.8654\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.3746 - accuracy: 0.8896 - val_loss: 0.7636 - val_accuracy: 0.7834\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 0.3687 - accuracy: 0.8923 - val_loss: 0.6271 - val_accuracy: 0.8224\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 0.3717 - accuracy: 0.8833 - val_loss: 0.4996 - val_accuracy: 0.8654\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.3747 - accuracy: 0.8914 - val_loss: 1.2036 - val_accuracy: 0.6842\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.3740 - accuracy: 0.8896 - val_loss: 2.1127 - val_accuracy: 0.5634\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 4s 38ms/step - loss: 0.3793 - accuracy: 0.8872 - val_loss: 0.5180 - val_accuracy: 0.8554\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 0.3499 - accuracy: 0.8953 - val_loss: 0.6091 - val_accuracy: 0.8276\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.3548 - accuracy: 0.8965 - val_loss: 0.5339 - val_accuracy: 0.8492\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 0.3525 - accuracy: 0.8878 - val_loss: 0.5153 - val_accuracy: 0.8578\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3455 - accuracy: 0.8959 - val_loss: 0.9703 - val_accuracy: 0.7234\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 1.3236 - accuracy: 0.6879\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 3s 23ms/step - loss: 2.3357 - accuracy: 0.1125 - val_loss: 2.2899 - val_accuracy: 0.1464\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2612 - accuracy: 0.1797 - val_loss: 2.2361 - val_accuracy: 0.2196\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2099 - accuracy: 0.2433 - val_loss: 2.1862 - val_accuracy: 0.2686\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.1559 - accuracy: 0.2865 - val_loss: 2.1290 - val_accuracy: 0.3044\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0938 - accuracy: 0.3309 - val_loss: 2.0652 - val_accuracy: 0.3446\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0279 - accuracy: 0.3627 - val_loss: 1.9997 - val_accuracy: 0.3850\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9609 - accuracy: 0.4077 - val_loss: 1.9345 - val_accuracy: 0.4176\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8945 - accuracy: 0.4377 - val_loss: 1.8707 - val_accuracy: 0.4392\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8289 - accuracy: 0.4569 - val_loss: 1.8060 - val_accuracy: 0.4624\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7612 - accuracy: 0.4890 - val_loss: 1.7384 - val_accuracy: 0.4976\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.6890 - accuracy: 0.5323 - val_loss: 1.6663 - val_accuracy: 0.5454\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.6153 - accuracy: 0.5785 - val_loss: 1.5951 - val_accuracy: 0.5794\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5430 - accuracy: 0.6082 - val_loss: 1.5253 - val_accuracy: 0.6040\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4726 - accuracy: 0.6280 - val_loss: 1.4580 - val_accuracy: 0.6282\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.4053 - accuracy: 0.6487 - val_loss: 1.3941 - val_accuracy: 0.6426\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 1.3415 - accuracy: 0.6616 - val_loss: 1.3340 - val_accuracy: 0.6584\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 1.2817 - accuracy: 0.6823 - val_loss: 1.2775 - val_accuracy: 0.6738\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2256 - accuracy: 0.6958 - val_loss: 1.2251 - val_accuracy: 0.6864\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1738 - accuracy: 0.7102 - val_loss: 1.1764 - val_accuracy: 0.7022\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1256 - accuracy: 0.7237 - val_loss: 1.1315 - val_accuracy: 0.7194\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0813 - accuracy: 0.7414 - val_loss: 1.0897 - val_accuracy: 0.7332\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0402 - accuracy: 0.7531 - val_loss: 1.0513 - val_accuracy: 0.7464\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0024 - accuracy: 0.7651 - val_loss: 1.0157 - val_accuracy: 0.7584\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.9673 - accuracy: 0.7753 - val_loss: 0.9830 - val_accuracy: 0.7686\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9350 - accuracy: 0.7876 - val_loss: 0.9525 - val_accuracy: 0.7750\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9050 - accuracy: 0.7912 - val_loss: 0.9247 - val_accuracy: 0.7818\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8774 - accuracy: 0.8008 - val_loss: 0.8982 - val_accuracy: 0.7892\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8516 - accuracy: 0.8050 - val_loss: 0.8738 - val_accuracy: 0.7954\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8277 - accuracy: 0.8086 - val_loss: 0.8513 - val_accuracy: 0.7988\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8055 - accuracy: 0.8143 - val_loss: 0.8300 - val_accuracy: 0.8026\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.7847 - accuracy: 0.8185 - val_loss: 0.8103 - val_accuracy: 0.8082\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7651 - accuracy: 0.8239 - val_loss: 0.7918 - val_accuracy: 0.8122\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7468 - accuracy: 0.8257 - val_loss: 0.7744 - val_accuracy: 0.8176\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.7295 - accuracy: 0.8323 - val_loss: 0.7584 - val_accuracy: 0.8208\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7132 - accuracy: 0.8347 - val_loss: 0.7426 - val_accuracy: 0.8218\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.8404 - val_loss: 0.7279 - val_accuracy: 0.8238\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6833 - accuracy: 0.8422 - val_loss: 0.7140 - val_accuracy: 0.8272\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6695 - accuracy: 0.8443 - val_loss: 0.7008 - val_accuracy: 0.8308\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6564 - accuracy: 0.8464 - val_loss: 0.6886 - val_accuracy: 0.8330\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6438 - accuracy: 0.8491 - val_loss: 0.6767 - val_accuracy: 0.8372\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6321 - accuracy: 0.8530 - val_loss: 0.6654 - val_accuracy: 0.8392\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6209 - accuracy: 0.8566 - val_loss: 0.6548 - val_accuracy: 0.8410\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6102 - accuracy: 0.8581 - val_loss: 0.6447 - val_accuracy: 0.8450\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5999 - accuracy: 0.8614 - val_loss: 0.6354 - val_accuracy: 0.8468\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5903 - accuracy: 0.8644 - val_loss: 0.6260 - val_accuracy: 0.8506\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5809 - accuracy: 0.8647 - val_loss: 0.6169 - val_accuracy: 0.8508\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5720 - accuracy: 0.8659 - val_loss: 0.6083 - val_accuracy: 0.8538\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5634 - accuracy: 0.8686 - val_loss: 0.6000 - val_accuracy: 0.8554\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5551 - accuracy: 0.8722 - val_loss: 0.5921 - val_accuracy: 0.8560\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5471 - accuracy: 0.8728 - val_loss: 0.5847 - val_accuracy: 0.8590\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5394 - accuracy: 0.8743 - val_loss: 0.5776 - val_accuracy: 0.8612\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5320 - accuracy: 0.8767 - val_loss: 0.5706 - val_accuracy: 0.8606\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5250 - accuracy: 0.8764 - val_loss: 0.5636 - val_accuracy: 0.8640\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5181 - accuracy: 0.8815 - val_loss: 0.5572 - val_accuracy: 0.8628\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5116 - accuracy: 0.8794 - val_loss: 0.5512 - val_accuracy: 0.8662\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5053 - accuracy: 0.8824 - val_loss: 0.5450 - val_accuracy: 0.8678\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4991 - accuracy: 0.8839 - val_loss: 0.5390 - val_accuracy: 0.8682\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4932 - accuracy: 0.8845 - val_loss: 0.5337 - val_accuracy: 0.8688\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4873 - accuracy: 0.8845 - val_loss: 0.5285 - val_accuracy: 0.8702\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4817 - accuracy: 0.8854 - val_loss: 0.5228 - val_accuracy: 0.8708\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4765 - accuracy: 0.8863 - val_loss: 0.5178 - val_accuracy: 0.8708\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4711 - accuracy: 0.8887 - val_loss: 0.5132 - val_accuracy: 0.8728\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4662 - accuracy: 0.8902 - val_loss: 0.5080 - val_accuracy: 0.8748\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4611 - accuracy: 0.8899 - val_loss: 0.5035 - val_accuracy: 0.8754\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4563 - accuracy: 0.8914 - val_loss: 0.4993 - val_accuracy: 0.8760\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4518 - accuracy: 0.8947 - val_loss: 0.4949 - val_accuracy: 0.8768\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4472 - accuracy: 0.8932 - val_loss: 0.4906 - val_accuracy: 0.8782\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4428 - accuracy: 0.8947 - val_loss: 0.4865 - val_accuracy: 0.8788\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.8965 - val_loss: 0.4827 - val_accuracy: 0.8796\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4344 - accuracy: 0.8965 - val_loss: 0.4783 - val_accuracy: 0.8804\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4304 - accuracy: 0.8983 - val_loss: 0.4747 - val_accuracy: 0.8810\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4264 - accuracy: 0.8989 - val_loss: 0.4709 - val_accuracy: 0.8818\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.9004 - val_loss: 0.4676 - val_accuracy: 0.8830\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.9001 - val_loss: 0.4639 - val_accuracy: 0.8836\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.9013 - val_loss: 0.4610 - val_accuracy: 0.8846\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4119 - accuracy: 0.9028 - val_loss: 0.4575 - val_accuracy: 0.8854\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4085 - accuracy: 0.9028 - val_loss: 0.4546 - val_accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4052 - accuracy: 0.9037 - val_loss: 0.4513 - val_accuracy: 0.8868\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4019 - accuracy: 0.9040 - val_loss: 0.4485 - val_accuracy: 0.8870\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3987 - accuracy: 0.9049 - val_loss: 0.4457 - val_accuracy: 0.8876\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3956 - accuracy: 0.9061 - val_loss: 0.4422 - val_accuracy: 0.8878\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3926 - accuracy: 0.9073 - val_loss: 0.4397 - val_accuracy: 0.8886\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3897 - accuracy: 0.9079 - val_loss: 0.4369 - val_accuracy: 0.8884\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3868 - accuracy: 0.9073 - val_loss: 0.4345 - val_accuracy: 0.8886\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3842 - accuracy: 0.9085 - val_loss: 0.4319 - val_accuracy: 0.8890\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3813 - accuracy: 0.9064 - val_loss: 0.4296 - val_accuracy: 0.8898\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3786 - accuracy: 0.9094 - val_loss: 0.4272 - val_accuracy: 0.8912\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3760 - accuracy: 0.9091 - val_loss: 0.4250 - val_accuracy: 0.8910\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3737 - accuracy: 0.9106 - val_loss: 0.4225 - val_accuracy: 0.8908\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3710 - accuracy: 0.9106 - val_loss: 0.4201 - val_accuracy: 0.8908\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3686 - accuracy: 0.9106 - val_loss: 0.4179 - val_accuracy: 0.8912\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.3663 - accuracy: 0.9109 - val_loss: 0.4162 - val_accuracy: 0.8924\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3640 - accuracy: 0.9124 - val_loss: 0.4139 - val_accuracy: 0.8928\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3616 - accuracy: 0.9115 - val_loss: 0.4121 - val_accuracy: 0.8928\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3596 - accuracy: 0.9127 - val_loss: 0.4106 - val_accuracy: 0.8930\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3574 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.8948\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3552 - accuracy: 0.9130 - val_loss: 0.4062 - val_accuracy: 0.8946\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.9124 - val_loss: 0.4045 - val_accuracy: 0.8952\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3510 - accuracy: 0.9142 - val_loss: 0.4024 - val_accuracy: 0.8950\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3491 - accuracy: 0.9136 - val_loss: 0.4005 - val_accuracy: 0.8954\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8566\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.3232 - accuracy: 0.1038 - val_loss: 2.2750 - val_accuracy: 0.1234\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2393 - accuracy: 0.1638 - val_loss: 2.2020 - val_accuracy: 0.1918\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1668 - accuracy: 0.2337 - val_loss: 2.1290 - val_accuracy: 0.2720\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0972 - accuracy: 0.2928 - val_loss: 2.0618 - val_accuracy: 0.3164\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.0352 - accuracy: 0.3252 - val_loss: 2.0044 - val_accuracy: 0.3372\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9807 - accuracy: 0.3414 - val_loss: 1.9515 - val_accuracy: 0.3594\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9314 - accuracy: 0.3651 - val_loss: 1.9040 - val_accuracy: 0.3724\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8861 - accuracy: 0.3765 - val_loss: 1.8601 - val_accuracy: 0.3828\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8439 - accuracy: 0.3870 - val_loss: 1.8178 - val_accuracy: 0.3980\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8031 - accuracy: 0.4017 - val_loss: 1.7772 - val_accuracy: 0.4126\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.7635 - accuracy: 0.4236 - val_loss: 1.7377 - val_accuracy: 0.4516\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7245 - accuracy: 0.4587 - val_loss: 1.6981 - val_accuracy: 0.4754\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.6856 - accuracy: 0.4818 - val_loss: 1.6593 - val_accuracy: 0.4906\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.6469 - accuracy: 0.5002 - val_loss: 1.6198 - val_accuracy: 0.5166\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.6065 - accuracy: 0.5287 - val_loss: 1.5770 - val_accuracy: 0.5398\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.5589 - accuracy: 0.5551 - val_loss: 1.5229 - val_accuracy: 0.5790\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5010 - accuracy: 0.5908 - val_loss: 1.4631 - val_accuracy: 0.6204\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 1.4425 - accuracy: 0.6262 - val_loss: 1.4053 - val_accuracy: 0.6450\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3857 - accuracy: 0.6496 - val_loss: 1.3485 - val_accuracy: 0.6586\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.3299 - accuracy: 0.6598 - val_loss: 1.2934 - val_accuracy: 0.6738\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 1.2762 - accuracy: 0.6751 - val_loss: 1.2404 - val_accuracy: 0.6902\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 4s 36ms/step - loss: 1.2244 - accuracy: 0.6922 - val_loss: 1.1890 - val_accuracy: 0.7046\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.1750 - accuracy: 0.7063 - val_loss: 1.1409 - val_accuracy: 0.7188\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.1282 - accuracy: 0.7216 - val_loss: 1.0956 - val_accuracy: 0.7288\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.0846 - accuracy: 0.7342 - val_loss: 1.0529 - val_accuracy: 0.7484\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 1.0435 - accuracy: 0.7462 - val_loss: 1.0134 - val_accuracy: 0.7610\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 1.0055 - accuracy: 0.7612 - val_loss: 0.9773 - val_accuracy: 0.7716\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.9708 - accuracy: 0.7711 - val_loss: 0.9437 - val_accuracy: 0.7810\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 0.9384 - accuracy: 0.7765 - val_loss: 0.9130 - val_accuracy: 0.7912\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.9088 - accuracy: 0.7840 - val_loss: 0.8845 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.8813 - accuracy: 0.7957 - val_loss: 0.8584 - val_accuracy: 0.8052\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8562 - accuracy: 0.8023 - val_loss: 0.8338 - val_accuracy: 0.8098\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.8326 - accuracy: 0.8074 - val_loss: 0.8115 - val_accuracy: 0.8148\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.8107 - accuracy: 0.8128 - val_loss: 0.7907 - val_accuracy: 0.8192\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.7903 - accuracy: 0.8179 - val_loss: 0.7711 - val_accuracy: 0.8234\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 0.7713 - accuracy: 0.8227 - val_loss: 0.7531 - val_accuracy: 0.8276\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.7535 - accuracy: 0.8242 - val_loss: 0.7360 - val_accuracy: 0.8292\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 0.7367 - accuracy: 0.8260 - val_loss: 0.7199 - val_accuracy: 0.8314\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.7210 - accuracy: 0.8293 - val_loss: 0.7045 - val_accuracy: 0.8346\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.7059 - accuracy: 0.8311 - val_loss: 0.6909 - val_accuracy: 0.8358\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 0.6922 - accuracy: 0.8344 - val_loss: 0.6778 - val_accuracy: 0.8394\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.6790 - accuracy: 0.8359 - val_loss: 0.6645 - val_accuracy: 0.8404\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 4s 36ms/step - loss: 0.6663 - accuracy: 0.8371 - val_loss: 0.6525 - val_accuracy: 0.8426\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 4s 38ms/step - loss: 0.6545 - accuracy: 0.8386 - val_loss: 0.6412 - val_accuracy: 0.8440\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 3s 33ms/step - loss: 0.6431 - accuracy: 0.8392 - val_loss: 0.6305 - val_accuracy: 0.8458\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.6325 - accuracy: 0.8410 - val_loss: 0.6204 - val_accuracy: 0.8480\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.6222 - accuracy: 0.8449 - val_loss: 0.6104 - val_accuracy: 0.8486\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.6125 - accuracy: 0.8455 - val_loss: 0.6012 - val_accuracy: 0.8502\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.6032 - accuracy: 0.8476 - val_loss: 0.5922 - val_accuracy: 0.8520\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.5944 - accuracy: 0.8491 - val_loss: 0.5837 - val_accuracy: 0.8542\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5861 - accuracy: 0.8503 - val_loss: 0.5757 - val_accuracy: 0.8558\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5779 - accuracy: 0.8509 - val_loss: 0.5680 - val_accuracy: 0.8568\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5701 - accuracy: 0.8539 - val_loss: 0.5609 - val_accuracy: 0.8562\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5626 - accuracy: 0.8542 - val_loss: 0.5538 - val_accuracy: 0.8582\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5555 - accuracy: 0.8566 - val_loss: 0.5470 - val_accuracy: 0.8594\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5486 - accuracy: 0.8596 - val_loss: 0.5402 - val_accuracy: 0.8614\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.8590 - val_loss: 0.5341 - val_accuracy: 0.8640\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5358 - accuracy: 0.8623 - val_loss: 0.5282 - val_accuracy: 0.8652\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5295 - accuracy: 0.8641 - val_loss: 0.5223 - val_accuracy: 0.8644\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.8656 - val_loss: 0.5166 - val_accuracy: 0.8672\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5181 - accuracy: 0.8650 - val_loss: 0.5112 - val_accuracy: 0.8690\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5126 - accuracy: 0.8671 - val_loss: 0.5061 - val_accuracy: 0.8706\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5073 - accuracy: 0.8686 - val_loss: 0.5012 - val_accuracy: 0.8722\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5021 - accuracy: 0.8713 - val_loss: 0.4961 - val_accuracy: 0.8724\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4972 - accuracy: 0.8710 - val_loss: 0.4915 - val_accuracy: 0.8738\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4924 - accuracy: 0.8719 - val_loss: 0.4870 - val_accuracy: 0.8742\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4879 - accuracy: 0.8725 - val_loss: 0.4828 - val_accuracy: 0.8756\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4834 - accuracy: 0.8731 - val_loss: 0.4784 - val_accuracy: 0.8774\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4790 - accuracy: 0.8752 - val_loss: 0.4743 - val_accuracy: 0.8776\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.4748 - accuracy: 0.8764 - val_loss: 0.4704 - val_accuracy: 0.8792\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4707 - accuracy: 0.8785 - val_loss: 0.4665 - val_accuracy: 0.8802\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4665 - accuracy: 0.8800 - val_loss: 0.4626 - val_accuracy: 0.8804\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4628 - accuracy: 0.8785 - val_loss: 0.4592 - val_accuracy: 0.8812\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4590 - accuracy: 0.8800 - val_loss: 0.4555 - val_accuracy: 0.8814\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4553 - accuracy: 0.8800 - val_loss: 0.4519 - val_accuracy: 0.8822\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.8794 - val_loss: 0.4486 - val_accuracy: 0.8832\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4482 - accuracy: 0.8815 - val_loss: 0.4452 - val_accuracy: 0.8844\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4449 - accuracy: 0.8818 - val_loss: 0.4421 - val_accuracy: 0.8842\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.8839 - val_loss: 0.4390 - val_accuracy: 0.8850\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.8839 - val_loss: 0.4359 - val_accuracy: 0.8860\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4351 - accuracy: 0.8860 - val_loss: 0.4329 - val_accuracy: 0.8870\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4321 - accuracy: 0.8860 - val_loss: 0.4301 - val_accuracy: 0.8878\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.8875 - val_loss: 0.4274 - val_accuracy: 0.8880\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4261 - accuracy: 0.8875 - val_loss: 0.4249 - val_accuracy: 0.8878\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4234 - accuracy: 0.8890 - val_loss: 0.4219 - val_accuracy: 0.8902\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8896 - val_loss: 0.4195 - val_accuracy: 0.8894\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4178 - accuracy: 0.8893 - val_loss: 0.4170 - val_accuracy: 0.8894\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4151 - accuracy: 0.8896 - val_loss: 0.4144 - val_accuracy: 0.8912\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4125 - accuracy: 0.8899 - val_loss: 0.4122 - val_accuracy: 0.8908\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4100 - accuracy: 0.8905 - val_loss: 0.4096 - val_accuracy: 0.8914\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4074 - accuracy: 0.8926 - val_loss: 0.4077 - val_accuracy: 0.8912\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4051 - accuracy: 0.8917 - val_loss: 0.4049 - val_accuracy: 0.8932\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4026 - accuracy: 0.8947 - val_loss: 0.4029 - val_accuracy: 0.8936\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4004 - accuracy: 0.8923 - val_loss: 0.4007 - val_accuracy: 0.8940\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3979 - accuracy: 0.8947 - val_loss: 0.3989 - val_accuracy: 0.8948\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3959 - accuracy: 0.8929 - val_loss: 0.3967 - val_accuracy: 0.8944\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3936 - accuracy: 0.8953 - val_loss: 0.3946 - val_accuracy: 0.8956\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3915 - accuracy: 0.8962 - val_loss: 0.3926 - val_accuracy: 0.8960\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.3892 - accuracy: 0.8986 - val_loss: 0.3907 - val_accuracy: 0.8964\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3872 - accuracy: 0.8980 - val_loss: 0.3887 - val_accuracy: 0.8970\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8944\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 4s 33ms/step - loss: 2.2754 - accuracy: 0.1251 - val_loss: 2.2279 - val_accuracy: 0.1660\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 2.1901 - accuracy: 0.2043 - val_loss: 2.1550 - val_accuracy: 0.2416\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1178 - accuracy: 0.2783 - val_loss: 2.0815 - val_accuracy: 0.3056\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0428 - accuracy: 0.3359 - val_loss: 2.0068 - val_accuracy: 0.3522\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9666 - accuracy: 0.3866 - val_loss: 1.9307 - val_accuracy: 0.4040\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8889 - accuracy: 0.4379 - val_loss: 1.8533 - val_accuracy: 0.4562\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.8102 - accuracy: 0.4913 - val_loss: 1.7758 - val_accuracy: 0.5066\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7322 - accuracy: 0.5417 - val_loss: 1.6990 - val_accuracy: 0.5470\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.6556 - accuracy: 0.5756 - val_loss: 1.6235 - val_accuracy: 0.5866\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.5807 - accuracy: 0.6182 - val_loss: 1.5508 - val_accuracy: 0.6190\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5088 - accuracy: 0.6461 - val_loss: 1.4801 - val_accuracy: 0.6566\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4395 - accuracy: 0.6797 - val_loss: 1.4126 - val_accuracy: 0.6870\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.3736 - accuracy: 0.7076 - val_loss: 1.3487 - val_accuracy: 0.7088\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.3114 - accuracy: 0.7235 - val_loss: 1.2886 - val_accuracy: 0.7260\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.2528 - accuracy: 0.7379 - val_loss: 1.2317 - val_accuracy: 0.7412\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 1.1974 - accuracy: 0.7504 - val_loss: 1.1781 - val_accuracy: 0.7518\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1454 - accuracy: 0.7594 - val_loss: 1.1281 - val_accuracy: 0.7638\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0971 - accuracy: 0.7711 - val_loss: 1.0814 - val_accuracy: 0.7758\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0517 - accuracy: 0.7813 - val_loss: 1.0377 - val_accuracy: 0.7860\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0101 - accuracy: 0.7891 - val_loss: 0.9977 - val_accuracy: 0.7918\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9714 - accuracy: 0.7963 - val_loss: 0.9609 - val_accuracy: 0.7962\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9356 - accuracy: 0.8032 - val_loss: 0.9264 - val_accuracy: 0.8020\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9023 - accuracy: 0.8071 - val_loss: 0.8952 - val_accuracy: 0.8068\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8718 - accuracy: 0.8125 - val_loss: 0.8654 - val_accuracy: 0.8104\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8432 - accuracy: 0.8155 - val_loss: 0.8383 - val_accuracy: 0.8136\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.8169 - accuracy: 0.8182 - val_loss: 0.8137 - val_accuracy: 0.8156\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7927 - accuracy: 0.8224 - val_loss: 0.7902 - val_accuracy: 0.8194\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7701 - accuracy: 0.8248 - val_loss: 0.7683 - val_accuracy: 0.8248\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7490 - accuracy: 0.8290 - val_loss: 0.7483 - val_accuracy: 0.8274\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7294 - accuracy: 0.8335 - val_loss: 0.7295 - val_accuracy: 0.8292\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7111 - accuracy: 0.8347 - val_loss: 0.7120 - val_accuracy: 0.8322\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6940 - accuracy: 0.8395 - val_loss: 0.6955 - val_accuracy: 0.8354\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6781 - accuracy: 0.8425 - val_loss: 0.6808 - val_accuracy: 0.8404\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6634 - accuracy: 0.8458 - val_loss: 0.6664 - val_accuracy: 0.8436\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6494 - accuracy: 0.8485 - val_loss: 0.6531 - val_accuracy: 0.8474\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6360 - accuracy: 0.8524 - val_loss: 0.6411 - val_accuracy: 0.8458\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.8515 - val_loss: 0.6288 - val_accuracy: 0.8502\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6122 - accuracy: 0.8548 - val_loss: 0.6176 - val_accuracy: 0.8516\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6014 - accuracy: 0.8572 - val_loss: 0.6069 - val_accuracy: 0.8526\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5909 - accuracy: 0.8599 - val_loss: 0.5969 - val_accuracy: 0.8522\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5811 - accuracy: 0.8602 - val_loss: 0.5874 - val_accuracy: 0.8544\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5718 - accuracy: 0.8620 - val_loss: 0.5786 - val_accuracy: 0.8558\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5629 - accuracy: 0.8626 - val_loss: 0.5707 - val_accuracy: 0.8580\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5548 - accuracy: 0.8641 - val_loss: 0.5621 - val_accuracy: 0.8582\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5467 - accuracy: 0.8653 - val_loss: 0.5547 - val_accuracy: 0.8602\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5393 - accuracy: 0.8665 - val_loss: 0.5474 - val_accuracy: 0.8632\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5320 - accuracy: 0.8713 - val_loss: 0.5404 - val_accuracy: 0.8650\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5250 - accuracy: 0.8719 - val_loss: 0.5339 - val_accuracy: 0.8666\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5184 - accuracy: 0.8740 - val_loss: 0.5274 - val_accuracy: 0.8672\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5121 - accuracy: 0.8746 - val_loss: 0.5214 - val_accuracy: 0.8680\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.5059 - accuracy: 0.8755 - val_loss: 0.5156 - val_accuracy: 0.8680\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5003 - accuracy: 0.8749 - val_loss: 0.5102 - val_accuracy: 0.8698\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4947 - accuracy: 0.8752 - val_loss: 0.5049 - val_accuracy: 0.8694\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.4893 - accuracy: 0.8764 - val_loss: 0.4994 - val_accuracy: 0.8710\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4842 - accuracy: 0.8776 - val_loss: 0.4949 - val_accuracy: 0.8722\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4792 - accuracy: 0.8788 - val_loss: 0.4901 - val_accuracy: 0.8724\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.8776 - val_loss: 0.4854 - val_accuracy: 0.8726\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4699 - accuracy: 0.8782 - val_loss: 0.4811 - val_accuracy: 0.8730\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.8788 - val_loss: 0.4770 - val_accuracy: 0.8734\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4610 - accuracy: 0.8794 - val_loss: 0.4727 - val_accuracy: 0.8738\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4569 - accuracy: 0.8800 - val_loss: 0.4687 - val_accuracy: 0.8758\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4530 - accuracy: 0.8815 - val_loss: 0.4649 - val_accuracy: 0.8756\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4491 - accuracy: 0.8812 - val_loss: 0.4614 - val_accuracy: 0.8768\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4453 - accuracy: 0.8833 - val_loss: 0.4577 - val_accuracy: 0.8784\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8857 - val_loss: 0.4541 - val_accuracy: 0.8804\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4382 - accuracy: 0.8854 - val_loss: 0.4507 - val_accuracy: 0.8804\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.8860 - val_loss: 0.4474 - val_accuracy: 0.8808\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4313 - accuracy: 0.8872 - val_loss: 0.4442 - val_accuracy: 0.8804\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4283 - accuracy: 0.8875 - val_loss: 0.4412 - val_accuracy: 0.8822\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4247 - accuracy: 0.8875 - val_loss: 0.4385 - val_accuracy: 0.8826\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4220 - accuracy: 0.8869 - val_loss: 0.4353 - val_accuracy: 0.8844\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4188 - accuracy: 0.8884 - val_loss: 0.4325 - val_accuracy: 0.8844\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4160 - accuracy: 0.8899 - val_loss: 0.4299 - val_accuracy: 0.8846\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4132 - accuracy: 0.8905 - val_loss: 0.4272 - val_accuracy: 0.8856\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4104 - accuracy: 0.8905 - val_loss: 0.4245 - val_accuracy: 0.8854\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4077 - accuracy: 0.8908 - val_loss: 0.4221 - val_accuracy: 0.8838\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4051 - accuracy: 0.8899 - val_loss: 0.4196 - val_accuracy: 0.8858\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4024 - accuracy: 0.8908 - val_loss: 0.4169 - val_accuracy: 0.8858\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3999 - accuracy: 0.8887 - val_loss: 0.4146 - val_accuracy: 0.8872\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3976 - accuracy: 0.8902 - val_loss: 0.4124 - val_accuracy: 0.8878\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3952 - accuracy: 0.8929 - val_loss: 0.4100 - val_accuracy: 0.8874\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3929 - accuracy: 0.8917 - val_loss: 0.4079 - val_accuracy: 0.8870\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3906 - accuracy: 0.8917 - val_loss: 0.4057 - val_accuracy: 0.8886\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 0.3883 - accuracy: 0.8932 - val_loss: 0.4036 - val_accuracy: 0.8890\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3861 - accuracy: 0.8932 - val_loss: 0.4016 - val_accuracy: 0.8896\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3839 - accuracy: 0.8947 - val_loss: 0.3999 - val_accuracy: 0.8892\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.3819 - accuracy: 0.8956 - val_loss: 0.3978 - val_accuracy: 0.8900\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 0.3798 - accuracy: 0.8950 - val_loss: 0.3956 - val_accuracy: 0.8902\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.3775 - accuracy: 0.8953 - val_loss: 0.3939 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.3757 - accuracy: 0.8950 - val_loss: 0.3920 - val_accuracy: 0.8912\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.3737 - accuracy: 0.8965 - val_loss: 0.3904 - val_accuracy: 0.8916\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.3719 - accuracy: 0.8980 - val_loss: 0.3882 - val_accuracy: 0.8916\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3699 - accuracy: 0.8968 - val_loss: 0.3867 - val_accuracy: 0.8920\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.3681 - accuracy: 0.8992 - val_loss: 0.3849 - val_accuracy: 0.8918\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.3662 - accuracy: 0.8986 - val_loss: 0.3831 - val_accuracy: 0.8920\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.3644 - accuracy: 0.8983 - val_loss: 0.3815 - val_accuracy: 0.8922\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 0.3628 - accuracy: 0.8983 - val_loss: 0.3798 - val_accuracy: 0.8930\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3610 - accuracy: 0.8995 - val_loss: 0.3785 - val_accuracy: 0.8930\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.3593 - accuracy: 0.9013 - val_loss: 0.3769 - val_accuracy: 0.8930\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3577 - accuracy: 0.9013 - val_loss: 0.3753 - val_accuracy: 0.8944\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8800\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 4s 30ms/step - loss: 2.3095 - accuracy: 0.0771 - val_loss: 2.3084 - val_accuracy: 0.0822\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.3081 - accuracy: 0.0798 - val_loss: 2.3071 - val_accuracy: 0.0846\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 2.3068 - accuracy: 0.0819 - val_loss: 2.3058 - val_accuracy: 0.0850\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 2.3055 - accuracy: 0.0828 - val_loss: 2.3047 - val_accuracy: 0.0860\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 2.3043 - accuracy: 0.0834 - val_loss: 2.3036 - val_accuracy: 0.0864\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.3032 - accuracy: 0.0846 - val_loss: 2.3026 - val_accuracy: 0.0880\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.3021 - accuracy: 0.0876 - val_loss: 2.3016 - val_accuracy: 0.0900\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.3011 - accuracy: 0.0888 - val_loss: 2.3006 - val_accuracy: 0.0906\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.3001 - accuracy: 0.0909 - val_loss: 2.2997 - val_accuracy: 0.0926\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.2992 - accuracy: 0.0918 - val_loss: 2.2988 - val_accuracy: 0.0942\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2982 - accuracy: 0.0942 - val_loss: 2.2979 - val_accuracy: 0.0970\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.2973 - accuracy: 0.0975 - val_loss: 2.2971 - val_accuracy: 0.1014\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.2964 - accuracy: 0.1011 - val_loss: 2.2962 - val_accuracy: 0.1038\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.2955 - accuracy: 0.1029 - val_loss: 2.2954 - val_accuracy: 0.1062\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 2.2946 - accuracy: 0.1065 - val_loss: 2.2945 - val_accuracy: 0.1092\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2937 - accuracy: 0.1101 - val_loss: 2.2937 - val_accuracy: 0.1116\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 2.2928 - accuracy: 0.1143 - val_loss: 2.2929 - val_accuracy: 0.1154\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 2.2920 - accuracy: 0.1167 - val_loss: 2.2920 - val_accuracy: 0.1180\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 2.2911 - accuracy: 0.1197 - val_loss: 2.2912 - val_accuracy: 0.1208\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 2.2902 - accuracy: 0.1236 - val_loss: 2.2903 - val_accuracy: 0.1250\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 2.2893 - accuracy: 0.1278 - val_loss: 2.2895 - val_accuracy: 0.1294\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 2.2884 - accuracy: 0.1320 - val_loss: 2.2886 - val_accuracy: 0.1326\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 2.2875 - accuracy: 0.1347 - val_loss: 2.2877 - val_accuracy: 0.1356\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.2865 - accuracy: 0.1380 - val_loss: 2.2868 - val_accuracy: 0.1410\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2856 - accuracy: 0.1434 - val_loss: 2.2859 - val_accuracy: 0.1464\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2846 - accuracy: 0.1491 - val_loss: 2.2849 - val_accuracy: 0.1486\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2836 - accuracy: 0.1530 - val_loss: 2.2839 - val_accuracy: 0.1518\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2826 - accuracy: 0.1581 - val_loss: 2.2829 - val_accuracy: 0.1560\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.2816 - accuracy: 0.1620 - val_loss: 2.2819 - val_accuracy: 0.1600\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2805 - accuracy: 0.1647 - val_loss: 2.2808 - val_accuracy: 0.1616\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2793 - accuracy: 0.1671 - val_loss: 2.2797 - val_accuracy: 0.1648\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2782 - accuracy: 0.1698 - val_loss: 2.2785 - val_accuracy: 0.1674\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2770 - accuracy: 0.1725 - val_loss: 2.2773 - val_accuracy: 0.1710\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2757 - accuracy: 0.1752 - val_loss: 2.2761 - val_accuracy: 0.1752\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2744 - accuracy: 0.1791 - val_loss: 2.2748 - val_accuracy: 0.1800\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 2.2731 - accuracy: 0.1821 - val_loss: 2.2735 - val_accuracy: 0.1822\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2717 - accuracy: 0.1836 - val_loss: 2.2721 - val_accuracy: 0.1848\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2703 - accuracy: 0.1848 - val_loss: 2.2707 - val_accuracy: 0.1868\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2689 - accuracy: 0.1869 - val_loss: 2.2693 - val_accuracy: 0.1886\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2674 - accuracy: 0.1875 - val_loss: 2.2678 - val_accuracy: 0.1896\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2658 - accuracy: 0.1878 - val_loss: 2.2662 - val_accuracy: 0.1892\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2642 - accuracy: 0.1887 - val_loss: 2.2646 - val_accuracy: 0.1908\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2626 - accuracy: 0.1911 - val_loss: 2.2629 - val_accuracy: 0.1922\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2608 - accuracy: 0.1902 - val_loss: 2.2611 - val_accuracy: 0.1938\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2589 - accuracy: 0.1923 - val_loss: 2.2593 - val_accuracy: 0.1954\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2570 - accuracy: 0.1932 - val_loss: 2.2574 - val_accuracy: 0.1966\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2550 - accuracy: 0.1950 - val_loss: 2.2554 - val_accuracy: 0.1982\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2530 - accuracy: 0.1959 - val_loss: 2.2533 - val_accuracy: 0.1994\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2508 - accuracy: 0.1959 - val_loss: 2.2511 - val_accuracy: 0.1986\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2486 - accuracy: 0.1959 - val_loss: 2.2489 - val_accuracy: 0.2000\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2463 - accuracy: 0.1974 - val_loss: 2.2465 - val_accuracy: 0.2010\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.2438 - accuracy: 0.1974 - val_loss: 2.2441 - val_accuracy: 0.2010\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 2.2413 - accuracy: 0.1974 - val_loss: 2.2416 - val_accuracy: 0.2016\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2387 - accuracy: 0.1974 - val_loss: 2.2389 - val_accuracy: 0.2020\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2360 - accuracy: 0.1989 - val_loss: 2.2362 - val_accuracy: 0.2022\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2332 - accuracy: 0.1986 - val_loss: 2.2334 - val_accuracy: 0.2034\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2304 - accuracy: 0.2007 - val_loss: 2.2305 - val_accuracy: 0.2034\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2274 - accuracy: 0.2007 - val_loss: 2.2275 - val_accuracy: 0.2034\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2243 - accuracy: 0.2004 - val_loss: 2.2244 - val_accuracy: 0.2042\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2210 - accuracy: 0.2019 - val_loss: 2.2212 - val_accuracy: 0.2048\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2177 - accuracy: 0.2028 - val_loss: 2.2178 - val_accuracy: 0.2056\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2142 - accuracy: 0.2022 - val_loss: 2.2143 - val_accuracy: 0.2064\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2106 - accuracy: 0.2031 - val_loss: 2.2106 - val_accuracy: 0.2068\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2068 - accuracy: 0.2049 - val_loss: 2.2068 - val_accuracy: 0.2084\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2029 - accuracy: 0.2067 - val_loss: 2.2028 - val_accuracy: 0.2102\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1988 - accuracy: 0.2073 - val_loss: 2.1987 - val_accuracy: 0.2112\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1945 - accuracy: 0.2085 - val_loss: 2.1943 - val_accuracy: 0.2120\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1900 - accuracy: 0.2106 - val_loss: 2.1899 - val_accuracy: 0.2150\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1854 - accuracy: 0.2121 - val_loss: 2.1852 - val_accuracy: 0.2164\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1805 - accuracy: 0.2145 - val_loss: 2.1803 - val_accuracy: 0.2186\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1755 - accuracy: 0.2166 - val_loss: 2.1752 - val_accuracy: 0.2212\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1703 - accuracy: 0.2217 - val_loss: 2.1700 - val_accuracy: 0.2246\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.1648 - accuracy: 0.2229 - val_loss: 2.1645 - val_accuracy: 0.2268\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.1591 - accuracy: 0.2286 - val_loss: 2.1587 - val_accuracy: 0.2318\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.1532 - accuracy: 0.2322 - val_loss: 2.1527 - val_accuracy: 0.2344\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1469 - accuracy: 0.2361 - val_loss: 2.1464 - val_accuracy: 0.2422\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1404 - accuracy: 0.2448 - val_loss: 2.1398 - val_accuracy: 0.2500\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1337 - accuracy: 0.2484 - val_loss: 2.1330 - val_accuracy: 0.2570\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1266 - accuracy: 0.2577 - val_loss: 2.1259 - val_accuracy: 0.2666\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1192 - accuracy: 0.2694 - val_loss: 2.1184 - val_accuracy: 0.2762\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1115 - accuracy: 0.2811 - val_loss: 2.1106 - val_accuracy: 0.2844\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1035 - accuracy: 0.2901 - val_loss: 2.1026 - val_accuracy: 0.2920\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0951 - accuracy: 0.2988 - val_loss: 2.0941 - val_accuracy: 0.2982\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0864 - accuracy: 0.3087 - val_loss: 2.0852 - val_accuracy: 0.3068\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0772 - accuracy: 0.3135 - val_loss: 2.0760 - val_accuracy: 0.3126\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0677 - accuracy: 0.3180 - val_loss: 2.0664 - val_accuracy: 0.3154\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0577 - accuracy: 0.3231 - val_loss: 2.0563 - val_accuracy: 0.3202\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0473 - accuracy: 0.3267 - val_loss: 2.0458 - val_accuracy: 0.3258\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0365 - accuracy: 0.3345 - val_loss: 2.0349 - val_accuracy: 0.3292\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0252 - accuracy: 0.3342 - val_loss: 2.0236 - val_accuracy: 0.3312\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0136 - accuracy: 0.3342 - val_loss: 2.0119 - val_accuracy: 0.3318\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0016 - accuracy: 0.3348 - val_loss: 1.9998 - val_accuracy: 0.3316\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9892 - accuracy: 0.3360 - val_loss: 1.9872 - val_accuracy: 0.3328\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9763 - accuracy: 0.3369 - val_loss: 1.9744 - val_accuracy: 0.3346\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9631 - accuracy: 0.3369 - val_loss: 1.9612 - val_accuracy: 0.3380\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9496 - accuracy: 0.3402 - val_loss: 1.9477 - val_accuracy: 0.3402\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.9359 - accuracy: 0.3423 - val_loss: 1.9338 - val_accuracy: 0.3422\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9217 - accuracy: 0.3435 - val_loss: 1.9198 - val_accuracy: 0.3428\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9074 - accuracy: 0.3456 - val_loss: 1.9055 - val_accuracy: 0.3442\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8929 - accuracy: 0.3438 - val_loss: 1.8910 - val_accuracy: 0.3454\n",
      "53/53 [==============================] - 1s 8ms/step - loss: 1.9029 - accuracy: 0.3401\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 2.3098 - accuracy: 0.0612 - val_loss: 2.3093 - val_accuracy: 0.0602\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3085 - accuracy: 0.0636 - val_loss: 2.3080 - val_accuracy: 0.0640\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.3072 - accuracy: 0.0684 - val_loss: 2.3068 - val_accuracy: 0.0692\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.3060 - accuracy: 0.0747 - val_loss: 2.3056 - val_accuracy: 0.0768\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3048 - accuracy: 0.0825 - val_loss: 2.3044 - val_accuracy: 0.0818\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.3036 - accuracy: 0.0876 - val_loss: 2.3033 - val_accuracy: 0.0884\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3025 - accuracy: 0.0936 - val_loss: 2.3022 - val_accuracy: 0.0952\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3014 - accuracy: 0.1011 - val_loss: 2.3011 - val_accuracy: 0.1020\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.3003 - accuracy: 0.1077 - val_loss: 2.3000 - val_accuracy: 0.1084\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2992 - accuracy: 0.1110 - val_loss: 2.2989 - val_accuracy: 0.1126\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2982 - accuracy: 0.1146 - val_loss: 2.2979 - val_accuracy: 0.1170\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2971 - accuracy: 0.1185 - val_loss: 2.2968 - val_accuracy: 0.1192\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2961 - accuracy: 0.1209 - val_loss: 2.2958 - val_accuracy: 0.1220\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2951 - accuracy: 0.1230 - val_loss: 2.2948 - val_accuracy: 0.1248\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2941 - accuracy: 0.1266 - val_loss: 2.2938 - val_accuracy: 0.1274\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2931 - accuracy: 0.1299 - val_loss: 2.2928 - val_accuracy: 0.1314\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2921 - accuracy: 0.1335 - val_loss: 2.2918 - val_accuracy: 0.1334\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2911 - accuracy: 0.1368 - val_loss: 2.2908 - val_accuracy: 0.1344\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2901 - accuracy: 0.1368 - val_loss: 2.2899 - val_accuracy: 0.1342\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2891 - accuracy: 0.1368 - val_loss: 2.2889 - val_accuracy: 0.1354\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2882 - accuracy: 0.1392 - val_loss: 2.2880 - val_accuracy: 0.1358\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2872 - accuracy: 0.1389 - val_loss: 2.2870 - val_accuracy: 0.1368\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2862 - accuracy: 0.1401 - val_loss: 2.2861 - val_accuracy: 0.1374\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2853 - accuracy: 0.1410 - val_loss: 2.2851 - val_accuracy: 0.1378\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2843 - accuracy: 0.1407 - val_loss: 2.2841 - val_accuracy: 0.1378\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2834 - accuracy: 0.1413 - val_loss: 2.2832 - val_accuracy: 0.1382\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2824 - accuracy: 0.1413 - val_loss: 2.2822 - val_accuracy: 0.1388\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2814 - accuracy: 0.1413 - val_loss: 2.2812 - val_accuracy: 0.1400\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2803 - accuracy: 0.1428 - val_loss: 2.2802 - val_accuracy: 0.1408\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2793 - accuracy: 0.1431 - val_loss: 2.2791 - val_accuracy: 0.1410\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.2782 - accuracy: 0.1440 - val_loss: 2.2781 - val_accuracy: 0.1412\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2771 - accuracy: 0.1449 - val_loss: 2.2770 - val_accuracy: 0.1422\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2760 - accuracy: 0.1452 - val_loss: 2.2759 - val_accuracy: 0.1426\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2749 - accuracy: 0.1461 - val_loss: 2.2747 - val_accuracy: 0.1424\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2737 - accuracy: 0.1458 - val_loss: 2.2735 - val_accuracy: 0.1432\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2725 - accuracy: 0.1473 - val_loss: 2.2724 - val_accuracy: 0.1444\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2713 - accuracy: 0.1485 - val_loss: 2.2711 - val_accuracy: 0.1452\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2700 - accuracy: 0.1488 - val_loss: 2.2699 - val_accuracy: 0.1460\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2687 - accuracy: 0.1497 - val_loss: 2.2686 - val_accuracy: 0.1474\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2674 - accuracy: 0.1527 - val_loss: 2.2673 - val_accuracy: 0.1496\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2660 - accuracy: 0.1566 - val_loss: 2.2659 - val_accuracy: 0.1540\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2646 - accuracy: 0.1587 - val_loss: 2.2645 - val_accuracy: 0.1562\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2632 - accuracy: 0.1602 - val_loss: 2.2631 - val_accuracy: 0.1606\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2617 - accuracy: 0.1665 - val_loss: 2.2616 - val_accuracy: 0.1678\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2602 - accuracy: 0.1707 - val_loss: 2.2600 - val_accuracy: 0.1712\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2587 - accuracy: 0.1749 - val_loss: 2.2585 - val_accuracy: 0.1764\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2571 - accuracy: 0.1821 - val_loss: 2.2569 - val_accuracy: 0.1848\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2554 - accuracy: 0.1911 - val_loss: 2.2552 - val_accuracy: 0.1952\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2537 - accuracy: 0.2010 - val_loss: 2.2535 - val_accuracy: 0.2034\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2519 - accuracy: 0.2055 - val_loss: 2.2517 - val_accuracy: 0.2112\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2501 - accuracy: 0.2145 - val_loss: 2.2498 - val_accuracy: 0.2186\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2482 - accuracy: 0.2223 - val_loss: 2.2479 - val_accuracy: 0.2236\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2462 - accuracy: 0.2277 - val_loss: 2.2459 - val_accuracy: 0.2306\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2442 - accuracy: 0.2334 - val_loss: 2.2439 - val_accuracy: 0.2352\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2421 - accuracy: 0.2373 - val_loss: 2.2417 - val_accuracy: 0.2394\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2400 - accuracy: 0.2418 - val_loss: 2.2395 - val_accuracy: 0.2422\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2377 - accuracy: 0.2454 - val_loss: 2.2373 - val_accuracy: 0.2470\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2354 - accuracy: 0.2490 - val_loss: 2.2349 - val_accuracy: 0.2492\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2330 - accuracy: 0.2538 - val_loss: 2.2325 - val_accuracy: 0.2528\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2305 - accuracy: 0.2559 - val_loss: 2.2300 - val_accuracy: 0.2556\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2279 - accuracy: 0.2577 - val_loss: 2.2273 - val_accuracy: 0.2564\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2252 - accuracy: 0.2601 - val_loss: 2.2246 - val_accuracy: 0.2578\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2224 - accuracy: 0.2601 - val_loss: 2.2217 - val_accuracy: 0.2598\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2195 - accuracy: 0.2619 - val_loss: 2.2188 - val_accuracy: 0.2620\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2165 - accuracy: 0.2646 - val_loss: 2.2157 - val_accuracy: 0.2628\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2133 - accuracy: 0.2649 - val_loss: 2.2125 - val_accuracy: 0.2656\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2100 - accuracy: 0.2667 - val_loss: 2.2091 - val_accuracy: 0.2676\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2066 - accuracy: 0.2691 - val_loss: 2.2057 - val_accuracy: 0.2710\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2031 - accuracy: 0.2718 - val_loss: 2.2021 - val_accuracy: 0.2724\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1994 - accuracy: 0.2736 - val_loss: 2.1983 - val_accuracy: 0.2758\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1956 - accuracy: 0.2772 - val_loss: 2.1944 - val_accuracy: 0.2778\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1916 - accuracy: 0.2784 - val_loss: 2.1903 - val_accuracy: 0.2808\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1874 - accuracy: 0.2802 - val_loss: 2.1860 - val_accuracy: 0.2812\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1829 - accuracy: 0.2811 - val_loss: 2.1815 - val_accuracy: 0.2824\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1784 - accuracy: 0.2823 - val_loss: 2.1769 - val_accuracy: 0.2844\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1737 - accuracy: 0.2847 - val_loss: 2.1722 - val_accuracy: 0.2860\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.1688 - accuracy: 0.2847 - val_loss: 2.1672 - val_accuracy: 0.2878\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1637 - accuracy: 0.2871 - val_loss: 2.1620 - val_accuracy: 0.2908\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1585 - accuracy: 0.2907 - val_loss: 2.1567 - val_accuracy: 0.2948\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1530 - accuracy: 0.2952 - val_loss: 2.1511 - val_accuracy: 0.2978\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1473 - accuracy: 0.2967 - val_loss: 2.1452 - val_accuracy: 0.2998\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1413 - accuracy: 0.3012 - val_loss: 2.1392 - val_accuracy: 0.3028\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1352 - accuracy: 0.3018 - val_loss: 2.1328 - val_accuracy: 0.3034\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1287 - accuracy: 0.3042 - val_loss: 2.1263 - val_accuracy: 0.3052\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1221 - accuracy: 0.3048 - val_loss: 2.1196 - val_accuracy: 0.3064\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1153 - accuracy: 0.3069 - val_loss: 2.1128 - val_accuracy: 0.3090\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1083 - accuracy: 0.3093 - val_loss: 2.1057 - val_accuracy: 0.3104\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1011 - accuracy: 0.3105 - val_loss: 2.0984 - val_accuracy: 0.3122\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0937 - accuracy: 0.3117 - val_loss: 2.0908 - val_accuracy: 0.3130\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0860 - accuracy: 0.3138 - val_loss: 2.0831 - val_accuracy: 0.3168\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0782 - accuracy: 0.3171 - val_loss: 2.0752 - val_accuracy: 0.3192\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0703 - accuracy: 0.3210 - val_loss: 2.0672 - val_accuracy: 0.3216\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0621 - accuracy: 0.3225 - val_loss: 2.0588 - val_accuracy: 0.3234\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0536 - accuracy: 0.3249 - val_loss: 2.0503 - val_accuracy: 0.3240\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0451 - accuracy: 0.3264 - val_loss: 2.0417 - val_accuracy: 0.3258\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0364 - accuracy: 0.3291 - val_loss: 2.0329 - val_accuracy: 0.3286\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0275 - accuracy: 0.3306 - val_loss: 2.0239 - val_accuracy: 0.3310\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.0185 - accuracy: 0.3330 - val_loss: 2.0149 - val_accuracy: 0.3318\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0094 - accuracy: 0.3333 - val_loss: 2.0057 - val_accuracy: 0.3328\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0002 - accuracy: 0.3342 - val_loss: 1.9963 - val_accuracy: 0.3346\n",
      "53/53 [==============================] - 1s 6ms/step - loss: 1.9986 - accuracy: 0.3317\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 2.3037 - accuracy: 0.0981 - val_loss: 2.3029 - val_accuracy: 0.0984\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3032 - accuracy: 0.0984 - val_loss: 2.3024 - val_accuracy: 0.0998\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3019 - val_accuracy: 0.1024\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.3022 - accuracy: 0.1017 - val_loss: 2.3014 - val_accuracy: 0.1052\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3017 - accuracy: 0.1038 - val_loss: 2.3009 - val_accuracy: 0.1064\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.3012 - accuracy: 0.1077 - val_loss: 2.3004 - val_accuracy: 0.1096\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3007 - accuracy: 0.1101 - val_loss: 2.2999 - val_accuracy: 0.1130\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3002 - accuracy: 0.1137 - val_loss: 2.2994 - val_accuracy: 0.1148\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2997 - accuracy: 0.1164 - val_loss: 2.2989 - val_accuracy: 0.1188\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2992 - accuracy: 0.1194 - val_loss: 2.2984 - val_accuracy: 0.1212\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2987 - accuracy: 0.1224 - val_loss: 2.2979 - val_accuracy: 0.1244\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2982 - accuracy: 0.1245 - val_loss: 2.2974 - val_accuracy: 0.1266\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2977 - accuracy: 0.1272 - val_loss: 2.2969 - val_accuracy: 0.1304\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2972 - accuracy: 0.1308 - val_loss: 2.2964 - val_accuracy: 0.1322\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2967 - accuracy: 0.1338 - val_loss: 2.2959 - val_accuracy: 0.1346\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2962 - accuracy: 0.1356 - val_loss: 2.2954 - val_accuracy: 0.1360\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2957 - accuracy: 0.1368 - val_loss: 2.2949 - val_accuracy: 0.1386\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2952 - accuracy: 0.1407 - val_loss: 2.2944 - val_accuracy: 0.1434\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2947 - accuracy: 0.1434 - val_loss: 2.2939 - val_accuracy: 0.1450\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2942 - accuracy: 0.1458 - val_loss: 2.2933 - val_accuracy: 0.1468\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2936 - accuracy: 0.1476 - val_loss: 2.2928 - val_accuracy: 0.1480\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2931 - accuracy: 0.1497 - val_loss: 2.2923 - val_accuracy: 0.1492\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2926 - accuracy: 0.1494 - val_loss: 2.2917 - val_accuracy: 0.1514\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2920 - accuracy: 0.1536 - val_loss: 2.2912 - val_accuracy: 0.1540\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2915 - accuracy: 0.1560 - val_loss: 2.2906 - val_accuracy: 0.1560\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2909 - accuracy: 0.1569 - val_loss: 2.2901 - val_accuracy: 0.1578\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2904 - accuracy: 0.1593 - val_loss: 2.2895 - val_accuracy: 0.1594\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2898 - accuracy: 0.1596 - val_loss: 2.2889 - val_accuracy: 0.1622\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2892 - accuracy: 0.1626 - val_loss: 2.2883 - val_accuracy: 0.1640\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2886 - accuracy: 0.1647 - val_loss: 2.2877 - val_accuracy: 0.1656\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2880 - accuracy: 0.1647 - val_loss: 2.2871 - val_accuracy: 0.1672\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2874 - accuracy: 0.1653 - val_loss: 2.2864 - val_accuracy: 0.1688\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2868 - accuracy: 0.1674 - val_loss: 2.2858 - val_accuracy: 0.1700\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2861 - accuracy: 0.1686 - val_loss: 2.2851 - val_accuracy: 0.1716\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2855 - accuracy: 0.1704 - val_loss: 2.2844 - val_accuracy: 0.1730\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2848 - accuracy: 0.1719 - val_loss: 2.2837 - val_accuracy: 0.1744\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2841 - accuracy: 0.1740 - val_loss: 2.2830 - val_accuracy: 0.1770\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2833 - accuracy: 0.1758 - val_loss: 2.2823 - val_accuracy: 0.1784\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2826 - accuracy: 0.1776 - val_loss: 2.2815 - val_accuracy: 0.1800\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2818 - accuracy: 0.1782 - val_loss: 2.2807 - val_accuracy: 0.1810\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2810 - accuracy: 0.1803 - val_loss: 2.2799 - val_accuracy: 0.1826\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2802 - accuracy: 0.1821 - val_loss: 2.2791 - val_accuracy: 0.1852\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2794 - accuracy: 0.1827 - val_loss: 2.2782 - val_accuracy: 0.1854\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2785 - accuracy: 0.1824 - val_loss: 2.2774 - val_accuracy: 0.1852\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2777 - accuracy: 0.1842 - val_loss: 2.2765 - val_accuracy: 0.1868\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2768 - accuracy: 0.1845 - val_loss: 2.2756 - val_accuracy: 0.1876\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2759 - accuracy: 0.1863 - val_loss: 2.2747 - val_accuracy: 0.1890\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2750 - accuracy: 0.1884 - val_loss: 2.2738 - val_accuracy: 0.1906\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2741 - accuracy: 0.1887 - val_loss: 2.2728 - val_accuracy: 0.1904\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2731 - accuracy: 0.1890 - val_loss: 2.2718 - val_accuracy: 0.1916\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2721 - accuracy: 0.1899 - val_loss: 2.2708 - val_accuracy: 0.1926\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2711 - accuracy: 0.1902 - val_loss: 2.2698 - val_accuracy: 0.1930\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2701 - accuracy: 0.1938 - val_loss: 2.2687 - val_accuracy: 0.1954\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2690 - accuracy: 0.1947 - val_loss: 2.2676 - val_accuracy: 0.1958\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2679 - accuracy: 0.1959 - val_loss: 2.2665 - val_accuracy: 0.1966\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2668 - accuracy: 0.1962 - val_loss: 2.2654 - val_accuracy: 0.1974\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2656 - accuracy: 0.1980 - val_loss: 2.2642 - val_accuracy: 0.1984\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2644 - accuracy: 0.1977 - val_loss: 2.2629 - val_accuracy: 0.1986\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2632 - accuracy: 0.1995 - val_loss: 2.2617 - val_accuracy: 0.1996\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2619 - accuracy: 0.2013 - val_loss: 2.2604 - val_accuracy: 0.2008\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2606 - accuracy: 0.2025 - val_loss: 2.2591 - val_accuracy: 0.2016\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2593 - accuracy: 0.2025 - val_loss: 2.2577 - val_accuracy: 0.2024\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2579 - accuracy: 0.2037 - val_loss: 2.2563 - val_accuracy: 0.2036\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2565 - accuracy: 0.2034 - val_loss: 2.2548 - val_accuracy: 0.2046\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2550 - accuracy: 0.2049 - val_loss: 2.2533 - val_accuracy: 0.2048\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2535 - accuracy: 0.2064 - val_loss: 2.2518 - val_accuracy: 0.2056\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2520 - accuracy: 0.2067 - val_loss: 2.2502 - val_accuracy: 0.2054\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2504 - accuracy: 0.2061 - val_loss: 2.2486 - val_accuracy: 0.2064\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2487 - accuracy: 0.2085 - val_loss: 2.2469 - val_accuracy: 0.2074\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2470 - accuracy: 0.2085 - val_loss: 2.2452 - val_accuracy: 0.2090\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2452 - accuracy: 0.2097 - val_loss: 2.2434 - val_accuracy: 0.2092\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2434 - accuracy: 0.2112 - val_loss: 2.2415 - val_accuracy: 0.2110\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2416 - accuracy: 0.2124 - val_loss: 2.2396 - val_accuracy: 0.2114\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2396 - accuracy: 0.2124 - val_loss: 2.2376 - val_accuracy: 0.2126\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2376 - accuracy: 0.2130 - val_loss: 2.2356 - val_accuracy: 0.2144\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2356 - accuracy: 0.2148 - val_loss: 2.2335 - val_accuracy: 0.2154\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2334 - accuracy: 0.2157 - val_loss: 2.2314 - val_accuracy: 0.2170\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2313 - accuracy: 0.2172 - val_loss: 2.2291 - val_accuracy: 0.2186\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2290 - accuracy: 0.2187 - val_loss: 2.2268 - val_accuracy: 0.2198\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2266 - accuracy: 0.2202 - val_loss: 2.2244 - val_accuracy: 0.2206\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2242 - accuracy: 0.2199 - val_loss: 2.2219 - val_accuracy: 0.2212\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2217 - accuracy: 0.2229 - val_loss: 2.2194 - val_accuracy: 0.2224\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2191 - accuracy: 0.2241 - val_loss: 2.2168 - val_accuracy: 0.2252\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2165 - accuracy: 0.2262 - val_loss: 2.2140 - val_accuracy: 0.2252\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2137 - accuracy: 0.2262 - val_loss: 2.2112 - val_accuracy: 0.2272\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2109 - accuracy: 0.2280 - val_loss: 2.2083 - val_accuracy: 0.2286\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2079 - accuracy: 0.2292 - val_loss: 2.2053 - val_accuracy: 0.2310\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2048 - accuracy: 0.2316 - val_loss: 2.2022 - val_accuracy: 0.2324\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2017 - accuracy: 0.2331 - val_loss: 2.1990 - val_accuracy: 0.2330\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1985 - accuracy: 0.2337 - val_loss: 2.1957 - val_accuracy: 0.2342\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1952 - accuracy: 0.2343 - val_loss: 2.1923 - val_accuracy: 0.2360\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1918 - accuracy: 0.2361 - val_loss: 2.1888 - val_accuracy: 0.2374\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1883 - accuracy: 0.2376 - val_loss: 2.1852 - val_accuracy: 0.2400\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1847 - accuracy: 0.2409 - val_loss: 2.1816 - val_accuracy: 0.2414\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1809 - accuracy: 0.2427 - val_loss: 2.1778 - val_accuracy: 0.2440\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1771 - accuracy: 0.2451 - val_loss: 2.1739 - val_accuracy: 0.2466\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1732 - accuracy: 0.2478 - val_loss: 2.1699 - val_accuracy: 0.2490\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1692 - accuracy: 0.2490 - val_loss: 2.1658 - val_accuracy: 0.2514\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1650 - accuracy: 0.2510 - val_loss: 2.1616 - val_accuracy: 0.2540\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1608 - accuracy: 0.2534 - val_loss: 2.1574 - val_accuracy: 0.2576\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 2.1549 - accuracy: 0.2611\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 13ms/step - loss: 2.3101 - accuracy: 0.0954 - val_loss: 2.2971 - val_accuracy: 0.1162\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2867 - accuracy: 0.1305 - val_loss: 2.2758 - val_accuracy: 0.1548\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2659 - accuracy: 0.1728 - val_loss: 2.2556 - val_accuracy: 0.1990\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2455 - accuracy: 0.2211 - val_loss: 2.2356 - val_accuracy: 0.2384\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2249 - accuracy: 0.2571 - val_loss: 2.2147 - val_accuracy: 0.2740\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2029 - accuracy: 0.2901 - val_loss: 2.1919 - val_accuracy: 0.3028\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.1784 - accuracy: 0.3144 - val_loss: 2.1660 - val_accuracy: 0.3290\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1503 - accuracy: 0.3468 - val_loss: 2.1366 - val_accuracy: 0.3584\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1186 - accuracy: 0.3744 - val_loss: 2.1036 - val_accuracy: 0.3804\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0830 - accuracy: 0.4014 - val_loss: 2.0666 - val_accuracy: 0.4094\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0433 - accuracy: 0.4302 - val_loss: 2.0255 - val_accuracy: 0.4410\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9993 - accuracy: 0.4668 - val_loss: 1.9801 - val_accuracy: 0.4652\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9510 - accuracy: 0.4818 - val_loss: 1.9308 - val_accuracy: 0.4904\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8983 - accuracy: 0.5077 - val_loss: 1.8770 - val_accuracy: 0.5124\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8412 - accuracy: 0.5251 - val_loss: 1.8189 - val_accuracy: 0.5348\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7799 - accuracy: 0.5455 - val_loss: 1.7563 - val_accuracy: 0.5582\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7140 - accuracy: 0.5695 - val_loss: 1.6902 - val_accuracy: 0.5810\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.6448 - accuracy: 0.5956 - val_loss: 1.6204 - val_accuracy: 0.6056\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.5723 - accuracy: 0.6169 - val_loss: 1.5472 - val_accuracy: 0.6296\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4968 - accuracy: 0.6424 - val_loss: 1.4725 - val_accuracy: 0.6468\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.4204 - accuracy: 0.6610 - val_loss: 1.3977 - val_accuracy: 0.6646\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.3446 - accuracy: 0.6796 - val_loss: 1.3239 - val_accuracy: 0.6912\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.2703 - accuracy: 0.7087 - val_loss: 1.2533 - val_accuracy: 0.7092\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1998 - accuracy: 0.7288 - val_loss: 1.1859 - val_accuracy: 0.7292\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1336 - accuracy: 0.7504 - val_loss: 1.1235 - val_accuracy: 0.7468\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0717 - accuracy: 0.7621 - val_loss: 1.0657 - val_accuracy: 0.7616\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0157 - accuracy: 0.7783 - val_loss: 1.0127 - val_accuracy: 0.7754\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9636 - accuracy: 0.7888 - val_loss: 0.9645 - val_accuracy: 0.7856\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9163 - accuracy: 0.8041 - val_loss: 0.9211 - val_accuracy: 0.7932\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8735 - accuracy: 0.8104 - val_loss: 0.8817 - val_accuracy: 0.7956\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8347 - accuracy: 0.8125 - val_loss: 0.8449 - val_accuracy: 0.8090\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7996 - accuracy: 0.8224 - val_loss: 0.8118 - val_accuracy: 0.8150\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7667 - accuracy: 0.8296 - val_loss: 0.7814 - val_accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7372 - accuracy: 0.8350 - val_loss: 0.7533 - val_accuracy: 0.8270\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7099 - accuracy: 0.8425 - val_loss: 0.7277 - val_accuracy: 0.8302\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6847 - accuracy: 0.8467 - val_loss: 0.7045 - val_accuracy: 0.8326\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6615 - accuracy: 0.8467 - val_loss: 0.6829 - val_accuracy: 0.8348\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6403 - accuracy: 0.8521 - val_loss: 0.6631 - val_accuracy: 0.8408\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6205 - accuracy: 0.8578 - val_loss: 0.6456 - val_accuracy: 0.8414\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6023 - accuracy: 0.8554 - val_loss: 0.6281 - val_accuracy: 0.8462\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5858 - accuracy: 0.8638 - val_loss: 0.6134 - val_accuracy: 0.8470\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5703 - accuracy: 0.8635 - val_loss: 0.5978 - val_accuracy: 0.8498\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5557 - accuracy: 0.8662 - val_loss: 0.5851 - val_accuracy: 0.8510\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5424 - accuracy: 0.8668 - val_loss: 0.5719 - val_accuracy: 0.8534\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5298 - accuracy: 0.8710 - val_loss: 0.5607 - val_accuracy: 0.8564\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5173 - accuracy: 0.8743 - val_loss: 0.5529 - val_accuracy: 0.8556\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5069 - accuracy: 0.8740 - val_loss: 0.5398 - val_accuracy: 0.8612\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.8764 - val_loss: 0.5300 - val_accuracy: 0.8638\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4859 - accuracy: 0.8824 - val_loss: 0.5208 - val_accuracy: 0.8648\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4766 - accuracy: 0.8824 - val_loss: 0.5140 - val_accuracy: 0.8668\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4682 - accuracy: 0.8857 - val_loss: 0.5057 - val_accuracy: 0.8654\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4596 - accuracy: 0.8881 - val_loss: 0.4971 - val_accuracy: 0.8696\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4514 - accuracy: 0.8875 - val_loss: 0.4880 - val_accuracy: 0.8724\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4438 - accuracy: 0.8914 - val_loss: 0.4815 - val_accuracy: 0.8728\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4363 - accuracy: 0.8941 - val_loss: 0.4742 - val_accuracy: 0.8738\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8923 - val_loss: 0.4687 - val_accuracy: 0.8754\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8959 - val_loss: 0.4612 - val_accuracy: 0.8776\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4155 - accuracy: 0.8983 - val_loss: 0.4572 - val_accuracy: 0.8772\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4097 - accuracy: 0.8974 - val_loss: 0.4496 - val_accuracy: 0.8794\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4036 - accuracy: 0.9001 - val_loss: 0.4449 - val_accuracy: 0.8812\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3979 - accuracy: 0.8989 - val_loss: 0.4393 - val_accuracy: 0.8824\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3923 - accuracy: 0.9007 - val_loss: 0.4336 - val_accuracy: 0.8842\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3869 - accuracy: 0.9034 - val_loss: 0.4301 - val_accuracy: 0.8844\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3817 - accuracy: 0.9040 - val_loss: 0.4252 - val_accuracy: 0.8842\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3768 - accuracy: 0.9040 - val_loss: 0.4197 - val_accuracy: 0.8874\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3716 - accuracy: 0.9058 - val_loss: 0.4166 - val_accuracy: 0.8886\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3674 - accuracy: 0.9055 - val_loss: 0.4117 - val_accuracy: 0.8892\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3627 - accuracy: 0.9100 - val_loss: 0.4069 - val_accuracy: 0.8912\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3582 - accuracy: 0.9118 - val_loss: 0.4032 - val_accuracy: 0.8922\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3538 - accuracy: 0.9112 - val_loss: 0.3986 - val_accuracy: 0.8952\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3495 - accuracy: 0.9157 - val_loss: 0.3953 - val_accuracy: 0.8950\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3453 - accuracy: 0.9145 - val_loss: 0.3927 - val_accuracy: 0.8966\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3414 - accuracy: 0.9148 - val_loss: 0.3887 - val_accuracy: 0.8968\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.9157 - val_loss: 0.3851 - val_accuracy: 0.8996\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3345 - accuracy: 0.9169 - val_loss: 0.3812 - val_accuracy: 0.8994\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3308 - accuracy: 0.9205 - val_loss: 0.3790 - val_accuracy: 0.8988\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3268 - accuracy: 0.9160 - val_loss: 0.3767 - val_accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3243 - accuracy: 0.9205 - val_loss: 0.3721 - val_accuracy: 0.9012\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 0.3204 - accuracy: 0.9193 - val_loss: 0.3686 - val_accuracy: 0.9008\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3175 - accuracy: 0.9205 - val_loss: 0.3678 - val_accuracy: 0.9020\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3144 - accuracy: 0.9214 - val_loss: 0.3633 - val_accuracy: 0.9026\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3115 - accuracy: 0.9211 - val_loss: 0.3606 - val_accuracy: 0.9024\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3082 - accuracy: 0.9223 - val_loss: 0.3578 - val_accuracy: 0.9038\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3052 - accuracy: 0.9214 - val_loss: 0.3552 - val_accuracy: 0.9054\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3026 - accuracy: 0.9238 - val_loss: 0.3518 - val_accuracy: 0.9052\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2995 - accuracy: 0.9232 - val_loss: 0.3503 - val_accuracy: 0.9062\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2971 - accuracy: 0.9232 - val_loss: 0.3479 - val_accuracy: 0.9058\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2944 - accuracy: 0.9247 - val_loss: 0.3453 - val_accuracy: 0.9060\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2916 - accuracy: 0.9265 - val_loss: 0.3428 - val_accuracy: 0.9068\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2893 - accuracy: 0.9259 - val_loss: 0.3417 - val_accuracy: 0.9082\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2864 - accuracy: 0.9277 - val_loss: 0.3402 - val_accuracy: 0.9082\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2842 - accuracy: 0.9259 - val_loss: 0.3377 - val_accuracy: 0.9084\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2816 - accuracy: 0.9271 - val_loss: 0.3345 - val_accuracy: 0.9078\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2796 - accuracy: 0.9262 - val_loss: 0.3327 - val_accuracy: 0.9094\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2769 - accuracy: 0.9289 - val_loss: 0.3322 - val_accuracy: 0.9094\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2748 - accuracy: 0.9286 - val_loss: 0.3289 - val_accuracy: 0.9096\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2722 - accuracy: 0.9292 - val_loss: 0.3264 - val_accuracy: 0.9108\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2706 - accuracy: 0.9283 - val_loss: 0.3239 - val_accuracy: 0.9110\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2682 - accuracy: 0.9289 - val_loss: 0.3226 - val_accuracy: 0.9112\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2661 - accuracy: 0.9310 - val_loss: 0.3204 - val_accuracy: 0.9128\n",
      "53/53 [==============================] - 1s 4ms/step - loss: 0.4360 - accuracy: 0.8752\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.3002 - accuracy: 0.0975 - val_loss: 2.2757 - val_accuracy: 0.1118\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2603 - accuracy: 0.1218 - val_loss: 2.2420 - val_accuracy: 0.1460\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2280 - accuracy: 0.1581 - val_loss: 2.2109 - val_accuracy: 0.1816\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1964 - accuracy: 0.1983 - val_loss: 2.1788 - val_accuracy: 0.2224\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1637 - accuracy: 0.2370 - val_loss: 2.1447 - val_accuracy: 0.2636\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1284 - accuracy: 0.2808 - val_loss: 2.1077 - val_accuracy: 0.3012\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0900 - accuracy: 0.3195 - val_loss: 2.0672 - val_accuracy: 0.3376\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0480 - accuracy: 0.3486 - val_loss: 2.0227 - val_accuracy: 0.3602\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0017 - accuracy: 0.3747 - val_loss: 1.9741 - val_accuracy: 0.3840\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9516 - accuracy: 0.4011 - val_loss: 1.9218 - val_accuracy: 0.4112\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8976 - accuracy: 0.4224 - val_loss: 1.8655 - val_accuracy: 0.4336\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8402 - accuracy: 0.4476 - val_loss: 1.8062 - val_accuracy: 0.4556\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7795 - accuracy: 0.4689 - val_loss: 1.7441 - val_accuracy: 0.4730\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7164 - accuracy: 0.4929 - val_loss: 1.6801 - val_accuracy: 0.5016\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.6515 - accuracy: 0.5266 - val_loss: 1.6138 - val_accuracy: 0.5316\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.5847 - accuracy: 0.5584 - val_loss: 1.5463 - val_accuracy: 0.5578\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.5166 - accuracy: 0.5818 - val_loss: 1.4783 - val_accuracy: 0.5802\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4484 - accuracy: 0.6046 - val_loss: 1.4096 - val_accuracy: 0.6090\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.3801 - accuracy: 0.6292 - val_loss: 1.3414 - val_accuracy: 0.6370\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3123 - accuracy: 0.6580 - val_loss: 1.2745 - val_accuracy: 0.6696\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2467 - accuracy: 0.6898 - val_loss: 1.2102 - val_accuracy: 0.6898\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1836 - accuracy: 0.7075 - val_loss: 1.1484 - val_accuracy: 0.7160\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1239 - accuracy: 0.7285 - val_loss: 1.0920 - val_accuracy: 0.7436\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0681 - accuracy: 0.7513 - val_loss: 1.0373 - val_accuracy: 0.7498\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0162 - accuracy: 0.7591 - val_loss: 0.9873 - val_accuracy: 0.7660\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9682 - accuracy: 0.7774 - val_loss: 0.9426 - val_accuracy: 0.7716\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9252 - accuracy: 0.7783 - val_loss: 0.9003 - val_accuracy: 0.7846\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8854 - accuracy: 0.7906 - val_loss: 0.8632 - val_accuracy: 0.7952\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8493 - accuracy: 0.8002 - val_loss: 0.8292 - val_accuracy: 0.8004\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8160 - accuracy: 0.8047 - val_loss: 0.7977 - val_accuracy: 0.8054\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7852 - accuracy: 0.8119 - val_loss: 0.7691 - val_accuracy: 0.8180\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7569 - accuracy: 0.8203 - val_loss: 0.7409 - val_accuracy: 0.8218\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7317 - accuracy: 0.8251 - val_loss: 0.7166 - val_accuracy: 0.8264\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7075 - accuracy: 0.8299 - val_loss: 0.6940 - val_accuracy: 0.8268\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6855 - accuracy: 0.8323 - val_loss: 0.6723 - val_accuracy: 0.8344\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6650 - accuracy: 0.8368 - val_loss: 0.6531 - val_accuracy: 0.8388\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6458 - accuracy: 0.8452 - val_loss: 0.6355 - val_accuracy: 0.8432\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6285 - accuracy: 0.8464 - val_loss: 0.6179 - val_accuracy: 0.8452\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6116 - accuracy: 0.8485 - val_loss: 0.6035 - val_accuracy: 0.8478\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5971 - accuracy: 0.8530 - val_loss: 0.5873 - val_accuracy: 0.8534\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5824 - accuracy: 0.8581 - val_loss: 0.5734 - val_accuracy: 0.8568\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5689 - accuracy: 0.8605 - val_loss: 0.5626 - val_accuracy: 0.8590\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5571 - accuracy: 0.8608 - val_loss: 0.5489 - val_accuracy: 0.8644\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.8650 - val_loss: 0.5379 - val_accuracy: 0.8658\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5332 - accuracy: 0.8707 - val_loss: 0.5273 - val_accuracy: 0.8690\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5229 - accuracy: 0.8683 - val_loss: 0.5172 - val_accuracy: 0.8710\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.8746 - val_loss: 0.5078 - val_accuracy: 0.8732\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5035 - accuracy: 0.8728 - val_loss: 0.5004 - val_accuracy: 0.8720\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4949 - accuracy: 0.8767 - val_loss: 0.4900 - val_accuracy: 0.8776\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4860 - accuracy: 0.8776 - val_loss: 0.4818 - val_accuracy: 0.8802\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4779 - accuracy: 0.8797 - val_loss: 0.4750 - val_accuracy: 0.8802\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.8806 - val_loss: 0.4673 - val_accuracy: 0.8816\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4627 - accuracy: 0.8839 - val_loss: 0.4612 - val_accuracy: 0.8810\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4561 - accuracy: 0.8848 - val_loss: 0.4528 - val_accuracy: 0.8846\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4485 - accuracy: 0.8869 - val_loss: 0.4467 - val_accuracy: 0.8868\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4423 - accuracy: 0.8869 - val_loss: 0.4403 - val_accuracy: 0.8884\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4361 - accuracy: 0.8887 - val_loss: 0.4342 - val_accuracy: 0.8890\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4306 - accuracy: 0.8893 - val_loss: 0.4288 - val_accuracy: 0.8888\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4244 - accuracy: 0.8905 - val_loss: 0.4236 - val_accuracy: 0.8910\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8941 - val_loss: 0.4184 - val_accuracy: 0.8912\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4139 - accuracy: 0.8917 - val_loss: 0.4140 - val_accuracy: 0.8924\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4093 - accuracy: 0.8944 - val_loss: 0.4079 - val_accuracy: 0.8936\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4039 - accuracy: 0.8962 - val_loss: 0.4049 - val_accuracy: 0.8938\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3991 - accuracy: 0.8956 - val_loss: 0.3997 - val_accuracy: 0.8972\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3946 - accuracy: 0.8995 - val_loss: 0.3955 - val_accuracy: 0.8948\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3903 - accuracy: 0.8944 - val_loss: 0.3910 - val_accuracy: 0.8962\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3857 - accuracy: 0.8974 - val_loss: 0.3875 - val_accuracy: 0.8982\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3819 - accuracy: 0.9025 - val_loss: 0.3862 - val_accuracy: 0.8954\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3784 - accuracy: 0.9007 - val_loss: 0.3816 - val_accuracy: 0.8988\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3743 - accuracy: 0.9013 - val_loss: 0.3773 - val_accuracy: 0.8998\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3706 - accuracy: 0.9043 - val_loss: 0.3742 - val_accuracy: 0.9008\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3671 - accuracy: 0.9043 - val_loss: 0.3717 - val_accuracy: 0.9008\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3638 - accuracy: 0.9037 - val_loss: 0.3672 - val_accuracy: 0.9022\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3601 - accuracy: 0.9064 - val_loss: 0.3638 - val_accuracy: 0.9026\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3564 - accuracy: 0.9076 - val_loss: 0.3614 - val_accuracy: 0.9034\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3534 - accuracy: 0.9079 - val_loss: 0.3602 - val_accuracy: 0.9008\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3504 - accuracy: 0.9064 - val_loss: 0.3545 - val_accuracy: 0.9040\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3473 - accuracy: 0.9079 - val_loss: 0.3519 - val_accuracy: 0.9082\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3445 - accuracy: 0.9115 - val_loss: 0.3493 - val_accuracy: 0.9078\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3414 - accuracy: 0.9118 - val_loss: 0.3468 - val_accuracy: 0.9072\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3385 - accuracy: 0.9145 - val_loss: 0.3464 - val_accuracy: 0.9050\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3362 - accuracy: 0.9112 - val_loss: 0.3417 - val_accuracy: 0.9078\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3328 - accuracy: 0.9130 - val_loss: 0.3399 - val_accuracy: 0.9094\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3303 - accuracy: 0.9130 - val_loss: 0.3393 - val_accuracy: 0.9102\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3273 - accuracy: 0.9139 - val_loss: 0.3353 - val_accuracy: 0.9100\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3249 - accuracy: 0.9154 - val_loss: 0.3328 - val_accuracy: 0.9098\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3225 - accuracy: 0.9139 - val_loss: 0.3303 - val_accuracy: 0.9112\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3200 - accuracy: 0.9160 - val_loss: 0.3289 - val_accuracy: 0.9086\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3174 - accuracy: 0.9169 - val_loss: 0.3267 - val_accuracy: 0.9112\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3151 - accuracy: 0.9169 - val_loss: 0.3263 - val_accuracy: 0.9100\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3137 - accuracy: 0.9166 - val_loss: 0.3225 - val_accuracy: 0.9122\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3107 - accuracy: 0.9190 - val_loss: 0.3217 - val_accuracy: 0.9118\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3086 - accuracy: 0.9190 - val_loss: 0.3202 - val_accuracy: 0.9122\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3069 - accuracy: 0.9184 - val_loss: 0.3160 - val_accuracy: 0.9136\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3043 - accuracy: 0.9199 - val_loss: 0.3137 - val_accuracy: 0.9154\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3021 - accuracy: 0.9196 - val_loss: 0.3120 - val_accuracy: 0.9150\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2999 - accuracy: 0.9202 - val_loss: 0.3112 - val_accuracy: 0.9158\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.2980 - accuracy: 0.9232 - val_loss: 0.3094 - val_accuracy: 0.9156\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2961 - accuracy: 0.9223 - val_loss: 0.3096 - val_accuracy: 0.9170\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.2943 - accuracy: 0.9220 - val_loss: 0.3090 - val_accuracy: 0.9164\n",
      "53/53 [==============================] - 1s 4ms/step - loss: 0.3398 - accuracy: 0.9016\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 2.2907 - accuracy: 0.0858 - val_loss: 2.2783 - val_accuracy: 0.0938\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2676 - accuracy: 0.1053 - val_loss: 2.2565 - val_accuracy: 0.1134\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2455 - accuracy: 0.1266 - val_loss: 2.2347 - val_accuracy: 0.1466\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2232 - accuracy: 0.1689 - val_loss: 2.2124 - val_accuracy: 0.1866\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1998 - accuracy: 0.2097 - val_loss: 2.1880 - val_accuracy: 0.2228\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1739 - accuracy: 0.2430 - val_loss: 2.1615 - val_accuracy: 0.2584\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1456 - accuracy: 0.2765 - val_loss: 2.1320 - val_accuracy: 0.2910\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1142 - accuracy: 0.3056 - val_loss: 2.0993 - val_accuracy: 0.3262\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0792 - accuracy: 0.3449 - val_loss: 2.0625 - val_accuracy: 0.3684\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0396 - accuracy: 0.3845 - val_loss: 2.0204 - val_accuracy: 0.4074\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9941 - accuracy: 0.4253 - val_loss: 1.9724 - val_accuracy: 0.4598\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9422 - accuracy: 0.4829 - val_loss: 1.9167 - val_accuracy: 0.5082\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.8823 - accuracy: 0.5318 - val_loss: 1.8530 - val_accuracy: 0.5598\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8136 - accuracy: 0.5831 - val_loss: 1.7796 - val_accuracy: 0.6074\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7352 - accuracy: 0.6317 - val_loss: 1.6976 - val_accuracy: 0.6502\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.6497 - accuracy: 0.6680 - val_loss: 1.6100 - val_accuracy: 0.6918\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5599 - accuracy: 0.7037 - val_loss: 1.5194 - val_accuracy: 0.7110\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.4685 - accuracy: 0.7202 - val_loss: 1.4284 - val_accuracy: 0.7216\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3782 - accuracy: 0.7307 - val_loss: 1.3402 - val_accuracy: 0.7314\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2924 - accuracy: 0.7388 - val_loss: 1.2575 - val_accuracy: 0.7384\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.2127 - accuracy: 0.7472 - val_loss: 1.1811 - val_accuracy: 0.7466\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.1397 - accuracy: 0.7484 - val_loss: 1.1124 - val_accuracy: 0.7538\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0743 - accuracy: 0.7567 - val_loss: 1.0501 - val_accuracy: 0.7630\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.0154 - accuracy: 0.7672 - val_loss: 0.9950 - val_accuracy: 0.7656\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9628 - accuracy: 0.7732 - val_loss: 0.9448 - val_accuracy: 0.7744\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.9156 - accuracy: 0.7816 - val_loss: 0.9002 - val_accuracy: 0.7858\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8731 - accuracy: 0.7924 - val_loss: 0.8604 - val_accuracy: 0.7924\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8351 - accuracy: 0.7972 - val_loss: 0.8239 - val_accuracy: 0.8032\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8007 - accuracy: 0.8083 - val_loss: 0.7910 - val_accuracy: 0.8062\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7692 - accuracy: 0.8113 - val_loss: 0.7618 - val_accuracy: 0.8140\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7404 - accuracy: 0.8176 - val_loss: 0.7347 - val_accuracy: 0.8196\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7147 - accuracy: 0.8236 - val_loss: 0.7099 - val_accuracy: 0.8248\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6906 - accuracy: 0.8251 - val_loss: 0.6883 - val_accuracy: 0.8286\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6688 - accuracy: 0.8338 - val_loss: 0.6660 - val_accuracy: 0.8312\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6484 - accuracy: 0.8344 - val_loss: 0.6472 - val_accuracy: 0.8328\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6296 - accuracy: 0.8368 - val_loss: 0.6286 - val_accuracy: 0.8350\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6122 - accuracy: 0.8422 - val_loss: 0.6120 - val_accuracy: 0.8400\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5961 - accuracy: 0.8434 - val_loss: 0.5970 - val_accuracy: 0.8420\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5809 - accuracy: 0.8428 - val_loss: 0.5827 - val_accuracy: 0.8458\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5668 - accuracy: 0.8491 - val_loss: 0.5689 - val_accuracy: 0.8484\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5539 - accuracy: 0.8497 - val_loss: 0.5568 - val_accuracy: 0.8508\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5413 - accuracy: 0.8527 - val_loss: 0.5458 - val_accuracy: 0.8524\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.8548 - val_loss: 0.5357 - val_accuracy: 0.8560\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5190 - accuracy: 0.8581 - val_loss: 0.5249 - val_accuracy: 0.8574\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.8593 - val_loss: 0.5151 - val_accuracy: 0.8604\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.8635 - val_loss: 0.5086 - val_accuracy: 0.8578\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4910 - accuracy: 0.8671 - val_loss: 0.4970 - val_accuracy: 0.8654\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4816 - accuracy: 0.8692 - val_loss: 0.4892 - val_accuracy: 0.8662\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.8686 - val_loss: 0.4822 - val_accuracy: 0.8672\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4660 - accuracy: 0.8722 - val_loss: 0.4743 - val_accuracy: 0.8690\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4580 - accuracy: 0.8737 - val_loss: 0.4695 - val_accuracy: 0.8690\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4514 - accuracy: 0.8740 - val_loss: 0.4612 - val_accuracy: 0.8740\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4447 - accuracy: 0.8743 - val_loss: 0.4544 - val_accuracy: 0.8754\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4379 - accuracy: 0.8779 - val_loss: 0.4487 - val_accuracy: 0.8766\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8800 - val_loss: 0.4455 - val_accuracy: 0.8768\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8803 - val_loss: 0.4380 - val_accuracy: 0.8790\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4205 - accuracy: 0.8800 - val_loss: 0.4325 - val_accuracy: 0.8794\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4155 - accuracy: 0.8830 - val_loss: 0.4293 - val_accuracy: 0.8814\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4103 - accuracy: 0.8866 - val_loss: 0.4232 - val_accuracy: 0.8836\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4048 - accuracy: 0.8860 - val_loss: 0.4185 - val_accuracy: 0.8844\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4003 - accuracy: 0.8887 - val_loss: 0.4161 - val_accuracy: 0.8844\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3961 - accuracy: 0.8902 - val_loss: 0.4109 - val_accuracy: 0.8872\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3916 - accuracy: 0.8908 - val_loss: 0.4067 - val_accuracy: 0.8874\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3873 - accuracy: 0.8908 - val_loss: 0.4045 - val_accuracy: 0.8886\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3832 - accuracy: 0.8917 - val_loss: 0.3996 - val_accuracy: 0.8910\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3794 - accuracy: 0.8944 - val_loss: 0.3963 - val_accuracy: 0.8904\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3755 - accuracy: 0.8944 - val_loss: 0.3932 - val_accuracy: 0.8914\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3722 - accuracy: 0.8950 - val_loss: 0.3899 - val_accuracy: 0.8910\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3683 - accuracy: 0.8956 - val_loss: 0.3857 - val_accuracy: 0.8926\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3644 - accuracy: 0.8968 - val_loss: 0.3826 - val_accuracy: 0.8922\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3615 - accuracy: 0.8986 - val_loss: 0.3799 - val_accuracy: 0.8942\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3586 - accuracy: 0.8974 - val_loss: 0.3775 - val_accuracy: 0.8924\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3552 - accuracy: 0.9004 - val_loss: 0.3747 - val_accuracy: 0.8942\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3525 - accuracy: 0.8986 - val_loss: 0.3713 - val_accuracy: 0.8964\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3490 - accuracy: 0.9007 - val_loss: 0.3695 - val_accuracy: 0.8946\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3460 - accuracy: 0.9007 - val_loss: 0.3665 - val_accuracy: 0.8966\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3435 - accuracy: 0.9025 - val_loss: 0.3644 - val_accuracy: 0.8966\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3408 - accuracy: 0.9007 - val_loss: 0.3620 - val_accuracy: 0.8980\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.9043 - val_loss: 0.3594 - val_accuracy: 0.8976\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3354 - accuracy: 0.9037 - val_loss: 0.3579 - val_accuracy: 0.8974\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3321 - accuracy: 0.9058 - val_loss: 0.3551 - val_accuracy: 0.8990\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3300 - accuracy: 0.9067 - val_loss: 0.3527 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3280 - accuracy: 0.9073 - val_loss: 0.3505 - val_accuracy: 0.9002\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3254 - accuracy: 0.9067 - val_loss: 0.3486 - val_accuracy: 0.9012\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3228 - accuracy: 0.9052 - val_loss: 0.3466 - val_accuracy: 0.9008\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3205 - accuracy: 0.9079 - val_loss: 0.3452 - val_accuracy: 0.9008\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.3184 - accuracy: 0.9082 - val_loss: 0.3431 - val_accuracy: 0.9024\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3161 - accuracy: 0.9088 - val_loss: 0.3405 - val_accuracy: 0.9030\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3137 - accuracy: 0.9121 - val_loss: 0.3389 - val_accuracy: 0.9028\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3119 - accuracy: 0.9103 - val_loss: 0.3370 - val_accuracy: 0.9028\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3097 - accuracy: 0.9094 - val_loss: 0.3346 - val_accuracy: 0.9044\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3076 - accuracy: 0.9112 - val_loss: 0.3331 - val_accuracy: 0.9054\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3056 - accuracy: 0.9121 - val_loss: 0.3317 - val_accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3035 - accuracy: 0.9130 - val_loss: 0.3296 - val_accuracy: 0.9064\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3015 - accuracy: 0.9130 - val_loss: 0.3274 - val_accuracy: 0.9068\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2991 - accuracy: 0.9157 - val_loss: 0.3258 - val_accuracy: 0.9072\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2976 - accuracy: 0.9157 - val_loss: 0.3245 - val_accuracy: 0.9066\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2955 - accuracy: 0.9184 - val_loss: 0.3230 - val_accuracy: 0.9084\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2941 - accuracy: 0.9160 - val_loss: 0.3209 - val_accuracy: 0.9088\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2923 - accuracy: 0.9178 - val_loss: 0.3196 - val_accuracy: 0.9088\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8896\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.2799 - accuracy: 0.1245 - val_loss: 2.2220 - val_accuracy: 0.1552\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1716 - accuracy: 0.2046 - val_loss: 2.1216 - val_accuracy: 0.2588\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0692 - accuracy: 0.3045 - val_loss: 2.0215 - val_accuracy: 0.3484\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.9643 - accuracy: 0.3933 - val_loss: 1.9155 - val_accuracy: 0.4268\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8533 - accuracy: 0.4704 - val_loss: 1.8040 - val_accuracy: 0.5122\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7376 - accuracy: 0.5683 - val_loss: 1.6885 - val_accuracy: 0.5984\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.6208 - accuracy: 0.6430 - val_loss: 1.5750 - val_accuracy: 0.6596\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.5075 - accuracy: 0.6907 - val_loss: 1.4658 - val_accuracy: 0.6974\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.3997 - accuracy: 0.7168 - val_loss: 1.3637 - val_accuracy: 0.7230\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.2992 - accuracy: 0.7369 - val_loss: 1.2690 - val_accuracy: 0.7406\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.2065 - accuracy: 0.7537 - val_loss: 1.1819 - val_accuracy: 0.7568\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.1216 - accuracy: 0.7717 - val_loss: 1.1028 - val_accuracy: 0.7704\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0448 - accuracy: 0.7849 - val_loss: 1.0318 - val_accuracy: 0.7854\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.9764 - accuracy: 0.8035 - val_loss: 0.9689 - val_accuracy: 0.7956\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.9155 - accuracy: 0.8134 - val_loss: 0.9134 - val_accuracy: 0.8090\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8616 - accuracy: 0.8227 - val_loss: 0.8654 - val_accuracy: 0.8140\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8145 - accuracy: 0.8275 - val_loss: 0.8212 - val_accuracy: 0.8274\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7722 - accuracy: 0.8356 - val_loss: 0.7830 - val_accuracy: 0.8334\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.7349 - accuracy: 0.8461 - val_loss: 0.7485 - val_accuracy: 0.8384\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7017 - accuracy: 0.8509 - val_loss: 0.7175 - val_accuracy: 0.8408\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6717 - accuracy: 0.8563 - val_loss: 0.6904 - val_accuracy: 0.8466\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6448 - accuracy: 0.8614 - val_loss: 0.6672 - val_accuracy: 0.8490\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.6207 - accuracy: 0.8617 - val_loss: 0.6445 - val_accuracy: 0.8516\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5987 - accuracy: 0.8689 - val_loss: 0.6228 - val_accuracy: 0.8558\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5784 - accuracy: 0.8683 - val_loss: 0.6044 - val_accuracy: 0.8568\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5598 - accuracy: 0.8713 - val_loss: 0.5871 - val_accuracy: 0.8606\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.8752 - val_loss: 0.5724 - val_accuracy: 0.8638\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5274 - accuracy: 0.8809 - val_loss: 0.5571 - val_accuracy: 0.8688\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5127 - accuracy: 0.8845 - val_loss: 0.5440 - val_accuracy: 0.8688\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4996 - accuracy: 0.8863 - val_loss: 0.5317 - val_accuracy: 0.8708\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4874 - accuracy: 0.8899 - val_loss: 0.5199 - val_accuracy: 0.8740\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4758 - accuracy: 0.8911 - val_loss: 0.5089 - val_accuracy: 0.8762\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4646 - accuracy: 0.8932 - val_loss: 0.4986 - val_accuracy: 0.8794\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4546 - accuracy: 0.8944 - val_loss: 0.4890 - val_accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.8983 - val_loss: 0.4807 - val_accuracy: 0.8840\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.9001 - val_loss: 0.4723 - val_accuracy: 0.8846\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4279 - accuracy: 0.8995 - val_loss: 0.4657 - val_accuracy: 0.8850\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.9016 - val_loss: 0.4575 - val_accuracy: 0.8864\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4123 - accuracy: 0.9040 - val_loss: 0.4506 - val_accuracy: 0.8880\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4053 - accuracy: 0.9022 - val_loss: 0.4438 - val_accuracy: 0.8902\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3983 - accuracy: 0.9046 - val_loss: 0.4378 - val_accuracy: 0.8918\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3920 - accuracy: 0.9088 - val_loss: 0.4312 - val_accuracy: 0.8942\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3858 - accuracy: 0.9100 - val_loss: 0.4272 - val_accuracy: 0.8938\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3801 - accuracy: 0.9106 - val_loss: 0.4210 - val_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3742 - accuracy: 0.9112 - val_loss: 0.4159 - val_accuracy: 0.8962\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3690 - accuracy: 0.9136 - val_loss: 0.4111 - val_accuracy: 0.8978\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3638 - accuracy: 0.9148 - val_loss: 0.4066 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3586 - accuracy: 0.9151 - val_loss: 0.4021 - val_accuracy: 0.8988\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3540 - accuracy: 0.9157 - val_loss: 0.3980 - val_accuracy: 0.9012\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3494 - accuracy: 0.9175 - val_loss: 0.3935 - val_accuracy: 0.9002\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3450 - accuracy: 0.9166 - val_loss: 0.3892 - val_accuracy: 0.9030\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3408 - accuracy: 0.9187 - val_loss: 0.3855 - val_accuracy: 0.9028\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3367 - accuracy: 0.9199 - val_loss: 0.3820 - val_accuracy: 0.9016\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3327 - accuracy: 0.9190 - val_loss: 0.3786 - val_accuracy: 0.9036\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3289 - accuracy: 0.9211 - val_loss: 0.3761 - val_accuracy: 0.9050\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3255 - accuracy: 0.9208 - val_loss: 0.3713 - val_accuracy: 0.9068\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3217 - accuracy: 0.9229 - val_loss: 0.3682 - val_accuracy: 0.9062\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3182 - accuracy: 0.9226 - val_loss: 0.3650 - val_accuracy: 0.9058\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3148 - accuracy: 0.9238 - val_loss: 0.3622 - val_accuracy: 0.9080\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3117 - accuracy: 0.9250 - val_loss: 0.3597 - val_accuracy: 0.9090\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.9262 - val_loss: 0.3573 - val_accuracy: 0.9098\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3054 - accuracy: 0.9259 - val_loss: 0.3538 - val_accuracy: 0.9084\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3022 - accuracy: 0.9256 - val_loss: 0.3516 - val_accuracy: 0.9086\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2995 - accuracy: 0.9256 - val_loss: 0.3484 - val_accuracy: 0.9090\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.2966 - accuracy: 0.9262 - val_loss: 0.3459 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2938 - accuracy: 0.9280 - val_loss: 0.3436 - val_accuracy: 0.9116\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2913 - accuracy: 0.9274 - val_loss: 0.3415 - val_accuracy: 0.9106\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2886 - accuracy: 0.9292 - val_loss: 0.3394 - val_accuracy: 0.9096\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2863 - accuracy: 0.9301 - val_loss: 0.3370 - val_accuracy: 0.9116\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2838 - accuracy: 0.9304 - val_loss: 0.3347 - val_accuracy: 0.9130\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2809 - accuracy: 0.9316 - val_loss: 0.3323 - val_accuracy: 0.9136\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2789 - accuracy: 0.9307 - val_loss: 0.3301 - val_accuracy: 0.9136\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2765 - accuracy: 0.9310 - val_loss: 0.3283 - val_accuracy: 0.9146\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2742 - accuracy: 0.9313 - val_loss: 0.3273 - val_accuracy: 0.9148\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2720 - accuracy: 0.9316 - val_loss: 0.3253 - val_accuracy: 0.9152\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2700 - accuracy: 0.9316 - val_loss: 0.3228 - val_accuracy: 0.9142\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2679 - accuracy: 0.9328 - val_loss: 0.3219 - val_accuracy: 0.9164\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2657 - accuracy: 0.9343 - val_loss: 0.3205 - val_accuracy: 0.9158\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2635 - accuracy: 0.9322 - val_loss: 0.3193 - val_accuracy: 0.9166\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2620 - accuracy: 0.9364 - val_loss: 0.3162 - val_accuracy: 0.9174\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2597 - accuracy: 0.9361 - val_loss: 0.3144 - val_accuracy: 0.9182\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2578 - accuracy: 0.9355 - val_loss: 0.3129 - val_accuracy: 0.9186\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2558 - accuracy: 0.9343 - val_loss: 0.3107 - val_accuracy: 0.9178\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2539 - accuracy: 0.9361 - val_loss: 0.3088 - val_accuracy: 0.9182\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2523 - accuracy: 0.9358 - val_loss: 0.3081 - val_accuracy: 0.9194\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2506 - accuracy: 0.9379 - val_loss: 0.3067 - val_accuracy: 0.9190\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2488 - accuracy: 0.9367 - val_loss: 0.3046 - val_accuracy: 0.9206\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2471 - accuracy: 0.9397 - val_loss: 0.3039 - val_accuracy: 0.9202\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2456 - accuracy: 0.9370 - val_loss: 0.3022 - val_accuracy: 0.9194\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2436 - accuracy: 0.9391 - val_loss: 0.3016 - val_accuracy: 0.9198\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2422 - accuracy: 0.9379 - val_loss: 0.2992 - val_accuracy: 0.9214\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2404 - accuracy: 0.9397 - val_loss: 0.2980 - val_accuracy: 0.9202\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2391 - accuracy: 0.9409 - val_loss: 0.2969 - val_accuracy: 0.9212\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2372 - accuracy: 0.9421 - val_loss: 0.2961 - val_accuracy: 0.9206\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2356 - accuracy: 0.9409 - val_loss: 0.2940 - val_accuracy: 0.9222\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2344 - accuracy: 0.9409 - val_loss: 0.2930 - val_accuracy: 0.9236\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.2331 - accuracy: 0.9418 - val_loss: 0.2914 - val_accuracy: 0.9236\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2311 - accuracy: 0.9421 - val_loss: 0.2912 - val_accuracy: 0.9240\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2302 - accuracy: 0.9433 - val_loss: 0.2892 - val_accuracy: 0.9236\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2284 - accuracy: 0.9433 - val_loss: 0.2881 - val_accuracy: 0.9236\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8818\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 2.3406 - accuracy: 0.1371 - val_loss: 2.3011 - val_accuracy: 0.1554\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2728 - accuracy: 0.1803 - val_loss: 2.2411 - val_accuracy: 0.2116\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2150 - accuracy: 0.2406 - val_loss: 2.1848 - val_accuracy: 0.2832\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.1581 - accuracy: 0.3192 - val_loss: 2.1266 - val_accuracy: 0.3600\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.0977 - accuracy: 0.3981 - val_loss: 2.0629 - val_accuracy: 0.4402\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0313 - accuracy: 0.4671 - val_loss: 1.9925 - val_accuracy: 0.5072\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.9584 - accuracy: 0.5314 - val_loss: 1.9160 - val_accuracy: 0.5676\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8797 - accuracy: 0.5839 - val_loss: 1.8338 - val_accuracy: 0.6158\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.7956 - accuracy: 0.6259 - val_loss: 1.7461 - val_accuracy: 0.6552\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7067 - accuracy: 0.6544 - val_loss: 1.6547 - val_accuracy: 0.6790\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.6148 - accuracy: 0.6715 - val_loss: 1.5613 - val_accuracy: 0.6996\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5219 - accuracy: 0.6973 - val_loss: 1.4678 - val_accuracy: 0.7138\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.4301 - accuracy: 0.7138 - val_loss: 1.3768 - val_accuracy: 0.7266\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.3414 - accuracy: 0.7249 - val_loss: 1.2898 - val_accuracy: 0.7392\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.2578 - accuracy: 0.7372 - val_loss: 1.2090 - val_accuracy: 0.7524\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1802 - accuracy: 0.7510 - val_loss: 1.1339 - val_accuracy: 0.7656\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1087 - accuracy: 0.7618 - val_loss: 1.0655 - val_accuracy: 0.7758\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.0440 - accuracy: 0.7750 - val_loss: 1.0042 - val_accuracy: 0.7836\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9859 - accuracy: 0.7795 - val_loss: 0.9493 - val_accuracy: 0.7920\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.9346 - accuracy: 0.7894 - val_loss: 0.9007 - val_accuracy: 0.7980\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8884 - accuracy: 0.7960 - val_loss: 0.8578 - val_accuracy: 0.8062\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8469 - accuracy: 0.8071 - val_loss: 0.8180 - val_accuracy: 0.8180\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8100 - accuracy: 0.8134 - val_loss: 0.7830 - val_accuracy: 0.8218\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7765 - accuracy: 0.8221 - val_loss: 0.7516 - val_accuracy: 0.8262\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7465 - accuracy: 0.8272 - val_loss: 0.7229 - val_accuracy: 0.8312\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7191 - accuracy: 0.8323 - val_loss: 0.6972 - val_accuracy: 0.8364\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6945 - accuracy: 0.8386 - val_loss: 0.6738 - val_accuracy: 0.8402\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6717 - accuracy: 0.8413 - val_loss: 0.6529 - val_accuracy: 0.8448\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6515 - accuracy: 0.8473 - val_loss: 0.6335 - val_accuracy: 0.8472\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6324 - accuracy: 0.8467 - val_loss: 0.6151 - val_accuracy: 0.8512\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6146 - accuracy: 0.8539 - val_loss: 0.5986 - val_accuracy: 0.8536\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5985 - accuracy: 0.8557 - val_loss: 0.5836 - val_accuracy: 0.8550\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.5837 - accuracy: 0.8566 - val_loss: 0.5692 - val_accuracy: 0.8578\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.8614 - val_loss: 0.5558 - val_accuracy: 0.8606\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5561 - accuracy: 0.8629 - val_loss: 0.5436 - val_accuracy: 0.8664\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.8662 - val_loss: 0.5317 - val_accuracy: 0.8704\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5328 - accuracy: 0.8680 - val_loss: 0.5209 - val_accuracy: 0.8684\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5219 - accuracy: 0.8695 - val_loss: 0.5108 - val_accuracy: 0.8698\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5117 - accuracy: 0.8707 - val_loss: 0.5012 - val_accuracy: 0.8722\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5021 - accuracy: 0.8731 - val_loss: 0.4923 - val_accuracy: 0.8732\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4932 - accuracy: 0.8761 - val_loss: 0.4839 - val_accuracy: 0.8756\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4847 - accuracy: 0.8752 - val_loss: 0.4767 - val_accuracy: 0.8792\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4765 - accuracy: 0.8797 - val_loss: 0.4691 - val_accuracy: 0.8800\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4690 - accuracy: 0.8803 - val_loss: 0.4609 - val_accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4614 - accuracy: 0.8848 - val_loss: 0.4542 - val_accuracy: 0.8836\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4545 - accuracy: 0.8845 - val_loss: 0.4476 - val_accuracy: 0.8852\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4479 - accuracy: 0.8857 - val_loss: 0.4419 - val_accuracy: 0.8858\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4417 - accuracy: 0.8854 - val_loss: 0.4356 - val_accuracy: 0.8876\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.8878 - val_loss: 0.4301 - val_accuracy: 0.8886\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4299 - accuracy: 0.8911 - val_loss: 0.4250 - val_accuracy: 0.8888\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4245 - accuracy: 0.8911 - val_loss: 0.4195 - val_accuracy: 0.8894\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4188 - accuracy: 0.8917 - val_loss: 0.4150 - val_accuracy: 0.8914\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4138 - accuracy: 0.8917 - val_loss: 0.4106 - val_accuracy: 0.8946\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4091 - accuracy: 0.8959 - val_loss: 0.4054 - val_accuracy: 0.8930\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4044 - accuracy: 0.8956 - val_loss: 0.4014 - val_accuracy: 0.8946\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3999 - accuracy: 0.8962 - val_loss: 0.3971 - val_accuracy: 0.8954\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3955 - accuracy: 0.8986 - val_loss: 0.3932 - val_accuracy: 0.8950\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3911 - accuracy: 0.8980 - val_loss: 0.3896 - val_accuracy: 0.8966\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3873 - accuracy: 0.8974 - val_loss: 0.3869 - val_accuracy: 0.8978\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3836 - accuracy: 0.9007 - val_loss: 0.3818 - val_accuracy: 0.8984\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8998 - val_loss: 0.3789 - val_accuracy: 0.8992\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3756 - accuracy: 0.9022 - val_loss: 0.3758 - val_accuracy: 0.9010\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3721 - accuracy: 0.9028 - val_loss: 0.3720 - val_accuracy: 0.9018\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3686 - accuracy: 0.9049 - val_loss: 0.3693 - val_accuracy: 0.9016\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3656 - accuracy: 0.9040 - val_loss: 0.3661 - val_accuracy: 0.9032\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3622 - accuracy: 0.9049 - val_loss: 0.3631 - val_accuracy: 0.9042\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3593 - accuracy: 0.9064 - val_loss: 0.3602 - val_accuracy: 0.9052\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3559 - accuracy: 0.9070 - val_loss: 0.3579 - val_accuracy: 0.9040\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3530 - accuracy: 0.9088 - val_loss: 0.3563 - val_accuracy: 0.9058\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3506 - accuracy: 0.9115 - val_loss: 0.3522 - val_accuracy: 0.9070\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3472 - accuracy: 0.9097 - val_loss: 0.3496 - val_accuracy: 0.9070\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3442 - accuracy: 0.9112 - val_loss: 0.3471 - val_accuracy: 0.9076\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3418 - accuracy: 0.9109 - val_loss: 0.3451 - val_accuracy: 0.9090\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3394 - accuracy: 0.9121 - val_loss: 0.3422 - val_accuracy: 0.9090\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3366 - accuracy: 0.9124 - val_loss: 0.3414 - val_accuracy: 0.9072\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3343 - accuracy: 0.9109 - val_loss: 0.3378 - val_accuracy: 0.9096\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3317 - accuracy: 0.9124 - val_loss: 0.3355 - val_accuracy: 0.9104\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3291 - accuracy: 0.9130 - val_loss: 0.3340 - val_accuracy: 0.9112\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3268 - accuracy: 0.9139 - val_loss: 0.3317 - val_accuracy: 0.9102\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3247 - accuracy: 0.9139 - val_loss: 0.3292 - val_accuracy: 0.9106\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3220 - accuracy: 0.9136 - val_loss: 0.3275 - val_accuracy: 0.9112\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3200 - accuracy: 0.9145 - val_loss: 0.3254 - val_accuracy: 0.9126\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3178 - accuracy: 0.9166 - val_loss: 0.3239 - val_accuracy: 0.9126\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3157 - accuracy: 0.9157 - val_loss: 0.3221 - val_accuracy: 0.9132\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3140 - accuracy: 0.9181 - val_loss: 0.3196 - val_accuracy: 0.9144\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3117 - accuracy: 0.9184 - val_loss: 0.3181 - val_accuracy: 0.9128\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3095 - accuracy: 0.9163 - val_loss: 0.3164 - val_accuracy: 0.9158\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3076 - accuracy: 0.9181 - val_loss: 0.3144 - val_accuracy: 0.9162\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3058 - accuracy: 0.9202 - val_loss: 0.3129 - val_accuracy: 0.9164\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3039 - accuracy: 0.9196 - val_loss: 0.3111 - val_accuracy: 0.9164\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3018 - accuracy: 0.9184 - val_loss: 0.3096 - val_accuracy: 0.9168\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3001 - accuracy: 0.9199 - val_loss: 0.3082 - val_accuracy: 0.9174\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2980 - accuracy: 0.9217 - val_loss: 0.3063 - val_accuracy: 0.9162\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2965 - accuracy: 0.9193 - val_loss: 0.3050 - val_accuracy: 0.9182\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2945 - accuracy: 0.9217 - val_loss: 0.3034 - val_accuracy: 0.9194\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2927 - accuracy: 0.9229 - val_loss: 0.3023 - val_accuracy: 0.9174\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2915 - accuracy: 0.9217 - val_loss: 0.3006 - val_accuracy: 0.9194\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2896 - accuracy: 0.9229 - val_loss: 0.2988 - val_accuracy: 0.9186\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2878 - accuracy: 0.9232 - val_loss: 0.2981 - val_accuracy: 0.9190\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2863 - accuracy: 0.9247 - val_loss: 0.2965 - val_accuracy: 0.9194\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.9094\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3189 - accuracy: 0.1290 - val_loss: 2.2855 - val_accuracy: 0.1540\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2586 - accuracy: 0.1887 - val_loss: 2.2292 - val_accuracy: 0.2122\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2013 - accuracy: 0.2463 - val_loss: 2.1721 - val_accuracy: 0.2740\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1415 - accuracy: 0.3122 - val_loss: 2.1109 - val_accuracy: 0.3358\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.0771 - accuracy: 0.3776 - val_loss: 2.0443 - val_accuracy: 0.3994\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0067 - accuracy: 0.4409 - val_loss: 1.9715 - val_accuracy: 0.4692\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.9308 - accuracy: 0.5039 - val_loss: 1.8936 - val_accuracy: 0.5314\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8497 - accuracy: 0.5588 - val_loss: 1.8105 - val_accuracy: 0.5848\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.7637 - accuracy: 0.6029 - val_loss: 1.7230 - val_accuracy: 0.6272\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.6739 - accuracy: 0.6437 - val_loss: 1.6319 - val_accuracy: 0.6654\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5813 - accuracy: 0.6818 - val_loss: 1.5397 - val_accuracy: 0.6972\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.4885 - accuracy: 0.7124 - val_loss: 1.4478 - val_accuracy: 0.7184\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.3971 - accuracy: 0.7307 - val_loss: 1.3586 - val_accuracy: 0.7424\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3089 - accuracy: 0.7531 - val_loss: 1.2726 - val_accuracy: 0.7566\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.2246 - accuracy: 0.7672 - val_loss: 1.1915 - val_accuracy: 0.7700\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1458 - accuracy: 0.7846 - val_loss: 1.1159 - val_accuracy: 0.7796\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0732 - accuracy: 0.7888 - val_loss: 1.0474 - val_accuracy: 0.7868\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0076 - accuracy: 0.7981 - val_loss: 0.9857 - val_accuracy: 0.7954\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9490 - accuracy: 0.8068 - val_loss: 0.9307 - val_accuracy: 0.8036\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8966 - accuracy: 0.8119 - val_loss: 0.8824 - val_accuracy: 0.8058\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8502 - accuracy: 0.8164 - val_loss: 0.8381 - val_accuracy: 0.8142\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8086 - accuracy: 0.8221 - val_loss: 0.8006 - val_accuracy: 0.8162\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7723 - accuracy: 0.8254 - val_loss: 0.7648 - val_accuracy: 0.8274\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7393 - accuracy: 0.8347 - val_loss: 0.7337 - val_accuracy: 0.8320\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7096 - accuracy: 0.8383 - val_loss: 0.7058 - val_accuracy: 0.8346\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.6828 - accuracy: 0.8413 - val_loss: 0.6804 - val_accuracy: 0.8364\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6585 - accuracy: 0.8467 - val_loss: 0.6570 - val_accuracy: 0.8422\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6365 - accuracy: 0.8494 - val_loss: 0.6361 - val_accuracy: 0.8470\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6165 - accuracy: 0.8539 - val_loss: 0.6168 - val_accuracy: 0.8488\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5982 - accuracy: 0.8557 - val_loss: 0.6000 - val_accuracy: 0.8526\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.5812 - accuracy: 0.8614 - val_loss: 0.5836 - val_accuracy: 0.8570\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5657 - accuracy: 0.8629 - val_loss: 0.5691 - val_accuracy: 0.8584\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5514 - accuracy: 0.8665 - val_loss: 0.5546 - val_accuracy: 0.8624\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5378 - accuracy: 0.8680 - val_loss: 0.5421 - val_accuracy: 0.8658\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5253 - accuracy: 0.8716 - val_loss: 0.5299 - val_accuracy: 0.8672\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5136 - accuracy: 0.8740 - val_loss: 0.5196 - val_accuracy: 0.8678\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5030 - accuracy: 0.8752 - val_loss: 0.5087 - val_accuracy: 0.8710\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4924 - accuracy: 0.8791 - val_loss: 0.4987 - val_accuracy: 0.8718\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.8797 - val_loss: 0.4896 - val_accuracy: 0.8748\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.8821 - val_loss: 0.4815 - val_accuracy: 0.8760\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4649 - accuracy: 0.8836 - val_loss: 0.4733 - val_accuracy: 0.8780\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4571 - accuracy: 0.8845 - val_loss: 0.4655 - val_accuracy: 0.8806\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4493 - accuracy: 0.8872 - val_loss: 0.4577 - val_accuracy: 0.8818\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4417 - accuracy: 0.8875 - val_loss: 0.4507 - val_accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4348 - accuracy: 0.8878 - val_loss: 0.4444 - val_accuracy: 0.8838\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4280 - accuracy: 0.8899 - val_loss: 0.4375 - val_accuracy: 0.8844\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4218 - accuracy: 0.8914 - val_loss: 0.4315 - val_accuracy: 0.8876\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4156 - accuracy: 0.8920 - val_loss: 0.4255 - val_accuracy: 0.8880\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4098 - accuracy: 0.8926 - val_loss: 0.4201 - val_accuracy: 0.8892\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4042 - accuracy: 0.8935 - val_loss: 0.4151 - val_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3988 - accuracy: 0.8950 - val_loss: 0.4103 - val_accuracy: 0.8904\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3936 - accuracy: 0.8944 - val_loss: 0.4052 - val_accuracy: 0.8936\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3889 - accuracy: 0.8977 - val_loss: 0.4005 - val_accuracy: 0.8938\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3843 - accuracy: 0.8992 - val_loss: 0.3964 - val_accuracy: 0.8956\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3796 - accuracy: 0.8992 - val_loss: 0.3922 - val_accuracy: 0.8950\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3754 - accuracy: 0.9007 - val_loss: 0.3877 - val_accuracy: 0.8968\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3711 - accuracy: 0.9013 - val_loss: 0.3839 - val_accuracy: 0.8976\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3669 - accuracy: 0.9010 - val_loss: 0.3802 - val_accuracy: 0.8986\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3632 - accuracy: 0.9013 - val_loss: 0.3763 - val_accuracy: 0.8986\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3593 - accuracy: 0.9037 - val_loss: 0.3736 - val_accuracy: 0.8994\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3558 - accuracy: 0.9031 - val_loss: 0.3697 - val_accuracy: 0.9002\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3522 - accuracy: 0.9043 - val_loss: 0.3666 - val_accuracy: 0.9010\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3488 - accuracy: 0.9049 - val_loss: 0.3631 - val_accuracy: 0.9026\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3454 - accuracy: 0.9076 - val_loss: 0.3605 - val_accuracy: 0.9018\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3420 - accuracy: 0.9067 - val_loss: 0.3572 - val_accuracy: 0.9028\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3389 - accuracy: 0.9088 - val_loss: 0.3548 - val_accuracy: 0.9040\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3358 - accuracy: 0.9094 - val_loss: 0.3521 - val_accuracy: 0.9048\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3331 - accuracy: 0.9082 - val_loss: 0.3487 - val_accuracy: 0.9060\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3300 - accuracy: 0.9109 - val_loss: 0.3465 - val_accuracy: 0.9072\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3271 - accuracy: 0.9112 - val_loss: 0.3438 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3246 - accuracy: 0.9121 - val_loss: 0.3420 - val_accuracy: 0.9058\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3220 - accuracy: 0.9103 - val_loss: 0.3387 - val_accuracy: 0.9102\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3192 - accuracy: 0.9145 - val_loss: 0.3365 - val_accuracy: 0.9106\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3165 - accuracy: 0.9136 - val_loss: 0.3343 - val_accuracy: 0.9078\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3143 - accuracy: 0.9148 - val_loss: 0.3317 - val_accuracy: 0.9102\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3118 - accuracy: 0.9160 - val_loss: 0.3299 - val_accuracy: 0.9106\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.3094 - accuracy: 0.9175 - val_loss: 0.3279 - val_accuracy: 0.9118\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3072 - accuracy: 0.9160 - val_loss: 0.3254 - val_accuracy: 0.9116\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3051 - accuracy: 0.9175 - val_loss: 0.3233 - val_accuracy: 0.9118\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3027 - accuracy: 0.9169 - val_loss: 0.3218 - val_accuracy: 0.9124\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.3003 - accuracy: 0.9190 - val_loss: 0.3199 - val_accuracy: 0.9134\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2984 - accuracy: 0.9175 - val_loss: 0.3179 - val_accuracy: 0.9138\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2961 - accuracy: 0.9190 - val_loss: 0.3159 - val_accuracy: 0.9148\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2941 - accuracy: 0.9190 - val_loss: 0.3142 - val_accuracy: 0.9158\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2922 - accuracy: 0.9205 - val_loss: 0.3122 - val_accuracy: 0.9156\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2901 - accuracy: 0.9208 - val_loss: 0.3103 - val_accuracy: 0.9150\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2883 - accuracy: 0.9211 - val_loss: 0.3087 - val_accuracy: 0.9162\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2862 - accuracy: 0.9220 - val_loss: 0.3075 - val_accuracy: 0.9168\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2845 - accuracy: 0.9229 - val_loss: 0.3057 - val_accuracy: 0.9160\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2828 - accuracy: 0.9220 - val_loss: 0.3040 - val_accuracy: 0.9170\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2808 - accuracy: 0.9220 - val_loss: 0.3022 - val_accuracy: 0.9168\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2791 - accuracy: 0.9259 - val_loss: 0.3011 - val_accuracy: 0.9180\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2773 - accuracy: 0.9262 - val_loss: 0.3001 - val_accuracy: 0.9194\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2758 - accuracy: 0.9262 - val_loss: 0.2980 - val_accuracy: 0.9194\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2740 - accuracy: 0.9268 - val_loss: 0.2962 - val_accuracy: 0.9184\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2723 - accuracy: 0.9265 - val_loss: 0.2949 - val_accuracy: 0.9196\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2707 - accuracy: 0.9271 - val_loss: 0.2936 - val_accuracy: 0.9202\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2691 - accuracy: 0.9271 - val_loss: 0.2918 - val_accuracy: 0.9208\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2674 - accuracy: 0.9292 - val_loss: 0.2905 - val_accuracy: 0.9202\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2658 - accuracy: 0.9286 - val_loss: 0.2892 - val_accuracy: 0.9190\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.9016\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 5s 41ms/step - loss: 2.2990 - accuracy: 0.1185 - val_loss: 2.2990 - val_accuracy: 0.1184\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2970 - accuracy: 0.1212 - val_loss: 2.2970 - val_accuracy: 0.1200\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2949 - accuracy: 0.1236 - val_loss: 2.2949 - val_accuracy: 0.1246\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2929 - accuracy: 0.1302 - val_loss: 2.2929 - val_accuracy: 0.1310\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2908 - accuracy: 0.1365 - val_loss: 2.2908 - val_accuracy: 0.1356\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2886 - accuracy: 0.1419 - val_loss: 2.2886 - val_accuracy: 0.1424\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2864 - accuracy: 0.1467 - val_loss: 2.2864 - val_accuracy: 0.1460\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2840 - accuracy: 0.1554 - val_loss: 2.2840 - val_accuracy: 0.1534\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 2.2815 - accuracy: 0.1653 - val_loss: 2.2815 - val_accuracy: 0.1618\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.2789 - accuracy: 0.1719 - val_loss: 2.2789 - val_accuracy: 0.1696\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2761 - accuracy: 0.1803 - val_loss: 2.2760 - val_accuracy: 0.1778\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2731 - accuracy: 0.1902 - val_loss: 2.2729 - val_accuracy: 0.1864\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2698 - accuracy: 0.2004 - val_loss: 2.2696 - val_accuracy: 0.1990\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2663 - accuracy: 0.2118 - val_loss: 2.2660 - val_accuracy: 0.2136\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2625 - accuracy: 0.2256 - val_loss: 2.2621 - val_accuracy: 0.2258\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2584 - accuracy: 0.2394 - val_loss: 2.2580 - val_accuracy: 0.2422\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.2540 - accuracy: 0.2577 - val_loss: 2.2535 - val_accuracy: 0.2602\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2493 - accuracy: 0.2730 - val_loss: 2.2487 - val_accuracy: 0.2750\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.2441 - accuracy: 0.2901 - val_loss: 2.2434 - val_accuracy: 0.2908\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2385 - accuracy: 0.3051 - val_loss: 2.2376 - val_accuracy: 0.3020\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2323 - accuracy: 0.3159 - val_loss: 2.2313 - val_accuracy: 0.3134\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2255 - accuracy: 0.3234 - val_loss: 2.2244 - val_accuracy: 0.3242\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2182 - accuracy: 0.3342 - val_loss: 2.2170 - val_accuracy: 0.3320\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2102 - accuracy: 0.3438 - val_loss: 2.2089 - val_accuracy: 0.3426\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2015 - accuracy: 0.3525 - val_loss: 2.1999 - val_accuracy: 0.3494\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1919 - accuracy: 0.3570 - val_loss: 2.1902 - val_accuracy: 0.3546\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.1815 - accuracy: 0.3696 - val_loss: 2.1796 - val_accuracy: 0.3634\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1703 - accuracy: 0.3714 - val_loss: 2.1681 - val_accuracy: 0.3688\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1580 - accuracy: 0.3762 - val_loss: 2.1556 - val_accuracy: 0.3794\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1447 - accuracy: 0.3861 - val_loss: 2.1420 - val_accuracy: 0.3824\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1301 - accuracy: 0.3903 - val_loss: 2.1272 - val_accuracy: 0.3868\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1144 - accuracy: 0.3948 - val_loss: 2.1114 - val_accuracy: 0.3908\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0975 - accuracy: 0.4002 - val_loss: 2.0942 - val_accuracy: 0.4006\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 2.0793 - accuracy: 0.4110 - val_loss: 2.0758 - val_accuracy: 0.4068\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0598 - accuracy: 0.4161 - val_loss: 2.0563 - val_accuracy: 0.4150\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0390 - accuracy: 0.4239 - val_loss: 2.0354 - val_accuracy: 0.4208\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0169 - accuracy: 0.4329 - val_loss: 2.0132 - val_accuracy: 0.4270\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9933 - accuracy: 0.4374 - val_loss: 1.9894 - val_accuracy: 0.4330\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.9682 - accuracy: 0.4410 - val_loss: 1.9641 - val_accuracy: 0.4394\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.9414 - accuracy: 0.4491 - val_loss: 1.9371 - val_accuracy: 0.4456\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9126 - accuracy: 0.4554 - val_loss: 1.9081 - val_accuracy: 0.4568\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8819 - accuracy: 0.4674 - val_loss: 1.8772 - val_accuracy: 0.4676\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.8491 - accuracy: 0.4770 - val_loss: 1.8440 - val_accuracy: 0.4792\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.8137 - accuracy: 0.4899 - val_loss: 1.8085 - val_accuracy: 0.4896\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7760 - accuracy: 0.5011 - val_loss: 1.7704 - val_accuracy: 0.5036\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7357 - accuracy: 0.5179 - val_loss: 1.7314 - val_accuracy: 0.5174\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.6930 - accuracy: 0.5287 - val_loss: 1.6870 - val_accuracy: 0.5200\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.6474 - accuracy: 0.5341 - val_loss: 1.6415 - val_accuracy: 0.5342\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.5995 - accuracy: 0.5434 - val_loss: 1.5937 - val_accuracy: 0.5384\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5496 - accuracy: 0.5500 - val_loss: 1.5442 - val_accuracy: 0.5466\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.4981 - accuracy: 0.5593 - val_loss: 1.4936 - val_accuracy: 0.5596\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.4454 - accuracy: 0.5743 - val_loss: 1.4409 - val_accuracy: 0.5634\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3920 - accuracy: 0.5824 - val_loss: 1.3890 - val_accuracy: 0.5750\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3386 - accuracy: 0.5920 - val_loss: 1.3357 - val_accuracy: 0.5828\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.2851 - accuracy: 0.6028 - val_loss: 1.2840 - val_accuracy: 0.5890\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.2325 - accuracy: 0.6094 - val_loss: 1.2336 - val_accuracy: 0.6020\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.1823 - accuracy: 0.6214 - val_loss: 1.1862 - val_accuracy: 0.6064\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1345 - accuracy: 0.6325 - val_loss: 1.1409 - val_accuracy: 0.6344\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0902 - accuracy: 0.6637 - val_loss: 1.0982 - val_accuracy: 0.6690\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0494 - accuracy: 0.6976 - val_loss: 1.0608 - val_accuracy: 0.6840\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.0122 - accuracy: 0.7042 - val_loss: 1.0252 - val_accuracy: 0.6934\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.9776 - accuracy: 0.7111 - val_loss: 0.9948 - val_accuracy: 0.7016\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.9476 - accuracy: 0.7177 - val_loss: 0.9656 - val_accuracy: 0.7050\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9190 - accuracy: 0.7219 - val_loss: 0.9423 - val_accuracy: 0.7086\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8935 - accuracy: 0.7270 - val_loss: 0.9162 - val_accuracy: 0.7192\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8697 - accuracy: 0.7363 - val_loss: 0.8953 - val_accuracy: 0.7198\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8469 - accuracy: 0.7411 - val_loss: 0.8736 - val_accuracy: 0.7308\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8268 - accuracy: 0.7405 - val_loss: 0.8553 - val_accuracy: 0.7368\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8079 - accuracy: 0.7513 - val_loss: 0.8389 - val_accuracy: 0.7388\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7899 - accuracy: 0.7579 - val_loss: 0.8263 - val_accuracy: 0.7366\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7733 - accuracy: 0.7633 - val_loss: 0.8064 - val_accuracy: 0.7454\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.7571 - accuracy: 0.7687 - val_loss: 0.7929 - val_accuracy: 0.7558\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.7422 - accuracy: 0.7732 - val_loss: 0.7773 - val_accuracy: 0.7586\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7280 - accuracy: 0.7747 - val_loss: 0.7695 - val_accuracy: 0.7600\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.7144 - accuracy: 0.7825 - val_loss: 0.7575 - val_accuracy: 0.7638\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7034 - accuracy: 0.7867 - val_loss: 0.7448 - val_accuracy: 0.7730\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6915 - accuracy: 0.7915 - val_loss: 0.7334 - val_accuracy: 0.7744\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6782 - accuracy: 0.7936 - val_loss: 0.7209 - val_accuracy: 0.7832\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6688 - accuracy: 0.8038 - val_loss: 0.7107 - val_accuracy: 0.7872\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6589 - accuracy: 0.8044 - val_loss: 0.7037 - val_accuracy: 0.7904\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6491 - accuracy: 0.8077 - val_loss: 0.6939 - val_accuracy: 0.7930\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6390 - accuracy: 0.8131 - val_loss: 0.6882 - val_accuracy: 0.7946\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6297 - accuracy: 0.8134 - val_loss: 0.6770 - val_accuracy: 0.7972\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6216 - accuracy: 0.8170 - val_loss: 0.6700 - val_accuracy: 0.8008\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6130 - accuracy: 0.8230 - val_loss: 0.6650 - val_accuracy: 0.7982\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6059 - accuracy: 0.8212 - val_loss: 0.6710 - val_accuracy: 0.7964\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5979 - accuracy: 0.8221 - val_loss: 0.6489 - val_accuracy: 0.8060\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5902 - accuracy: 0.8296 - val_loss: 0.6399 - val_accuracy: 0.8100\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5831 - accuracy: 0.8305 - val_loss: 0.6362 - val_accuracy: 0.8094\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5761 - accuracy: 0.8332 - val_loss: 0.6277 - val_accuracy: 0.8116\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5696 - accuracy: 0.8320 - val_loss: 0.6216 - val_accuracy: 0.8158\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5626 - accuracy: 0.8356 - val_loss: 0.6199 - val_accuracy: 0.8186\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5570 - accuracy: 0.8389 - val_loss: 0.6192 - val_accuracy: 0.8166\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5511 - accuracy: 0.8389 - val_loss: 0.6093 - val_accuracy: 0.8200\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5444 - accuracy: 0.8383 - val_loss: 0.5998 - val_accuracy: 0.8230\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5383 - accuracy: 0.8452 - val_loss: 0.5978 - val_accuracy: 0.8254\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5332 - accuracy: 0.8497 - val_loss: 0.5897 - val_accuracy: 0.8272\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5268 - accuracy: 0.8470 - val_loss: 0.5906 - val_accuracy: 0.8218\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5213 - accuracy: 0.8506 - val_loss: 0.5827 - val_accuracy: 0.8280\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5162 - accuracy: 0.8512 - val_loss: 0.5746 - val_accuracy: 0.8308\n",
      "53/53 [==============================] - 1s 3ms/step - loss: 0.7030 - accuracy: 0.7888\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 2.3101 - accuracy: 0.0867 - val_loss: 2.3088 - val_accuracy: 0.0928\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.3069 - accuracy: 0.0942 - val_loss: 2.3059 - val_accuracy: 0.1006\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.3042 - accuracy: 0.1044 - val_loss: 2.3033 - val_accuracy: 0.1100\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3017 - accuracy: 0.1146 - val_loss: 2.3010 - val_accuracy: 0.1224\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2995 - accuracy: 0.1266 - val_loss: 2.2988 - val_accuracy: 0.1334\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2973 - accuracy: 0.1365 - val_loss: 2.2968 - val_accuracy: 0.1440\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2953 - accuracy: 0.1482 - val_loss: 2.2949 - val_accuracy: 0.1570\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2934 - accuracy: 0.1620 - val_loss: 2.2930 - val_accuracy: 0.1672\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2915 - accuracy: 0.1734 - val_loss: 2.2911 - val_accuracy: 0.1774\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2897 - accuracy: 0.1836 - val_loss: 2.2893 - val_accuracy: 0.1876\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2879 - accuracy: 0.1935 - val_loss: 2.2876 - val_accuracy: 0.1958\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2861 - accuracy: 0.1962 - val_loss: 2.2858 - val_accuracy: 0.2034\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2843 - accuracy: 0.2064 - val_loss: 2.2840 - val_accuracy: 0.2120\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2824 - accuracy: 0.2121 - val_loss: 2.2822 - val_accuracy: 0.2178\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2806 - accuracy: 0.2193 - val_loss: 2.2804 - val_accuracy: 0.2230\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2787 - accuracy: 0.2256 - val_loss: 2.2785 - val_accuracy: 0.2294\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2768 - accuracy: 0.2310 - val_loss: 2.2766 - val_accuracy: 0.2362\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.2748 - accuracy: 0.2352 - val_loss: 2.2745 - val_accuracy: 0.2414\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2727 - accuracy: 0.2427 - val_loss: 2.2724 - val_accuracy: 0.2470\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2705 - accuracy: 0.2460 - val_loss: 2.2702 - val_accuracy: 0.2512\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2682 - accuracy: 0.2532 - val_loss: 2.2679 - val_accuracy: 0.2552\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2658 - accuracy: 0.2556 - val_loss: 2.2655 - val_accuracy: 0.2604\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2633 - accuracy: 0.2637 - val_loss: 2.2629 - val_accuracy: 0.2678\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2606 - accuracy: 0.2724 - val_loss: 2.2601 - val_accuracy: 0.2716\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2578 - accuracy: 0.2787 - val_loss: 2.2572 - val_accuracy: 0.2758\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2547 - accuracy: 0.2775 - val_loss: 2.2541 - val_accuracy: 0.2810\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2515 - accuracy: 0.2847 - val_loss: 2.2508 - val_accuracy: 0.2862\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2481 - accuracy: 0.2961 - val_loss: 2.2473 - val_accuracy: 0.2942\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2444 - accuracy: 0.2955 - val_loss: 2.2435 - val_accuracy: 0.2986\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2405 - accuracy: 0.3000 - val_loss: 2.2394 - val_accuracy: 0.3024\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2362 - accuracy: 0.3042 - val_loss: 2.2350 - val_accuracy: 0.3080\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2316 - accuracy: 0.3096 - val_loss: 2.2302 - val_accuracy: 0.3128\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2267 - accuracy: 0.3177 - val_loss: 2.2251 - val_accuracy: 0.3188\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2214 - accuracy: 0.3234 - val_loss: 2.2195 - val_accuracy: 0.3224\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2155 - accuracy: 0.3255 - val_loss: 2.2134 - val_accuracy: 0.3308\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2092 - accuracy: 0.3342 - val_loss: 2.2067 - val_accuracy: 0.3334\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2022 - accuracy: 0.3387 - val_loss: 2.1994 - val_accuracy: 0.3376\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1946 - accuracy: 0.3453 - val_loss: 2.1914 - val_accuracy: 0.3400\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1862 - accuracy: 0.3450 - val_loss: 2.1826 - val_accuracy: 0.3446\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1771 - accuracy: 0.3507 - val_loss: 2.1731 - val_accuracy: 0.3502\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1671 - accuracy: 0.3588 - val_loss: 2.1626 - val_accuracy: 0.3588\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1561 - accuracy: 0.3645 - val_loss: 2.1511 - val_accuracy: 0.3644\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.1442 - accuracy: 0.3723 - val_loss: 2.1386 - val_accuracy: 0.3682\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1311 - accuracy: 0.3738 - val_loss: 2.1249 - val_accuracy: 0.3732\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1169 - accuracy: 0.3828 - val_loss: 2.1101 - val_accuracy: 0.3796\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1014 - accuracy: 0.3876 - val_loss: 2.0939 - val_accuracy: 0.3860\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0845 - accuracy: 0.3909 - val_loss: 2.0762 - val_accuracy: 0.3976\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0660 - accuracy: 0.4053 - val_loss: 2.0566 - val_accuracy: 0.4016\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0456 - accuracy: 0.4089 - val_loss: 2.0352 - val_accuracy: 0.4072\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.0233 - accuracy: 0.4164 - val_loss: 2.0118 - val_accuracy: 0.4208\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.9990 - accuracy: 0.4320 - val_loss: 1.9864 - val_accuracy: 0.4318\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9726 - accuracy: 0.4413 - val_loss: 1.9588 - val_accuracy: 0.4498\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.9440 - accuracy: 0.4590 - val_loss: 1.9286 - val_accuracy: 0.4604\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9127 - accuracy: 0.4752 - val_loss: 1.8954 - val_accuracy: 0.4778\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.8782 - accuracy: 0.4947 - val_loss: 1.8588 - val_accuracy: 0.4982\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 1.8403 - accuracy: 0.5155 - val_loss: 1.8193 - val_accuracy: 0.5152\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7990 - accuracy: 0.5287 - val_loss: 1.7758 - val_accuracy: 0.5326\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.7551 - accuracy: 0.5431 - val_loss: 1.7304 - val_accuracy: 0.5462\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.7088 - accuracy: 0.5584 - val_loss: 1.6825 - val_accuracy: 0.5618\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.6606 - accuracy: 0.5704 - val_loss: 1.6333 - val_accuracy: 0.5738\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6112 - accuracy: 0.5803 - val_loss: 1.5838 - val_accuracy: 0.5852\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.5618 - accuracy: 0.5956 - val_loss: 1.5337 - val_accuracy: 0.5972\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.5125 - accuracy: 0.6061 - val_loss: 1.4845 - val_accuracy: 0.6122\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.4643 - accuracy: 0.6220 - val_loss: 1.4368 - val_accuracy: 0.6142\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.4170 - accuracy: 0.6280 - val_loss: 1.3898 - val_accuracy: 0.6276\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.3708 - accuracy: 0.6412 - val_loss: 1.3447 - val_accuracy: 0.6326\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.3267 - accuracy: 0.6433 - val_loss: 1.3010 - val_accuracy: 0.6530\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.2841 - accuracy: 0.6589 - val_loss: 1.2593 - val_accuracy: 0.6566\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.2442 - accuracy: 0.6628 - val_loss: 1.2202 - val_accuracy: 0.6642\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.2064 - accuracy: 0.6691 - val_loss: 1.1839 - val_accuracy: 0.6744\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1702 - accuracy: 0.6802 - val_loss: 1.1494 - val_accuracy: 0.6772\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.1367 - accuracy: 0.6844 - val_loss: 1.1155 - val_accuracy: 0.6854\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.1046 - accuracy: 0.6922 - val_loss: 1.0875 - val_accuracy: 0.6902\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.0746 - accuracy: 0.6985 - val_loss: 1.0575 - val_accuracy: 0.6988\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0468 - accuracy: 0.7027 - val_loss: 1.0306 - val_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.0198 - accuracy: 0.7069 - val_loss: 1.0032 - val_accuracy: 0.7068\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.9939 - accuracy: 0.7156 - val_loss: 0.9800 - val_accuracy: 0.7080\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.9698 - accuracy: 0.7231 - val_loss: 0.9564 - val_accuracy: 0.7110\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.9476 - accuracy: 0.7216 - val_loss: 0.9372 - val_accuracy: 0.7270\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.9252 - accuracy: 0.7336 - val_loss: 0.9107 - val_accuracy: 0.7304\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.9047 - accuracy: 0.7393 - val_loss: 0.8901 - val_accuracy: 0.7374\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.8846 - accuracy: 0.7441 - val_loss: 0.8721 - val_accuracy: 0.7436\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8659 - accuracy: 0.7510 - val_loss: 0.8542 - val_accuracy: 0.7486\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.8477 - accuracy: 0.7543 - val_loss: 0.8420 - val_accuracy: 0.7432\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8305 - accuracy: 0.7609 - val_loss: 0.8187 - val_accuracy: 0.7580\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.8129 - accuracy: 0.7657 - val_loss: 0.8010 - val_accuracy: 0.7658\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.7975 - accuracy: 0.7711 - val_loss: 0.7860 - val_accuracy: 0.7716\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.7819 - accuracy: 0.7771 - val_loss: 0.7710 - val_accuracy: 0.7714\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.7680 - accuracy: 0.7771 - val_loss: 0.7588 - val_accuracy: 0.7762\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.7528 - accuracy: 0.7813 - val_loss: 0.7475 - val_accuracy: 0.7832\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.7381 - accuracy: 0.7915 - val_loss: 0.7280 - val_accuracy: 0.7862\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7247 - accuracy: 0.7900 - val_loss: 0.7142 - val_accuracy: 0.7924\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.7126 - accuracy: 0.7957 - val_loss: 0.7024 - val_accuracy: 0.7926\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6984 - accuracy: 0.7942 - val_loss: 0.6929 - val_accuracy: 0.7892\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6864 - accuracy: 0.8017 - val_loss: 0.6776 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6749 - accuracy: 0.8029 - val_loss: 0.6670 - val_accuracy: 0.7972\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.6634 - accuracy: 0.8074 - val_loss: 0.6545 - val_accuracy: 0.8062\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6512 - accuracy: 0.8128 - val_loss: 0.6465 - val_accuracy: 0.8078\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6408 - accuracy: 0.8161 - val_loss: 0.6326 - val_accuracy: 0.8132\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6303 - accuracy: 0.8182 - val_loss: 0.6230 - val_accuracy: 0.8174\n",
      "53/53 [==============================] - 1s 7ms/step - loss: 0.6238 - accuracy: 0.8062\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.3051 - accuracy: 0.0861 - val_loss: 2.3046 - val_accuracy: 0.0898\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.3034 - accuracy: 0.0930 - val_loss: 2.3029 - val_accuracy: 0.0982\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.3017 - accuracy: 0.1011 - val_loss: 2.3013 - val_accuracy: 0.1090\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.3001 - accuracy: 0.1095 - val_loss: 2.2997 - val_accuracy: 0.1190\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2985 - accuracy: 0.1194 - val_loss: 2.2982 - val_accuracy: 0.1294\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2970 - accuracy: 0.1299 - val_loss: 2.2967 - val_accuracy: 0.1428\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2955 - accuracy: 0.1413 - val_loss: 2.2952 - val_accuracy: 0.1552\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2940 - accuracy: 0.1557 - val_loss: 2.2938 - val_accuracy: 0.1676\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2925 - accuracy: 0.1677 - val_loss: 2.2923 - val_accuracy: 0.1774\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2910 - accuracy: 0.1752 - val_loss: 2.2908 - val_accuracy: 0.1882\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2895 - accuracy: 0.1872 - val_loss: 2.2893 - val_accuracy: 0.1978\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2879 - accuracy: 0.1980 - val_loss: 2.2877 - val_accuracy: 0.2060\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2863 - accuracy: 0.2064 - val_loss: 2.2861 - val_accuracy: 0.2140\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.2846 - accuracy: 0.2091 - val_loss: 2.2844 - val_accuracy: 0.2168\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2829 - accuracy: 0.2145 - val_loss: 2.2827 - val_accuracy: 0.2214\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.2811 - accuracy: 0.2178 - val_loss: 2.2809 - val_accuracy: 0.2262\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2793 - accuracy: 0.2238 - val_loss: 2.2789 - val_accuracy: 0.2278\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2772 - accuracy: 0.2253 - val_loss: 2.2769 - val_accuracy: 0.2318\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2751 - accuracy: 0.2286 - val_loss: 2.2747 - val_accuracy: 0.2330\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2728 - accuracy: 0.2331 - val_loss: 2.2723 - val_accuracy: 0.2376\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2704 - accuracy: 0.2358 - val_loss: 2.2698 - val_accuracy: 0.2426\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2677 - accuracy: 0.2415 - val_loss: 2.2670 - val_accuracy: 0.2476\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2648 - accuracy: 0.2436 - val_loss: 2.2640 - val_accuracy: 0.2500\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.2617 - accuracy: 0.2475 - val_loss: 2.2608 - val_accuracy: 0.2560\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2584 - accuracy: 0.2513 - val_loss: 2.2573 - val_accuracy: 0.2642\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2546 - accuracy: 0.2582 - val_loss: 2.2533 - val_accuracy: 0.2692\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2505 - accuracy: 0.2603 - val_loss: 2.2490 - val_accuracy: 0.2704\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2459 - accuracy: 0.2669 - val_loss: 2.2443 - val_accuracy: 0.2752\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2409 - accuracy: 0.2708 - val_loss: 2.2390 - val_accuracy: 0.2794\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2354 - accuracy: 0.2744 - val_loss: 2.2333 - val_accuracy: 0.2842\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2293 - accuracy: 0.2789 - val_loss: 2.2270 - val_accuracy: 0.2866\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 2.2227 - accuracy: 0.2822 - val_loss: 2.2200 - val_accuracy: 0.2896\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2155 - accuracy: 0.2855 - val_loss: 2.2124 - val_accuracy: 0.2900\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.2075 - accuracy: 0.2819 - val_loss: 2.2041 - val_accuracy: 0.2910\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1988 - accuracy: 0.2867 - val_loss: 2.1950 - val_accuracy: 0.2938\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1894 - accuracy: 0.2903 - val_loss: 2.1850 - val_accuracy: 0.2950\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1790 - accuracy: 0.2927 - val_loss: 2.1742 - val_accuracy: 0.2952\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 2.1676 - accuracy: 0.2942 - val_loss: 2.1624 - val_accuracy: 0.2982\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1553 - accuracy: 0.2975 - val_loss: 2.1494 - val_accuracy: 0.2992\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1419 - accuracy: 0.2984 - val_loss: 2.1356 - val_accuracy: 0.3042\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.1275 - accuracy: 0.3032 - val_loss: 2.1207 - val_accuracy: 0.3072\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.1121 - accuracy: 0.3071 - val_loss: 2.1045 - val_accuracy: 0.3092\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 2.0955 - accuracy: 0.3101 - val_loss: 2.0874 - val_accuracy: 0.3130\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0778 - accuracy: 0.3146 - val_loss: 2.0691 - val_accuracy: 0.3170\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0589 - accuracy: 0.3185 - val_loss: 2.0496 - val_accuracy: 0.3210\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 2.0389 - accuracy: 0.3248 - val_loss: 2.0289 - val_accuracy: 0.3264\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 2.0178 - accuracy: 0.3296 - val_loss: 2.0069 - val_accuracy: 0.3304\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.9952 - accuracy: 0.3359 - val_loss: 1.9837 - val_accuracy: 0.3344\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9714 - accuracy: 0.3383 - val_loss: 1.9590 - val_accuracy: 0.3402\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9462 - accuracy: 0.3476 - val_loss: 1.9332 - val_accuracy: 0.3464\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.9197 - accuracy: 0.3527 - val_loss: 1.9060 - val_accuracy: 0.3548\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8918 - accuracy: 0.3611 - val_loss: 1.8771 - val_accuracy: 0.3650\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8621 - accuracy: 0.3755 - val_loss: 1.8467 - val_accuracy: 0.3756\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8309 - accuracy: 0.3857 - val_loss: 1.8146 - val_accuracy: 0.3896\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7978 - accuracy: 0.4040 - val_loss: 1.7811 - val_accuracy: 0.4060\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7633 - accuracy: 0.4256 - val_loss: 1.7453 - val_accuracy: 0.4322\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.7267 - accuracy: 0.4517 - val_loss: 1.7081 - val_accuracy: 0.4588\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.6887 - accuracy: 0.4802 - val_loss: 1.6691 - val_accuracy: 0.4830\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.6490 - accuracy: 0.5057 - val_loss: 1.6300 - val_accuracy: 0.5270\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.6084 - accuracy: 0.5396 - val_loss: 1.5874 - val_accuracy: 0.5556\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5662 - accuracy: 0.5723 - val_loss: 1.5443 - val_accuracy: 0.5818\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.5228 - accuracy: 0.5951 - val_loss: 1.5009 - val_accuracy: 0.6058\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.4792 - accuracy: 0.6167 - val_loss: 1.4568 - val_accuracy: 0.6182\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.4354 - accuracy: 0.6347 - val_loss: 1.4133 - val_accuracy: 0.6280\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3917 - accuracy: 0.6425 - val_loss: 1.3697 - val_accuracy: 0.6600\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3482 - accuracy: 0.6698 - val_loss: 1.3273 - val_accuracy: 0.6652\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.3060 - accuracy: 0.6740 - val_loss: 1.2856 - val_accuracy: 0.6788\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.2647 - accuracy: 0.6908 - val_loss: 1.2448 - val_accuracy: 0.6862\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.2246 - accuracy: 0.6983 - val_loss: 1.2053 - val_accuracy: 0.6926\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.1859 - accuracy: 0.7040 - val_loss: 1.1666 - val_accuracy: 0.7066\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1479 - accuracy: 0.7127 - val_loss: 1.1305 - val_accuracy: 0.7116\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.1115 - accuracy: 0.7175 - val_loss: 1.0960 - val_accuracy: 0.7190\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0764 - accuracy: 0.7268 - val_loss: 1.0634 - val_accuracy: 0.7210\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0429 - accuracy: 0.7307 - val_loss: 1.0287 - val_accuracy: 0.7284\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0106 - accuracy: 0.7325 - val_loss: 0.9976 - val_accuracy: 0.7350\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.9794 - accuracy: 0.7418 - val_loss: 0.9679 - val_accuracy: 0.7424\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.9499 - accuracy: 0.7439 - val_loss: 0.9379 - val_accuracy: 0.7460\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.9220 - accuracy: 0.7481 - val_loss: 0.9130 - val_accuracy: 0.7482\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8956 - accuracy: 0.7579 - val_loss: 0.8868 - val_accuracy: 0.7514\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8709 - accuracy: 0.7603 - val_loss: 0.8615 - val_accuracy: 0.7586\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8467 - accuracy: 0.7627 - val_loss: 0.8399 - val_accuracy: 0.7590\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8248 - accuracy: 0.7699 - val_loss: 0.8190 - val_accuracy: 0.7638\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8033 - accuracy: 0.7735 - val_loss: 0.7989 - val_accuracy: 0.7740\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7831 - accuracy: 0.7780 - val_loss: 0.7829 - val_accuracy: 0.7754\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7644 - accuracy: 0.7795 - val_loss: 0.7602 - val_accuracy: 0.7810\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7458 - accuracy: 0.7828 - val_loss: 0.7448 - val_accuracy: 0.7826\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.7295 - accuracy: 0.7852 - val_loss: 0.7275 - val_accuracy: 0.7872\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.7135 - accuracy: 0.7906 - val_loss: 0.7156 - val_accuracy: 0.7872\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.6987 - accuracy: 0.7897 - val_loss: 0.7011 - val_accuracy: 0.7922\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.6851 - accuracy: 0.7924 - val_loss: 0.6874 - val_accuracy: 0.7942\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6730 - accuracy: 0.7972 - val_loss: 0.6776 - val_accuracy: 0.7966\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6602 - accuracy: 0.8014 - val_loss: 0.6671 - val_accuracy: 0.7970\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6492 - accuracy: 0.8032 - val_loss: 0.6528 - val_accuracy: 0.8014\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6371 - accuracy: 0.8074 - val_loss: 0.6444 - val_accuracy: 0.8042\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6283 - accuracy: 0.8077 - val_loss: 0.6325 - val_accuracy: 0.8090\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6177 - accuracy: 0.8119 - val_loss: 0.6244 - val_accuracy: 0.8088\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6074 - accuracy: 0.8152 - val_loss: 0.6156 - val_accuracy: 0.8126\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5993 - accuracy: 0.8182 - val_loss: 0.6081 - val_accuracy: 0.8150\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5917 - accuracy: 0.8227 - val_loss: 0.6023 - val_accuracy: 0.8152\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5818 - accuracy: 0.8233 - val_loss: 0.5929 - val_accuracy: 0.8172\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.8067\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 2.1283 - accuracy: 0.3252 - val_loss: 1.9260 - val_accuracy: 0.5014\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.7535 - accuracy: 0.5920 - val_loss: 1.5828 - val_accuracy: 0.6624\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.4316 - accuracy: 0.6997 - val_loss: 1.3030 - val_accuracy: 0.7414\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.1782 - accuracy: 0.7696 - val_loss: 1.0899 - val_accuracy: 0.7756\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.9913 - accuracy: 0.8014 - val_loss: 0.9380 - val_accuracy: 0.8060\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.8577 - accuracy: 0.8260 - val_loss: 0.8288 - val_accuracy: 0.8194\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.7615 - accuracy: 0.8362 - val_loss: 0.7482 - val_accuracy: 0.8326\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6884 - accuracy: 0.8515 - val_loss: 0.6890 - val_accuracy: 0.8430\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6320 - accuracy: 0.8647 - val_loss: 0.6418 - val_accuracy: 0.8514\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5876 - accuracy: 0.8716 - val_loss: 0.6015 - val_accuracy: 0.8574\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5507 - accuracy: 0.8776 - val_loss: 0.5704 - val_accuracy: 0.8652\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.5201 - accuracy: 0.8839 - val_loss: 0.5425 - val_accuracy: 0.8666\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4945 - accuracy: 0.8875 - val_loss: 0.5207 - val_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4719 - accuracy: 0.8929 - val_loss: 0.5011 - val_accuracy: 0.8796\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4525 - accuracy: 0.8986 - val_loss: 0.4841 - val_accuracy: 0.8804\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4355 - accuracy: 0.9001 - val_loss: 0.4675 - val_accuracy: 0.8854\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4206 - accuracy: 0.9022 - val_loss: 0.4542 - val_accuracy: 0.8868\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4068 - accuracy: 0.9043 - val_loss: 0.4422 - val_accuracy: 0.8878\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3945 - accuracy: 0.9070 - val_loss: 0.4316 - val_accuracy: 0.8924\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3833 - accuracy: 0.9091 - val_loss: 0.4217 - val_accuracy: 0.8950\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3730 - accuracy: 0.9115 - val_loss: 0.4135 - val_accuracy: 0.8968\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3638 - accuracy: 0.9109 - val_loss: 0.4045 - val_accuracy: 0.8962\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3553 - accuracy: 0.9133 - val_loss: 0.3969 - val_accuracy: 0.8990\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3470 - accuracy: 0.9154 - val_loss: 0.3914 - val_accuracy: 0.8998\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.3398 - accuracy: 0.9163 - val_loss: 0.3830 - val_accuracy: 0.9026\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.3328 - accuracy: 0.9199 - val_loss: 0.3764 - val_accuracy: 0.9040\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3261 - accuracy: 0.9205 - val_loss: 0.3722 - val_accuracy: 0.9038\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3202 - accuracy: 0.9199 - val_loss: 0.3662 - val_accuracy: 0.9060\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3144 - accuracy: 0.9229 - val_loss: 0.3628 - val_accuracy: 0.9054\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3092 - accuracy: 0.9205 - val_loss: 0.3563 - val_accuracy: 0.9090\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3037 - accuracy: 0.9247 - val_loss: 0.3513 - val_accuracy: 0.9090\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2989 - accuracy: 0.9253 - val_loss: 0.3470 - val_accuracy: 0.9102\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2939 - accuracy: 0.9262 - val_loss: 0.3424 - val_accuracy: 0.9120\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2894 - accuracy: 0.9292 - val_loss: 0.3390 - val_accuracy: 0.9138\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2854 - accuracy: 0.9274 - val_loss: 0.3353 - val_accuracy: 0.9134\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2814 - accuracy: 0.9310 - val_loss: 0.3331 - val_accuracy: 0.9122\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2772 - accuracy: 0.9310 - val_loss: 0.3288 - val_accuracy: 0.9142\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2736 - accuracy: 0.9310 - val_loss: 0.3249 - val_accuracy: 0.9150\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2696 - accuracy: 0.9307 - val_loss: 0.3219 - val_accuracy: 0.9174\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2663 - accuracy: 0.9322 - val_loss: 0.3193 - val_accuracy: 0.9176\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2631 - accuracy: 0.9343 - val_loss: 0.3165 - val_accuracy: 0.9176\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2595 - accuracy: 0.9346 - val_loss: 0.3131 - val_accuracy: 0.9180\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2565 - accuracy: 0.9343 - val_loss: 0.3110 - val_accuracy: 0.9180\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2534 - accuracy: 0.9352 - val_loss: 0.3087 - val_accuracy: 0.9190\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2505 - accuracy: 0.9361 - val_loss: 0.3057 - val_accuracy: 0.9192\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2475 - accuracy: 0.9373 - val_loss: 0.3037 - val_accuracy: 0.9194\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2446 - accuracy: 0.9382 - val_loss: 0.3004 - val_accuracy: 0.9216\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2421 - accuracy: 0.9385 - val_loss: 0.2985 - val_accuracy: 0.9216\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2394 - accuracy: 0.9385 - val_loss: 0.2968 - val_accuracy: 0.9202\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2371 - accuracy: 0.9385 - val_loss: 0.2941 - val_accuracy: 0.9226\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2348 - accuracy: 0.9415 - val_loss: 0.2924 - val_accuracy: 0.9216\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2319 - accuracy: 0.9388 - val_loss: 0.2900 - val_accuracy: 0.9240\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2298 - accuracy: 0.9421 - val_loss: 0.2890 - val_accuracy: 0.9232\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2278 - accuracy: 0.9409 - val_loss: 0.2866 - val_accuracy: 0.9232\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2254 - accuracy: 0.9421 - val_loss: 0.2844 - val_accuracy: 0.9254\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2229 - accuracy: 0.9439 - val_loss: 0.2833 - val_accuracy: 0.9244\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2211 - accuracy: 0.9442 - val_loss: 0.2811 - val_accuracy: 0.9256\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2189 - accuracy: 0.9421 - val_loss: 0.2802 - val_accuracy: 0.9240\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2168 - accuracy: 0.9439 - val_loss: 0.2785 - val_accuracy: 0.9250\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2149 - accuracy: 0.9451 - val_loss: 0.2764 - val_accuracy: 0.9266\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2129 - accuracy: 0.9451 - val_loss: 0.2747 - val_accuracy: 0.9264\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.2111 - accuracy: 0.9463 - val_loss: 0.2732 - val_accuracy: 0.9260\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2092 - accuracy: 0.9472 - val_loss: 0.2720 - val_accuracy: 0.9268\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2071 - accuracy: 0.9466 - val_loss: 0.2696 - val_accuracy: 0.9280\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2056 - accuracy: 0.9472 - val_loss: 0.2689 - val_accuracy: 0.9286\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2039 - accuracy: 0.9478 - val_loss: 0.2671 - val_accuracy: 0.9284\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2022 - accuracy: 0.9478 - val_loss: 0.2647 - val_accuracy: 0.9290\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.2005 - accuracy: 0.9493 - val_loss: 0.2641 - val_accuracy: 0.9296\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1986 - accuracy: 0.9490 - val_loss: 0.2627 - val_accuracy: 0.9292\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.1973 - accuracy: 0.9508 - val_loss: 0.2611 - val_accuracy: 0.9304\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1953 - accuracy: 0.9499 - val_loss: 0.2608 - val_accuracy: 0.9300\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1939 - accuracy: 0.9508 - val_loss: 0.2583 - val_accuracy: 0.9312\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1923 - accuracy: 0.9520 - val_loss: 0.2570 - val_accuracy: 0.9312\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1908 - accuracy: 0.9508 - val_loss: 0.2561 - val_accuracy: 0.9314\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1892 - accuracy: 0.9508 - val_loss: 0.2557 - val_accuracy: 0.9314\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1880 - accuracy: 0.9520 - val_loss: 0.2542 - val_accuracy: 0.9316\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1864 - accuracy: 0.9514 - val_loss: 0.2530 - val_accuracy: 0.9316\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1848 - accuracy: 0.9529 - val_loss: 0.2527 - val_accuracy: 0.9324\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1836 - accuracy: 0.9535 - val_loss: 0.2507 - val_accuracy: 0.9328\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1823 - accuracy: 0.9535 - val_loss: 0.2492 - val_accuracy: 0.9344\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.1807 - accuracy: 0.9541 - val_loss: 0.2479 - val_accuracy: 0.9344\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1795 - accuracy: 0.9535 - val_loss: 0.2469 - val_accuracy: 0.9342\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1780 - accuracy: 0.9541 - val_loss: 0.2462 - val_accuracy: 0.9344\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.1768 - accuracy: 0.9553 - val_loss: 0.2453 - val_accuracy: 0.9346\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1754 - accuracy: 0.9553 - val_loss: 0.2446 - val_accuracy: 0.9364\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1742 - accuracy: 0.9553 - val_loss: 0.2434 - val_accuracy: 0.9366\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1729 - accuracy: 0.9571 - val_loss: 0.2425 - val_accuracy: 0.9358\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1717 - accuracy: 0.9568 - val_loss: 0.2414 - val_accuracy: 0.9368\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1704 - accuracy: 0.9577 - val_loss: 0.2401 - val_accuracy: 0.9362\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1692 - accuracy: 0.9595 - val_loss: 0.2404 - val_accuracy: 0.9352\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.1679 - accuracy: 0.9583 - val_loss: 0.2382 - val_accuracy: 0.9386\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1670 - accuracy: 0.9586 - val_loss: 0.2375 - val_accuracy: 0.9382\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1659 - accuracy: 0.9613 - val_loss: 0.2363 - val_accuracy: 0.9394\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1645 - accuracy: 0.9598 - val_loss: 0.2357 - val_accuracy: 0.9396\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1634 - accuracy: 0.9601 - val_loss: 0.2348 - val_accuracy: 0.9390\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1619 - accuracy: 0.9616 - val_loss: 0.2346 - val_accuracy: 0.9386\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1610 - accuracy: 0.9613 - val_loss: 0.2330 - val_accuracy: 0.9396\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1600 - accuracy: 0.9619 - val_loss: 0.2327 - val_accuracy: 0.9392\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1589 - accuracy: 0.9619 - val_loss: 0.2313 - val_accuracy: 0.9402\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1577 - accuracy: 0.9619 - val_loss: 0.2312 - val_accuracy: 0.9408\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8950\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 2.0498 - accuracy: 0.3408 - val_loss: 1.8325 - val_accuracy: 0.5292\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.6561 - accuracy: 0.6031 - val_loss: 1.4718 - val_accuracy: 0.6788\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.3365 - accuracy: 0.7129 - val_loss: 1.1961 - val_accuracy: 0.7526\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.1058 - accuracy: 0.7675 - val_loss: 1.0064 - val_accuracy: 0.7860\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.9470 - accuracy: 0.7960 - val_loss: 0.8733 - val_accuracy: 0.8092\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.8343 - accuracy: 0.8137 - val_loss: 0.7789 - val_accuracy: 0.8242\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.7514 - accuracy: 0.8287 - val_loss: 0.7079 - val_accuracy: 0.8370\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.6881 - accuracy: 0.8437 - val_loss: 0.6543 - val_accuracy: 0.8454\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.6393 - accuracy: 0.8494 - val_loss: 0.6088 - val_accuracy: 0.8580\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5992 - accuracy: 0.8626 - val_loss: 0.5738 - val_accuracy: 0.8606\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.5667 - accuracy: 0.8662 - val_loss: 0.5449 - val_accuracy: 0.8652\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5395 - accuracy: 0.8716 - val_loss: 0.5211 - val_accuracy: 0.8712\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5160 - accuracy: 0.8788 - val_loss: 0.4986 - val_accuracy: 0.8768\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4959 - accuracy: 0.8800 - val_loss: 0.4808 - val_accuracy: 0.8838\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4783 - accuracy: 0.8851 - val_loss: 0.4644 - val_accuracy: 0.8854\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4627 - accuracy: 0.8875 - val_loss: 0.4507 - val_accuracy: 0.8890\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4488 - accuracy: 0.8890 - val_loss: 0.4388 - val_accuracy: 0.8898\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4366 - accuracy: 0.8911 - val_loss: 0.4270 - val_accuracy: 0.8940\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4252 - accuracy: 0.8941 - val_loss: 0.4172 - val_accuracy: 0.8948\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.8974 - val_loss: 0.4076 - val_accuracy: 0.8988\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4055 - accuracy: 0.8986 - val_loss: 0.3984 - val_accuracy: 0.8992\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3969 - accuracy: 0.9013 - val_loss: 0.3916 - val_accuracy: 0.9004\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3885 - accuracy: 0.9046 - val_loss: 0.3842 - val_accuracy: 0.9046\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3815 - accuracy: 0.9076 - val_loss: 0.3774 - val_accuracy: 0.9052\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3744 - accuracy: 0.9088 - val_loss: 0.3708 - val_accuracy: 0.9074\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3678 - accuracy: 0.9097 - val_loss: 0.3653 - val_accuracy: 0.9060\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3616 - accuracy: 0.9118 - val_loss: 0.3598 - val_accuracy: 0.9108\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3559 - accuracy: 0.9133 - val_loss: 0.3544 - val_accuracy: 0.9104\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3505 - accuracy: 0.9154 - val_loss: 0.3493 - val_accuracy: 0.9106\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3454 - accuracy: 0.9130 - val_loss: 0.3455 - val_accuracy: 0.9126\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3406 - accuracy: 0.9160 - val_loss: 0.3417 - val_accuracy: 0.9118\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3359 - accuracy: 0.9166 - val_loss: 0.3371 - val_accuracy: 0.9150\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3316 - accuracy: 0.9181 - val_loss: 0.3338 - val_accuracy: 0.9134\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3272 - accuracy: 0.9178 - val_loss: 0.3288 - val_accuracy: 0.9146\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3229 - accuracy: 0.9196 - val_loss: 0.3261 - val_accuracy: 0.9150\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3190 - accuracy: 0.9208 - val_loss: 0.3226 - val_accuracy: 0.9178\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3154 - accuracy: 0.9208 - val_loss: 0.3190 - val_accuracy: 0.9164\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3117 - accuracy: 0.9214 - val_loss: 0.3159 - val_accuracy: 0.9190\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3081 - accuracy: 0.9253 - val_loss: 0.3128 - val_accuracy: 0.9186\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3047 - accuracy: 0.9235 - val_loss: 0.3096 - val_accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3013 - accuracy: 0.9235 - val_loss: 0.3075 - val_accuracy: 0.9210\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2983 - accuracy: 0.9253 - val_loss: 0.3052 - val_accuracy: 0.9210\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2954 - accuracy: 0.9259 - val_loss: 0.3018 - val_accuracy: 0.9216\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2924 - accuracy: 0.9265 - val_loss: 0.2995 - val_accuracy: 0.9234\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2892 - accuracy: 0.9280 - val_loss: 0.2964 - val_accuracy: 0.9226\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2867 - accuracy: 0.9289 - val_loss: 0.2945 - val_accuracy: 0.9240\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2839 - accuracy: 0.9304 - val_loss: 0.2919 - val_accuracy: 0.9250\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2813 - accuracy: 0.9301 - val_loss: 0.2907 - val_accuracy: 0.9250\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2787 - accuracy: 0.9325 - val_loss: 0.2879 - val_accuracy: 0.9260\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2760 - accuracy: 0.9319 - val_loss: 0.2858 - val_accuracy: 0.9274\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2735 - accuracy: 0.9322 - val_loss: 0.2838 - val_accuracy: 0.9274\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2713 - accuracy: 0.9340 - val_loss: 0.2814 - val_accuracy: 0.9280\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2689 - accuracy: 0.9343 - val_loss: 0.2802 - val_accuracy: 0.9284\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2667 - accuracy: 0.9340 - val_loss: 0.2783 - val_accuracy: 0.9286\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2644 - accuracy: 0.9346 - val_loss: 0.2771 - val_accuracy: 0.9288\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2622 - accuracy: 0.9352 - val_loss: 0.2740 - val_accuracy: 0.9294\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2599 - accuracy: 0.9364 - val_loss: 0.2726 - val_accuracy: 0.9296\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2578 - accuracy: 0.9349 - val_loss: 0.2710 - val_accuracy: 0.9286\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2556 - accuracy: 0.9382 - val_loss: 0.2690 - val_accuracy: 0.9302\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2538 - accuracy: 0.9373 - val_loss: 0.2674 - val_accuracy: 0.9292\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2516 - accuracy: 0.9370 - val_loss: 0.2657 - val_accuracy: 0.9306\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2497 - accuracy: 0.9385 - val_loss: 0.2648 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2478 - accuracy: 0.9388 - val_loss: 0.2630 - val_accuracy: 0.9314\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2457 - accuracy: 0.9394 - val_loss: 0.2611 - val_accuracy: 0.9312\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2441 - accuracy: 0.9379 - val_loss: 0.2602 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2424 - accuracy: 0.9400 - val_loss: 0.2590 - val_accuracy: 0.9316\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2408 - accuracy: 0.9403 - val_loss: 0.2576 - val_accuracy: 0.9322\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2386 - accuracy: 0.9409 - val_loss: 0.2552 - val_accuracy: 0.9320\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2368 - accuracy: 0.9409 - val_loss: 0.2544 - val_accuracy: 0.9326\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2353 - accuracy: 0.9397 - val_loss: 0.2534 - val_accuracy: 0.9326\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2336 - accuracy: 0.9394 - val_loss: 0.2514 - val_accuracy: 0.9324\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2317 - accuracy: 0.9400 - val_loss: 0.2514 - val_accuracy: 0.9342\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2302 - accuracy: 0.9421 - val_loss: 0.2496 - val_accuracy: 0.9328\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2286 - accuracy: 0.9412 - val_loss: 0.2476 - val_accuracy: 0.9334\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2271 - accuracy: 0.9412 - val_loss: 0.2462 - val_accuracy: 0.9334\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2255 - accuracy: 0.9409 - val_loss: 0.2450 - val_accuracy: 0.9338\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2236 - accuracy: 0.9418 - val_loss: 0.2435 - val_accuracy: 0.9346\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2221 - accuracy: 0.9424 - val_loss: 0.2429 - val_accuracy: 0.9336\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2210 - accuracy: 0.9409 - val_loss: 0.2416 - val_accuracy: 0.9340\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2193 - accuracy: 0.9427 - val_loss: 0.2404 - val_accuracy: 0.9354\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2177 - accuracy: 0.9424 - val_loss: 0.2400 - val_accuracy: 0.9354\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2166 - accuracy: 0.9430 - val_loss: 0.2392 - val_accuracy: 0.9364\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2150 - accuracy: 0.9433 - val_loss: 0.2371 - val_accuracy: 0.9368\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2134 - accuracy: 0.9445 - val_loss: 0.2357 - val_accuracy: 0.9350\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2121 - accuracy: 0.9451 - val_loss: 0.2347 - val_accuracy: 0.9358\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2106 - accuracy: 0.9454 - val_loss: 0.2337 - val_accuracy: 0.9380\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2090 - accuracy: 0.9457 - val_loss: 0.2343 - val_accuracy: 0.9372\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2080 - accuracy: 0.9457 - val_loss: 0.2315 - val_accuracy: 0.9372\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2064 - accuracy: 0.9463 - val_loss: 0.2305 - val_accuracy: 0.9366\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2051 - accuracy: 0.9472 - val_loss: 0.2296 - val_accuracy: 0.9380\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9469 - val_loss: 0.2287 - val_accuracy: 0.9384\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2027 - accuracy: 0.9466 - val_loss: 0.2275 - val_accuracy: 0.9398\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2013 - accuracy: 0.9478 - val_loss: 0.2262 - val_accuracy: 0.9396\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2000 - accuracy: 0.9484 - val_loss: 0.2264 - val_accuracy: 0.9382\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1986 - accuracy: 0.9493 - val_loss: 0.2252 - val_accuracy: 0.9396\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1974 - accuracy: 0.9481 - val_loss: 0.2237 - val_accuracy: 0.9392\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1962 - accuracy: 0.9496 - val_loss: 0.2229 - val_accuracy: 0.9398\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1951 - accuracy: 0.9511 - val_loss: 0.2216 - val_accuracy: 0.9404\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1936 - accuracy: 0.9511 - val_loss: 0.2209 - val_accuracy: 0.9400\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1925 - accuracy: 0.9508 - val_loss: 0.2201 - val_accuracy: 0.9406\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.9184\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.1700 - accuracy: 0.2690 - val_loss: 1.9749 - val_accuracy: 0.4594\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.8021 - accuracy: 0.5540 - val_loss: 1.6281 - val_accuracy: 0.6224\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 1.4793 - accuracy: 0.6656 - val_loss: 1.3435 - val_accuracy: 0.7084\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.2314 - accuracy: 0.7382 - val_loss: 1.1338 - val_accuracy: 0.7574\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.0504 - accuracy: 0.7768 - val_loss: 0.9814 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.9184 - accuracy: 0.8053 - val_loss: 0.8706 - val_accuracy: 0.8138\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.8199 - accuracy: 0.8269 - val_loss: 0.7851 - val_accuracy: 0.8294\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.7443 - accuracy: 0.8389 - val_loss: 0.7192 - val_accuracy: 0.8432\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.6851 - accuracy: 0.8500 - val_loss: 0.6665 - val_accuracy: 0.8536\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.6369 - accuracy: 0.8602 - val_loss: 0.6245 - val_accuracy: 0.8606\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.5979 - accuracy: 0.8671 - val_loss: 0.5898 - val_accuracy: 0.8652\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.5652 - accuracy: 0.8704 - val_loss: 0.5593 - val_accuracy: 0.8690\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5368 - accuracy: 0.8773 - val_loss: 0.5345 - val_accuracy: 0.8742\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.5132 - accuracy: 0.8797 - val_loss: 0.5130 - val_accuracy: 0.8794\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.4925 - accuracy: 0.8845 - val_loss: 0.4947 - val_accuracy: 0.8816\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4747 - accuracy: 0.8881 - val_loss: 0.4766 - val_accuracy: 0.8866\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.4583 - accuracy: 0.8920 - val_loss: 0.4622 - val_accuracy: 0.8874\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4437 - accuracy: 0.8932 - val_loss: 0.4493 - val_accuracy: 0.8892\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4308 - accuracy: 0.8962 - val_loss: 0.4368 - val_accuracy: 0.8928\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.4191 - accuracy: 0.8986 - val_loss: 0.4258 - val_accuracy: 0.8950\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.4086 - accuracy: 0.9007 - val_loss: 0.4175 - val_accuracy: 0.8924\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3985 - accuracy: 0.8989 - val_loss: 0.4067 - val_accuracy: 0.8966\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3893 - accuracy: 0.9010 - val_loss: 0.3991 - val_accuracy: 0.8984\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3814 - accuracy: 0.9028 - val_loss: 0.3907 - val_accuracy: 0.8996\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3731 - accuracy: 0.9055 - val_loss: 0.3854 - val_accuracy: 0.8998\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3656 - accuracy: 0.9067 - val_loss: 0.3788 - val_accuracy: 0.9012\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3593 - accuracy: 0.9070 - val_loss: 0.3714 - val_accuracy: 0.9026\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3529 - accuracy: 0.9094 - val_loss: 0.3655 - val_accuracy: 0.9044\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3469 - accuracy: 0.9130 - val_loss: 0.3598 - val_accuracy: 0.9042\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3413 - accuracy: 0.9112 - val_loss: 0.3545 - val_accuracy: 0.9054\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3355 - accuracy: 0.9136 - val_loss: 0.3512 - val_accuracy: 0.9068\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3310 - accuracy: 0.9133 - val_loss: 0.3454 - val_accuracy: 0.9072\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.3261 - accuracy: 0.9163 - val_loss: 0.3410 - val_accuracy: 0.9088\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.3216 - accuracy: 0.9157 - val_loss: 0.3369 - val_accuracy: 0.9096\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3171 - accuracy: 0.9148 - val_loss: 0.3330 - val_accuracy: 0.9118\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3131 - accuracy: 0.9178 - val_loss: 0.3291 - val_accuracy: 0.9118\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3088 - accuracy: 0.9205 - val_loss: 0.3255 - val_accuracy: 0.9122\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.3052 - accuracy: 0.9190 - val_loss: 0.3221 - val_accuracy: 0.9130\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.3015 - accuracy: 0.9211 - val_loss: 0.3193 - val_accuracy: 0.9146\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2976 - accuracy: 0.9223 - val_loss: 0.3161 - val_accuracy: 0.9162\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2944 - accuracy: 0.9220 - val_loss: 0.3133 - val_accuracy: 0.9164\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2912 - accuracy: 0.9241 - val_loss: 0.3098 - val_accuracy: 0.9170\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2878 - accuracy: 0.9241 - val_loss: 0.3071 - val_accuracy: 0.9178\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2848 - accuracy: 0.9253 - val_loss: 0.3061 - val_accuracy: 0.9174\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2823 - accuracy: 0.9244 - val_loss: 0.3015 - val_accuracy: 0.9180\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2789 - accuracy: 0.9268 - val_loss: 0.2991 - val_accuracy: 0.9184\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2762 - accuracy: 0.9271 - val_loss: 0.2962 - val_accuracy: 0.9192\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2733 - accuracy: 0.9280 - val_loss: 0.2939 - val_accuracy: 0.9200\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2707 - accuracy: 0.9289 - val_loss: 0.2920 - val_accuracy: 0.9212\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2678 - accuracy: 0.9307 - val_loss: 0.2901 - val_accuracy: 0.9204\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2655 - accuracy: 0.9301 - val_loss: 0.2874 - val_accuracy: 0.9232\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2630 - accuracy: 0.9298 - val_loss: 0.2855 - val_accuracy: 0.9232\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2605 - accuracy: 0.9322 - val_loss: 0.2843 - val_accuracy: 0.9236\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2583 - accuracy: 0.9331 - val_loss: 0.2823 - val_accuracy: 0.9226\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2558 - accuracy: 0.9334 - val_loss: 0.2799 - val_accuracy: 0.9240\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2536 - accuracy: 0.9340 - val_loss: 0.2778 - val_accuracy: 0.9240\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2514 - accuracy: 0.9337 - val_loss: 0.2756 - val_accuracy: 0.9252\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2493 - accuracy: 0.9340 - val_loss: 0.2751 - val_accuracy: 0.9254\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2475 - accuracy: 0.9361 - val_loss: 0.2722 - val_accuracy: 0.9256\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2452 - accuracy: 0.9376 - val_loss: 0.2712 - val_accuracy: 0.9272\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2429 - accuracy: 0.9361 - val_loss: 0.2688 - val_accuracy: 0.9280\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2408 - accuracy: 0.9370 - val_loss: 0.2669 - val_accuracy: 0.9298\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2390 - accuracy: 0.9376 - val_loss: 0.2661 - val_accuracy: 0.9298\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2372 - accuracy: 0.9400 - val_loss: 0.2637 - val_accuracy: 0.9298\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2351 - accuracy: 0.9385 - val_loss: 0.2626 - val_accuracy: 0.9300\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2335 - accuracy: 0.9385 - val_loss: 0.2613 - val_accuracy: 0.9304\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2318 - accuracy: 0.9412 - val_loss: 0.2590 - val_accuracy: 0.9308\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2297 - accuracy: 0.9406 - val_loss: 0.2583 - val_accuracy: 0.9318\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2282 - accuracy: 0.9421 - val_loss: 0.2566 - val_accuracy: 0.9314\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2264 - accuracy: 0.9415 - val_loss: 0.2552 - val_accuracy: 0.9324\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.2247 - accuracy: 0.9442 - val_loss: 0.2538 - val_accuracy: 0.9306\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.2229 - accuracy: 0.9427 - val_loss: 0.2525 - val_accuracy: 0.9308\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2212 - accuracy: 0.9451 - val_loss: 0.2514 - val_accuracy: 0.9334\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.2196 - accuracy: 0.9436 - val_loss: 0.2498 - val_accuracy: 0.9334\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2181 - accuracy: 0.9451 - val_loss: 0.2483 - val_accuracy: 0.9330\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.2164 - accuracy: 0.9451 - val_loss: 0.2477 - val_accuracy: 0.9320\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.2146 - accuracy: 0.9436 - val_loss: 0.2463 - val_accuracy: 0.9334\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2136 - accuracy: 0.9457 - val_loss: 0.2450 - val_accuracy: 0.9334\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 0.2122 - accuracy: 0.9451 - val_loss: 0.2436 - val_accuracy: 0.9342\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2106 - accuracy: 0.9469 - val_loss: 0.2424 - val_accuracy: 0.9346\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2092 - accuracy: 0.9478 - val_loss: 0.2412 - val_accuracy: 0.9356\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2078 - accuracy: 0.9475 - val_loss: 0.2400 - val_accuracy: 0.9350\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2063 - accuracy: 0.9487 - val_loss: 0.2395 - val_accuracy: 0.9352\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2049 - accuracy: 0.9478 - val_loss: 0.2377 - val_accuracy: 0.9360\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.2035 - accuracy: 0.9487 - val_loss: 0.2375 - val_accuracy: 0.9350\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2021 - accuracy: 0.9469 - val_loss: 0.2367 - val_accuracy: 0.9370\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.2007 - accuracy: 0.9496 - val_loss: 0.2345 - val_accuracy: 0.9358\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1993 - accuracy: 0.9493 - val_loss: 0.2337 - val_accuracy: 0.9364\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.9493 - val_loss: 0.2325 - val_accuracy: 0.9370\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1968 - accuracy: 0.9502 - val_loss: 0.2317 - val_accuracy: 0.9370\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1953 - accuracy: 0.9502 - val_loss: 0.2305 - val_accuracy: 0.9378\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1941 - accuracy: 0.9505 - val_loss: 0.2310 - val_accuracy: 0.9372\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1929 - accuracy: 0.9505 - val_loss: 0.2293 - val_accuracy: 0.9366\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1917 - accuracy: 0.9517 - val_loss: 0.2275 - val_accuracy: 0.9384\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1903 - accuracy: 0.9505 - val_loss: 0.2270 - val_accuracy: 0.9384\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1891 - accuracy: 0.9526 - val_loss: 0.2256 - val_accuracy: 0.9388\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1878 - accuracy: 0.9517 - val_loss: 0.2253 - val_accuracy: 0.9380\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 0.1870 - accuracy: 0.9520 - val_loss: 0.2243 - val_accuracy: 0.9388\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1853 - accuracy: 0.9508 - val_loss: 0.2234 - val_accuracy: 0.9386\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.1842 - accuracy: 0.9526 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.9142\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 9ms/step - loss: 2.1321 - accuracy: 0.2874 - val_loss: 1.8615 - val_accuracy: 0.5198\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.6318 - accuracy: 0.6308 - val_loss: 1.4011 - val_accuracy: 0.7036\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 1.2272 - accuracy: 0.7500 - val_loss: 1.0673 - val_accuracy: 0.7886\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.9622 - accuracy: 0.8020 - val_loss: 0.8640 - val_accuracy: 0.8168\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.7997 - accuracy: 0.8256 - val_loss: 0.7368 - val_accuracy: 0.8412\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6951 - accuracy: 0.8458 - val_loss: 0.6508 - val_accuracy: 0.8548\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6227 - accuracy: 0.8572 - val_loss: 0.5901 - val_accuracy: 0.8632\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.8646 - val_loss: 0.5448 - val_accuracy: 0.8688\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.5296 - accuracy: 0.8716 - val_loss: 0.5104 - val_accuracy: 0.8724\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4977 - accuracy: 0.8762 - val_loss: 0.4811 - val_accuracy: 0.8798\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4717 - accuracy: 0.8798 - val_loss: 0.4578 - val_accuracy: 0.8872\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4498 - accuracy: 0.8874 - val_loss: 0.4377 - val_accuracy: 0.8866\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4314 - accuracy: 0.8904 - val_loss: 0.4216 - val_accuracy: 0.8914\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4157 - accuracy: 0.8934 - val_loss: 0.4056 - val_accuracy: 0.8970\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4013 - accuracy: 0.8968 - val_loss: 0.3940 - val_accuracy: 0.8988\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3897 - accuracy: 0.8994 - val_loss: 0.3811 - val_accuracy: 0.9022\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3785 - accuracy: 0.9020 - val_loss: 0.3707 - val_accuracy: 0.9030\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.3686 - accuracy: 0.9032 - val_loss: 0.3618 - val_accuracy: 0.9058\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3598 - accuracy: 0.9066 - val_loss: 0.3528 - val_accuracy: 0.9082\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3518 - accuracy: 0.9062 - val_loss: 0.3456 - val_accuracy: 0.9094\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 0.3445 - accuracy: 0.9092 - val_loss: 0.3381 - val_accuracy: 0.9090\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3371 - accuracy: 0.9114 - val_loss: 0.3325 - val_accuracy: 0.9122\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3308 - accuracy: 0.9130 - val_loss: 0.3259 - val_accuracy: 0.9140\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3251 - accuracy: 0.9124 - val_loss: 0.3207 - val_accuracy: 0.9158\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3198 - accuracy: 0.9150 - val_loss: 0.3143 - val_accuracy: 0.9160\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3143 - accuracy: 0.9154 - val_loss: 0.3095 - val_accuracy: 0.9186\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3091 - accuracy: 0.9166 - val_loss: 0.3050 - val_accuracy: 0.9188\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3049 - accuracy: 0.9190 - val_loss: 0.2999 - val_accuracy: 0.9204\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3003 - accuracy: 0.9198 - val_loss: 0.2955 - val_accuracy: 0.9214\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2960 - accuracy: 0.9210 - val_loss: 0.2916 - val_accuracy: 0.9226\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2919 - accuracy: 0.9220 - val_loss: 0.2888 - val_accuracy: 0.9226\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2883 - accuracy: 0.9238 - val_loss: 0.2843 - val_accuracy: 0.9240\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2845 - accuracy: 0.9242 - val_loss: 0.2804 - val_accuracy: 0.9254\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2812 - accuracy: 0.9256 - val_loss: 0.2770 - val_accuracy: 0.9254\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2778 - accuracy: 0.9270 - val_loss: 0.2737 - val_accuracy: 0.9264\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2745 - accuracy: 0.9264 - val_loss: 0.2705 - val_accuracy: 0.9276\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2715 - accuracy: 0.9278 - val_loss: 0.2671 - val_accuracy: 0.9290\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2684 - accuracy: 0.9286 - val_loss: 0.2644 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2647 - accuracy: 0.9320 - val_loss: 0.2620 - val_accuracy: 0.9308\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2624 - accuracy: 0.9312 - val_loss: 0.2587 - val_accuracy: 0.9324\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2598 - accuracy: 0.9304 - val_loss: 0.2561 - val_accuracy: 0.9328\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2573 - accuracy: 0.9324 - val_loss: 0.2537 - val_accuracy: 0.9332\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2547 - accuracy: 0.9324 - val_loss: 0.2512 - val_accuracy: 0.9348\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2522 - accuracy: 0.9346 - val_loss: 0.2483 - val_accuracy: 0.9360\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2495 - accuracy: 0.9350 - val_loss: 0.2462 - val_accuracy: 0.9360\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2475 - accuracy: 0.9358 - val_loss: 0.2436 - val_accuracy: 0.9370\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2451 - accuracy: 0.9352 - val_loss: 0.2413 - val_accuracy: 0.9378\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2427 - accuracy: 0.9372 - val_loss: 0.2391 - val_accuracy: 0.9380\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2404 - accuracy: 0.9370 - val_loss: 0.2372 - val_accuracy: 0.9380\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2383 - accuracy: 0.9392 - val_loss: 0.2352 - val_accuracy: 0.9394\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2365 - accuracy: 0.9382 - val_loss: 0.2328 - val_accuracy: 0.9394\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2342 - accuracy: 0.9388 - val_loss: 0.2312 - val_accuracy: 0.9412\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2321 - accuracy: 0.9390 - val_loss: 0.2293 - val_accuracy: 0.9416\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2302 - accuracy: 0.9400 - val_loss: 0.2270 - val_accuracy: 0.9410\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2285 - accuracy: 0.9404 - val_loss: 0.2250 - val_accuracy: 0.9424\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2264 - accuracy: 0.9420 - val_loss: 0.2239 - val_accuracy: 0.9420\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2249 - accuracy: 0.9426 - val_loss: 0.2214 - val_accuracy: 0.9440\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2224 - accuracy: 0.9426 - val_loss: 0.2202 - val_accuracy: 0.9442\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2211 - accuracy: 0.9430 - val_loss: 0.2192 - val_accuracy: 0.9446\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2198 - accuracy: 0.9434 - val_loss: 0.2160 - val_accuracy: 0.9456\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.2177 - accuracy: 0.9448 - val_loss: 0.2144 - val_accuracy: 0.9458\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2158 - accuracy: 0.9460 - val_loss: 0.2130 - val_accuracy: 0.9454\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2139 - accuracy: 0.9452 - val_loss: 0.2116 - val_accuracy: 0.9466\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2124 - accuracy: 0.9470 - val_loss: 0.2103 - val_accuracy: 0.9470\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2112 - accuracy: 0.9466 - val_loss: 0.2077 - val_accuracy: 0.9474\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2093 - accuracy: 0.9464 - val_loss: 0.2064 - val_accuracy: 0.9466\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2079 - accuracy: 0.9470 - val_loss: 0.2048 - val_accuracy: 0.9484\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2062 - accuracy: 0.9466 - val_loss: 0.2035 - val_accuracy: 0.9484\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2047 - accuracy: 0.9484 - val_loss: 0.2016 - val_accuracy: 0.9486\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2031 - accuracy: 0.9482 - val_loss: 0.2004 - val_accuracy: 0.9502\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2018 - accuracy: 0.9488 - val_loss: 0.1991 - val_accuracy: 0.9488\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2003 - accuracy: 0.9478 - val_loss: 0.1976 - val_accuracy: 0.9482\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1989 - accuracy: 0.9480 - val_loss: 0.1959 - val_accuracy: 0.9498\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1976 - accuracy: 0.9496 - val_loss: 0.1945 - val_accuracy: 0.9504\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1958 - accuracy: 0.9502 - val_loss: 0.1931 - val_accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1947 - accuracy: 0.9510 - val_loss: 0.1919 - val_accuracy: 0.9508\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1930 - accuracy: 0.9524 - val_loss: 0.1907 - val_accuracy: 0.9512\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1921 - accuracy: 0.9512 - val_loss: 0.1889 - val_accuracy: 0.9518\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 0.1905 - accuracy: 0.9510 - val_loss: 0.1877 - val_accuracy: 0.9512\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1893 - accuracy: 0.9512 - val_loss: 0.1863 - val_accuracy: 0.9516\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1878 - accuracy: 0.9526 - val_loss: 0.1853 - val_accuracy: 0.9530\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1865 - accuracy: 0.9510 - val_loss: 0.1837 - val_accuracy: 0.9528\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1850 - accuracy: 0.9518 - val_loss: 0.1828 - val_accuracy: 0.9516\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1841 - accuracy: 0.9512 - val_loss: 0.1812 - val_accuracy: 0.9536\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1826 - accuracy: 0.9528 - val_loss: 0.1800 - val_accuracy: 0.9542\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1814 - accuracy: 0.9542 - val_loss: 0.1789 - val_accuracy: 0.9530\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.1801 - accuracy: 0.9540 - val_loss: 0.1777 - val_accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.9546 - val_loss: 0.1763 - val_accuracy: 0.9550\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1778 - accuracy: 0.9544 - val_loss: 0.1753 - val_accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1766 - accuracy: 0.9546 - val_loss: 0.1740 - val_accuracy: 0.9572\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1755 - accuracy: 0.9564 - val_loss: 0.1729 - val_accuracy: 0.9574\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.1742 - accuracy: 0.9564 - val_loss: 0.1717 - val_accuracy: 0.9564\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1730 - accuracy: 0.9564 - val_loss: 0.1712 - val_accuracy: 0.9572\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1716 - accuracy: 0.9580 - val_loss: 0.1698 - val_accuracy: 0.9584\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.1708 - accuracy: 0.9572 - val_loss: 0.1681 - val_accuracy: 0.9580\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1697 - accuracy: 0.9578 - val_loss: 0.1670 - val_accuracy: 0.9594\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.1684 - accuracy: 0.9582 - val_loss: 0.1664 - val_accuracy: 0.9588\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1675 - accuracy: 0.9588 - val_loss: 0.1649 - val_accuracy: 0.9590\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1663 - accuracy: 0.9582 - val_loss: 0.1636 - val_accuracy: 0.9592\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1650 - accuracy: 0.9574 - val_loss: 0.1628 - val_accuracy: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x17a6bbd30&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: array([1, 2, 3, 4, 5, 6, 7]),\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x17a6bbd30&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: array([1, 2, 3, 4, 5, 6, 7]),\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x17a6bbd30>,\n",
       "                                        'n_hidden': array([1, 2, 3, 4, 5, 6, 7]),\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": np.arange(1,4),\n",
    "    \"n_neurons\": np.arange(20, 80),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_class, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                           tensorboard_cb],\n",
    "                  workers=2\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005349081049562388, 'n_hidden': 1, 'n_neurons': 60}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092010060946146"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.save(\"keras_model_mnist_1st_rnd_search.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params_around_best():\n",
    "    best_params = rnd_search_cv.best_params_\n",
    "    num_hidden = np.arange(best_params['n_hidden'] - 1, best_params['n_hidden'] + 3)\n",
    "    num_neurons = np.arange(best_params['n_neurons'] - 10, best_params['n_neurons'] + 10)\n",
    "    learning_rate = reciprocal(best_params['learning_rate'] * 0.5, best_params['learning_rate'] * 1.5)\n",
    "    \n",
    "    \n",
    "    param_distribs = {\n",
    "    \"n_hidden\": num_hidden,\n",
    "    \"n_neurons\": num_neurons,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": [10, 20, 30],\n",
    "    }\n",
    "    return param_distribs\n",
    "\n",
    "opt_param_distribs = create_params_around_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "167/167 [==============================] - 3s 11ms/step - loss: 2.1817 - accuracy: 0.2430 - val_loss: 2.0770 - val_accuracy: 0.3836\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 1.9126 - accuracy: 0.5281 - val_loss: 1.7367 - val_accuracy: 0.6172\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 1.4945 - accuracy: 0.6703 - val_loss: 1.2849 - val_accuracy: 0.7140\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 1.0736 - accuracy: 0.7531 - val_loss: 0.9367 - val_accuracy: 0.7732\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.8045 - accuracy: 0.8005 - val_loss: 0.7411 - val_accuracy: 0.8080\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.6517 - accuracy: 0.8299 - val_loss: 0.6270 - val_accuracy: 0.8334\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5526 - accuracy: 0.8596 - val_loss: 0.5547 - val_accuracy: 0.8494\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.8719 - val_loss: 0.4936 - val_accuracy: 0.8686\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8839 - val_loss: 0.4519 - val_accuracy: 0.8778\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3939 - accuracy: 0.8911 - val_loss: 0.4205 - val_accuracy: 0.8830\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3641 - accuracy: 0.9031 - val_loss: 0.3957 - val_accuracy: 0.8902\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3408 - accuracy: 0.9052 - val_loss: 0.3759 - val_accuracy: 0.8972\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3197 - accuracy: 0.9103 - val_loss: 0.3749 - val_accuracy: 0.8922\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2996 - accuracy: 0.9172 - val_loss: 0.3731 - val_accuracy: 0.8914\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2894 - accuracy: 0.9202 - val_loss: 0.3328 - val_accuracy: 0.9080\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.2736 - accuracy: 0.9274 - val_loss: 0.3188 - val_accuracy: 0.9112\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2608 - accuracy: 0.9289 - val_loss: 0.3176 - val_accuracy: 0.9120\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2524 - accuracy: 0.9322 - val_loss: 0.3014 - val_accuracy: 0.9168\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2402 - accuracy: 0.9349 - val_loss: 0.3046 - val_accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2309 - accuracy: 0.9364 - val_loss: 0.2901 - val_accuracy: 0.9220\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2242 - accuracy: 0.9400 - val_loss: 0.2868 - val_accuracy: 0.9222\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2169 - accuracy: 0.9427 - val_loss: 0.2818 - val_accuracy: 0.9228\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.2094 - accuracy: 0.9436 - val_loss: 0.2722 - val_accuracy: 0.9274\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2031 - accuracy: 0.9475 - val_loss: 0.2648 - val_accuracy: 0.9266\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1947 - accuracy: 0.9478 - val_loss: 0.2607 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1902 - accuracy: 0.9496 - val_loss: 0.2553 - val_accuracy: 0.9326\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9550 - val_loss: 0.2530 - val_accuracy: 0.9338\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1781 - accuracy: 0.9544 - val_loss: 0.2504 - val_accuracy: 0.9334\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1724 - accuracy: 0.9562 - val_loss: 0.2427 - val_accuracy: 0.9360\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1669 - accuracy: 0.9601 - val_loss: 0.2397 - val_accuracy: 0.9400\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1601 - accuracy: 0.9589 - val_loss: 0.2359 - val_accuracy: 0.9390\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1579 - accuracy: 0.9610 - val_loss: 0.2329 - val_accuracy: 0.9418\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1510 - accuracy: 0.9628 - val_loss: 0.2296 - val_accuracy: 0.9420\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1462 - accuracy: 0.9661 - val_loss: 0.2375 - val_accuracy: 0.9376\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1445 - accuracy: 0.9634 - val_loss: 0.2228 - val_accuracy: 0.9446\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1392 - accuracy: 0.9649 - val_loss: 0.2238 - val_accuracy: 0.9446\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1357 - accuracy: 0.9676 - val_loss: 0.2196 - val_accuracy: 0.9460\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1311 - accuracy: 0.9691 - val_loss: 0.2156 - val_accuracy: 0.9478\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.1266 - accuracy: 0.9727 - val_loss: 0.2128 - val_accuracy: 0.9458\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1241 - accuracy: 0.9709 - val_loss: 0.2132 - val_accuracy: 0.9456\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9724 - val_loss: 0.2071 - val_accuracy: 0.9494\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9712 - val_loss: 0.2079 - val_accuracy: 0.9474\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1136 - accuracy: 0.9733 - val_loss: 0.2027 - val_accuracy: 0.9508\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.1099 - accuracy: 0.9760 - val_loss: 0.2004 - val_accuracy: 0.9512\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1065 - accuracy: 0.9775 - val_loss: 0.2042 - val_accuracy: 0.9500\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1045 - accuracy: 0.9769 - val_loss: 0.1972 - val_accuracy: 0.9520\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1011 - accuracy: 0.9778 - val_loss: 0.1927 - val_accuracy: 0.9526\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0979 - accuracy: 0.9796 - val_loss: 0.1930 - val_accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0958 - accuracy: 0.9805 - val_loss: 0.1941 - val_accuracy: 0.9538\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.1950 - val_accuracy: 0.9550\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0905 - accuracy: 0.9823 - val_loss: 0.1921 - val_accuracy: 0.9552\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0872 - accuracy: 0.9814 - val_loss: 0.1865 - val_accuracy: 0.9556\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0838 - accuracy: 0.9838 - val_loss: 0.1893 - val_accuracy: 0.9560\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0823 - accuracy: 0.9844 - val_loss: 0.1877 - val_accuracy: 0.9574\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9853 - val_loss: 0.1847 - val_accuracy: 0.9542\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0782 - accuracy: 0.9838 - val_loss: 0.1825 - val_accuracy: 0.9582\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0755 - accuracy: 0.9844 - val_loss: 0.1844 - val_accuracy: 0.9570\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0731 - accuracy: 0.9859 - val_loss: 0.1858 - val_accuracy: 0.9554\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0710 - accuracy: 0.9877 - val_loss: 0.1786 - val_accuracy: 0.9580\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0694 - accuracy: 0.9871 - val_loss: 0.1774 - val_accuracy: 0.9584\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0677 - accuracy: 0.9874 - val_loss: 0.1785 - val_accuracy: 0.9594\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 0.9877 - val_loss: 0.1741 - val_accuracy: 0.9594\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0627 - accuracy: 0.9886 - val_loss: 0.1780 - val_accuracy: 0.9598\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0614 - accuracy: 0.9892 - val_loss: 0.1828 - val_accuracy: 0.9588\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0600 - accuracy: 0.9886 - val_loss: 0.1740 - val_accuracy: 0.9612\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0577 - accuracy: 0.9904 - val_loss: 0.1753 - val_accuracy: 0.9612\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0561 - accuracy: 0.9913 - val_loss: 0.1725 - val_accuracy: 0.9608\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0544 - accuracy: 0.9910 - val_loss: 0.1734 - val_accuracy: 0.9612\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0533 - accuracy: 0.9907 - val_loss: 0.1729 - val_accuracy: 0.9602\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0517 - accuracy: 0.9910 - val_loss: 0.1727 - val_accuracy: 0.9620\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0501 - accuracy: 0.9904 - val_loss: 0.1713 - val_accuracy: 0.9606\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0497 - accuracy: 0.9907 - val_loss: 0.1676 - val_accuracy: 0.9618\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0473 - accuracy: 0.9919 - val_loss: 0.1729 - val_accuracy: 0.9622\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0458 - accuracy: 0.9925 - val_loss: 0.1751 - val_accuracy: 0.9618\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0449 - accuracy: 0.9937 - val_loss: 0.1672 - val_accuracy: 0.9632\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0434 - accuracy: 0.9946 - val_loss: 0.1665 - val_accuracy: 0.9616\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9937 - val_loss: 0.1648 - val_accuracy: 0.9612\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0409 - accuracy: 0.9940 - val_loss: 0.1693 - val_accuracy: 0.9632\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0394 - accuracy: 0.9943 - val_loss: 0.1634 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0386 - accuracy: 0.9946 - val_loss: 0.1745 - val_accuracy: 0.9612\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0376 - accuracy: 0.9961 - val_loss: 0.1706 - val_accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0368 - accuracy: 0.9955 - val_loss: 0.1692 - val_accuracy: 0.9636\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0355 - accuracy: 0.9952 - val_loss: 0.1631 - val_accuracy: 0.9638\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9949 - val_loss: 0.1718 - val_accuracy: 0.9636\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0336 - accuracy: 0.9952 - val_loss: 0.1645 - val_accuracy: 0.9640\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9964 - val_loss: 0.1690 - val_accuracy: 0.9644\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9967 - val_loss: 0.1669 - val_accuracy: 0.9636\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9955 - val_loss: 0.1625 - val_accuracy: 0.9654\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9967 - val_loss: 0.1658 - val_accuracy: 0.9656\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0293 - accuracy: 0.9970 - val_loss: 0.1614 - val_accuracy: 0.9650\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9967 - val_loss: 0.1660 - val_accuracy: 0.9636\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0278 - accuracy: 0.9967 - val_loss: 0.1643 - val_accuracy: 0.9644\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9967 - val_loss: 0.1635 - val_accuracy: 0.9638\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0266 - accuracy: 0.9967 - val_loss: 0.1644 - val_accuracy: 0.9654\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0261 - accuracy: 0.9970 - val_loss: 0.1630 - val_accuracy: 0.9652\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0252 - accuracy: 0.9967 - val_loss: 0.1645 - val_accuracy: 0.9650\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0247 - accuracy: 0.9973 - val_loss: 0.1643 - val_accuracy: 0.9646\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0239 - accuracy: 0.9976 - val_loss: 0.1616 - val_accuracy: 0.9654\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0231 - accuracy: 0.9979 - val_loss: 0.1617 - val_accuracy: 0.9652\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9982 - val_loss: 0.1635 - val_accuracy: 0.9650\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8992\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 2s 7ms/step - loss: 2.2516 - accuracy: 0.1959 - val_loss: 2.1640 - val_accuracy: 0.2656\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 2.0471 - accuracy: 0.3366 - val_loss: 1.8957 - val_accuracy: 0.4094\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 1.7298 - accuracy: 0.5083 - val_loss: 1.5368 - val_accuracy: 0.6154\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 1.3613 - accuracy: 0.6859 - val_loss: 1.1781 - val_accuracy: 0.7182\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 1.0505 - accuracy: 0.7423 - val_loss: 0.9194 - val_accuracy: 0.7776\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.8425 - accuracy: 0.7909 - val_loss: 0.7532 - val_accuracy: 0.8038\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.7033 - accuracy: 0.8233 - val_loss: 0.6415 - val_accuracy: 0.8278\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.6066 - accuracy: 0.8434 - val_loss: 0.5553 - val_accuracy: 0.8532\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5350 - accuracy: 0.8641 - val_loss: 0.5077 - val_accuracy: 0.8584\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.4840 - accuracy: 0.8725 - val_loss: 0.4542 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.4437 - accuracy: 0.8842 - val_loss: 0.4196 - val_accuracy: 0.8940\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.4137 - accuracy: 0.8920 - val_loss: 0.3928 - val_accuracy: 0.8960\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3859 - accuracy: 0.8992 - val_loss: 0.3872 - val_accuracy: 0.8952\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3668 - accuracy: 0.9043 - val_loss: 0.3576 - val_accuracy: 0.9036\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3484 - accuracy: 0.9070 - val_loss: 0.3470 - val_accuracy: 0.9070\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3326 - accuracy: 0.9130 - val_loss: 0.3311 - val_accuracy: 0.9106\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3208 - accuracy: 0.9175 - val_loss: 0.3190 - val_accuracy: 0.9132\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3062 - accuracy: 0.9202 - val_loss: 0.3209 - val_accuracy: 0.9154\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2980 - accuracy: 0.9196 - val_loss: 0.2992 - val_accuracy: 0.9222\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2869 - accuracy: 0.9250 - val_loss: 0.2896 - val_accuracy: 0.9242\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2761 - accuracy: 0.9256 - val_loss: 0.2877 - val_accuracy: 0.9262\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2680 - accuracy: 0.9304 - val_loss: 0.2801 - val_accuracy: 0.9238\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2618 - accuracy: 0.9316 - val_loss: 0.2714 - val_accuracy: 0.9256\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2545 - accuracy: 0.9319 - val_loss: 0.2623 - val_accuracy: 0.9324\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2467 - accuracy: 0.9364 - val_loss: 0.2616 - val_accuracy: 0.9312\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2403 - accuracy: 0.9370 - val_loss: 0.2535 - val_accuracy: 0.9336\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2345 - accuracy: 0.9373 - val_loss: 0.2490 - val_accuracy: 0.9324\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2267 - accuracy: 0.9406 - val_loss: 0.2462 - val_accuracy: 0.9354\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2216 - accuracy: 0.9418 - val_loss: 0.2424 - val_accuracy: 0.9368\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2160 - accuracy: 0.9436 - val_loss: 0.2353 - val_accuracy: 0.9362\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2100 - accuracy: 0.9433 - val_loss: 0.2360 - val_accuracy: 0.9370\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2051 - accuracy: 0.9442 - val_loss: 0.2352 - val_accuracy: 0.9362\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2000 - accuracy: 0.9487 - val_loss: 0.2243 - val_accuracy: 0.9434\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1942 - accuracy: 0.9520 - val_loss: 0.2209 - val_accuracy: 0.9416\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1898 - accuracy: 0.9493 - val_loss: 0.2267 - val_accuracy: 0.9376\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.9541 - val_loss: 0.2149 - val_accuracy: 0.9424\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1806 - accuracy: 0.9544 - val_loss: 0.2069 - val_accuracy: 0.9446\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1764 - accuracy: 0.9520 - val_loss: 0.2079 - val_accuracy: 0.9442\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.1709 - accuracy: 0.9562 - val_loss: 0.2040 - val_accuracy: 0.9452\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1678 - accuracy: 0.9574 - val_loss: 0.2006 - val_accuracy: 0.9462\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1637 - accuracy: 0.9586 - val_loss: 0.1962 - val_accuracy: 0.9490\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.1603 - accuracy: 0.9583 - val_loss: 0.1916 - val_accuracy: 0.9488\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1551 - accuracy: 0.9595 - val_loss: 0.1955 - val_accuracy: 0.9472\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1530 - accuracy: 0.9601 - val_loss: 0.1912 - val_accuracy: 0.9488\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.1490 - accuracy: 0.9616 - val_loss: 0.1949 - val_accuracy: 0.9478\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.1456 - accuracy: 0.9640 - val_loss: 0.1856 - val_accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1424 - accuracy: 0.9640 - val_loss: 0.1862 - val_accuracy: 0.9510\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.1384 - accuracy: 0.9631 - val_loss: 0.1842 - val_accuracy: 0.9482\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.1330 - accuracy: 0.9667 - val_loss: 0.1821 - val_accuracy: 0.9504\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1317 - accuracy: 0.9676 - val_loss: 0.1737 - val_accuracy: 0.9546\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1276 - accuracy: 0.9682 - val_loss: 0.1718 - val_accuracy: 0.9554\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1253 - accuracy: 0.9688 - val_loss: 0.1720 - val_accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1211 - accuracy: 0.9694 - val_loss: 0.1700 - val_accuracy: 0.9554\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1183 - accuracy: 0.9700 - val_loss: 0.1736 - val_accuracy: 0.9526\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1161 - accuracy: 0.9724 - val_loss: 0.1646 - val_accuracy: 0.9574\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1130 - accuracy: 0.9712 - val_loss: 0.1646 - val_accuracy: 0.9588\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.1093 - accuracy: 0.9745 - val_loss: 0.1623 - val_accuracy: 0.9588\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1065 - accuracy: 0.9769 - val_loss: 0.1636 - val_accuracy: 0.9574\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1041 - accuracy: 0.9772 - val_loss: 0.1635 - val_accuracy: 0.9564\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1029 - accuracy: 0.9751 - val_loss: 0.1628 - val_accuracy: 0.9556\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9772 - val_loss: 0.1546 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0970 - accuracy: 0.9781 - val_loss: 0.1563 - val_accuracy: 0.9590\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0953 - accuracy: 0.9787 - val_loss: 0.1521 - val_accuracy: 0.9622\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0916 - accuracy: 0.9808 - val_loss: 0.1525 - val_accuracy: 0.9612\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0903 - accuracy: 0.9778 - val_loss: 0.1486 - val_accuracy: 0.9624\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0871 - accuracy: 0.9796 - val_loss: 0.1483 - val_accuracy: 0.9640\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0852 - accuracy: 0.9811 - val_loss: 0.1467 - val_accuracy: 0.9640\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0836 - accuracy: 0.9823 - val_loss: 0.1479 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9841 - val_loss: 0.1434 - val_accuracy: 0.9636\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0787 - accuracy: 0.9826 - val_loss: 0.1435 - val_accuracy: 0.9652\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0770 - accuracy: 0.9856 - val_loss: 0.1417 - val_accuracy: 0.9634\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0742 - accuracy: 0.9850 - val_loss: 0.1549 - val_accuracy: 0.9606\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9856 - val_loss: 0.1411 - val_accuracy: 0.9634\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0711 - accuracy: 0.9862 - val_loss: 0.1413 - val_accuracy: 0.9656\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0683 - accuracy: 0.9877 - val_loss: 0.1429 - val_accuracy: 0.9660\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0676 - accuracy: 0.9874 - val_loss: 0.1358 - val_accuracy: 0.9678\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0654 - accuracy: 0.9880 - val_loss: 0.1358 - val_accuracy: 0.9660\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0638 - accuracy: 0.9889 - val_loss: 0.1359 - val_accuracy: 0.9664\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0622 - accuracy: 0.9886 - val_loss: 0.1364 - val_accuracy: 0.9664\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0612 - accuracy: 0.9883 - val_loss: 0.1352 - val_accuracy: 0.9676\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0587 - accuracy: 0.9898 - val_loss: 0.1325 - val_accuracy: 0.9688\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0571 - accuracy: 0.9913 - val_loss: 0.1323 - val_accuracy: 0.9690\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0558 - accuracy: 0.9922 - val_loss: 0.1310 - val_accuracy: 0.9698\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0546 - accuracy: 0.9928 - val_loss: 0.1306 - val_accuracy: 0.9694\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0527 - accuracy: 0.9916 - val_loss: 0.1344 - val_accuracy: 0.9694\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0519 - accuracy: 0.9934 - val_loss: 0.1306 - val_accuracy: 0.9694\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0504 - accuracy: 0.9919 - val_loss: 0.1286 - val_accuracy: 0.9708\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0483 - accuracy: 0.9928 - val_loss: 0.1323 - val_accuracy: 0.9678\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9931 - val_loss: 0.1266 - val_accuracy: 0.9710\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0463 - accuracy: 0.9940 - val_loss: 0.1266 - val_accuracy: 0.9710\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0455 - accuracy: 0.9949 - val_loss: 0.1314 - val_accuracy: 0.9708\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9943 - val_loss: 0.1272 - val_accuracy: 0.9706\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0431 - accuracy: 0.9946 - val_loss: 0.1260 - val_accuracy: 0.9712\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0422 - accuracy: 0.9952 - val_loss: 0.1263 - val_accuracy: 0.9712\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9958 - val_loss: 0.1270 - val_accuracy: 0.9726\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0398 - accuracy: 0.9958 - val_loss: 0.1259 - val_accuracy: 0.9728\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0388 - accuracy: 0.9958 - val_loss: 0.1235 - val_accuracy: 0.9726\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0377 - accuracy: 0.9961 - val_loss: 0.1246 - val_accuracy: 0.9716\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0369 - accuracy: 0.9961 - val_loss: 0.1247 - val_accuracy: 0.9728\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0361 - accuracy: 0.9970 - val_loss: 0.1251 - val_accuracy: 0.9714\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.9208\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 2.2584 - accuracy: 0.1869 - val_loss: 2.1626 - val_accuracy: 0.3108\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 2.0382 - accuracy: 0.4100 - val_loss: 1.8868 - val_accuracy: 0.5040\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 1.6809 - accuracy: 0.5813 - val_loss: 1.4572 - val_accuracy: 0.6418\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.2395 - accuracy: 0.7013 - val_loss: 1.0481 - val_accuracy: 0.7426\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.9070 - accuracy: 0.7873 - val_loss: 0.8013 - val_accuracy: 0.7952\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.7210 - accuracy: 0.8197 - val_loss: 0.6654 - val_accuracy: 0.8292\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.6122 - accuracy: 0.8422 - val_loss: 0.5814 - val_accuracy: 0.8438\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.5401 - accuracy: 0.8515 - val_loss: 0.5191 - val_accuracy: 0.8634\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.4872 - accuracy: 0.8674 - val_loss: 0.4708 - val_accuracy: 0.8748\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.4453 - accuracy: 0.8779 - val_loss: 0.4517 - val_accuracy: 0.8732\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.4132 - accuracy: 0.8860 - val_loss: 0.4235 - val_accuracy: 0.8820\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.3877 - accuracy: 0.8932 - val_loss: 0.3841 - val_accuracy: 0.8960\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.3636 - accuracy: 0.8962 - val_loss: 0.3668 - val_accuracy: 0.8996\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.3450 - accuracy: 0.9022 - val_loss: 0.3540 - val_accuracy: 0.9018\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.3285 - accuracy: 0.9082 - val_loss: 0.3382 - val_accuracy: 0.9074\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3147 - accuracy: 0.9112 - val_loss: 0.3254 - val_accuracy: 0.9114\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3033 - accuracy: 0.9157 - val_loss: 0.3134 - val_accuracy: 0.9128\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2907 - accuracy: 0.9181 - val_loss: 0.3069 - val_accuracy: 0.9142\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2796 - accuracy: 0.9235 - val_loss: 0.3071 - val_accuracy: 0.9144\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.2695 - accuracy: 0.9259 - val_loss: 0.2918 - val_accuracy: 0.9172\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2605 - accuracy: 0.9274 - val_loss: 0.2834 - val_accuracy: 0.9238\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.2541 - accuracy: 0.9307 - val_loss: 0.2783 - val_accuracy: 0.9206\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2442 - accuracy: 0.9325 - val_loss: 0.2676 - val_accuracy: 0.9264\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2372 - accuracy: 0.9331 - val_loss: 0.2659 - val_accuracy: 0.9292\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2307 - accuracy: 0.9349 - val_loss: 0.2547 - val_accuracy: 0.9300\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2241 - accuracy: 0.9385 - val_loss: 0.2523 - val_accuracy: 0.9288\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.2171 - accuracy: 0.9400 - val_loss: 0.2544 - val_accuracy: 0.9272\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2119 - accuracy: 0.9403 - val_loss: 0.2427 - val_accuracy: 0.9350\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.2043 - accuracy: 0.9451 - val_loss: 0.2410 - val_accuracy: 0.9316\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1992 - accuracy: 0.9451 - val_loss: 0.2302 - val_accuracy: 0.9390\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.1942 - accuracy: 0.9454 - val_loss: 0.2312 - val_accuracy: 0.9368\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.1900 - accuracy: 0.9481 - val_loss: 0.2238 - val_accuracy: 0.9394\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1839 - accuracy: 0.9520 - val_loss: 0.2259 - val_accuracy: 0.9392\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1777 - accuracy: 0.9502 - val_loss: 0.2194 - val_accuracy: 0.9414\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1749 - accuracy: 0.9526 - val_loss: 0.2124 - val_accuracy: 0.9444\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1699 - accuracy: 0.9562 - val_loss: 0.2108 - val_accuracy: 0.9432\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.1662 - accuracy: 0.9544 - val_loss: 0.2089 - val_accuracy: 0.9446\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1613 - accuracy: 0.9565 - val_loss: 0.2035 - val_accuracy: 0.9480\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.1562 - accuracy: 0.9601 - val_loss: 0.2018 - val_accuracy: 0.9462\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1520 - accuracy: 0.9589 - val_loss: 0.1985 - val_accuracy: 0.9472\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1491 - accuracy: 0.9613 - val_loss: 0.1956 - val_accuracy: 0.9504\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1448 - accuracy: 0.9637 - val_loss: 0.1908 - val_accuracy: 0.9498\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1400 - accuracy: 0.9655 - val_loss: 0.1891 - val_accuracy: 0.9512\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1381 - accuracy: 0.9646 - val_loss: 0.1854 - val_accuracy: 0.9542\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1335 - accuracy: 0.9658 - val_loss: 0.1841 - val_accuracy: 0.9508\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1296 - accuracy: 0.9661 - val_loss: 0.1804 - val_accuracy: 0.9538\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9697 - val_loss: 0.1827 - val_accuracy: 0.9522\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1230 - accuracy: 0.9691 - val_loss: 0.1796 - val_accuracy: 0.9542\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1200 - accuracy: 0.9709 - val_loss: 0.1743 - val_accuracy: 0.9562\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1159 - accuracy: 0.9709 - val_loss: 0.1748 - val_accuracy: 0.9546\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.1134 - accuracy: 0.9730 - val_loss: 0.1692 - val_accuracy: 0.9584\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1092 - accuracy: 0.9742 - val_loss: 0.1698 - val_accuracy: 0.9570\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1072 - accuracy: 0.9742 - val_loss: 0.1663 - val_accuracy: 0.9588\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1049 - accuracy: 0.9748 - val_loss: 0.1668 - val_accuracy: 0.9590\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1021 - accuracy: 0.9766 - val_loss: 0.1621 - val_accuracy: 0.9612\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0990 - accuracy: 0.9781 - val_loss: 0.1616 - val_accuracy: 0.9614\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0964 - accuracy: 0.9784 - val_loss: 0.1589 - val_accuracy: 0.9624\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0938 - accuracy: 0.9790 - val_loss: 0.1569 - val_accuracy: 0.9636\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0912 - accuracy: 0.9805 - val_loss: 0.1570 - val_accuracy: 0.9632\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0883 - accuracy: 0.9817 - val_loss: 0.1557 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0852 - accuracy: 0.9820 - val_loss: 0.1545 - val_accuracy: 0.9644\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0844 - accuracy: 0.9823 - val_loss: 0.1547 - val_accuracy: 0.9648\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0820 - accuracy: 0.9835 - val_loss: 0.1509 - val_accuracy: 0.9646\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0793 - accuracy: 0.9835 - val_loss: 0.1528 - val_accuracy: 0.9648\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0769 - accuracy: 0.9856 - val_loss: 0.1502 - val_accuracy: 0.9650\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0745 - accuracy: 0.9865 - val_loss: 0.1491 - val_accuracy: 0.9664\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0726 - accuracy: 0.9859 - val_loss: 0.1492 - val_accuracy: 0.9642\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0709 - accuracy: 0.9862 - val_loss: 0.1454 - val_accuracy: 0.9672\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0681 - accuracy: 0.9892 - val_loss: 0.1464 - val_accuracy: 0.9658\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0671 - accuracy: 0.9868 - val_loss: 0.1448 - val_accuracy: 0.9668\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0652 - accuracy: 0.9862 - val_loss: 0.1429 - val_accuracy: 0.9686\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0631 - accuracy: 0.9892 - val_loss: 0.1420 - val_accuracy: 0.9700\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0614 - accuracy: 0.9883 - val_loss: 0.1421 - val_accuracy: 0.9682\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0600 - accuracy: 0.9901 - val_loss: 0.1433 - val_accuracy: 0.9674\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0585 - accuracy: 0.9904 - val_loss: 0.1406 - val_accuracy: 0.9682\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0566 - accuracy: 0.9916 - val_loss: 0.1415 - val_accuracy: 0.9676\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9904 - val_loss: 0.1388 - val_accuracy: 0.9700\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0544 - accuracy: 0.9919 - val_loss: 0.1393 - val_accuracy: 0.9692\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0527 - accuracy: 0.9922 - val_loss: 0.1371 - val_accuracy: 0.9704\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0508 - accuracy: 0.9925 - val_loss: 0.1406 - val_accuracy: 0.9690\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0502 - accuracy: 0.9922 - val_loss: 0.1379 - val_accuracy: 0.9690\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0486 - accuracy: 0.9919 - val_loss: 0.1358 - val_accuracy: 0.9712\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9928 - val_loss: 0.1364 - val_accuracy: 0.9710\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0455 - accuracy: 0.9934 - val_loss: 0.1358 - val_accuracy: 0.9710\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0441 - accuracy: 0.9937 - val_loss: 0.1373 - val_accuracy: 0.9708\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.0430 - accuracy: 0.9949 - val_loss: 0.1338 - val_accuracy: 0.9726\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0421 - accuracy: 0.9949 - val_loss: 0.1346 - val_accuracy: 0.9718\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9946 - val_loss: 0.1342 - val_accuracy: 0.9716\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9955 - val_loss: 0.1336 - val_accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0388 - accuracy: 0.9961 - val_loss: 0.1334 - val_accuracy: 0.9724\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0377 - accuracy: 0.9958 - val_loss: 0.1340 - val_accuracy: 0.9724\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0374 - accuracy: 0.9961 - val_loss: 0.1325 - val_accuracy: 0.9732\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9964 - val_loss: 0.1321 - val_accuracy: 0.9720\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0352 - accuracy: 0.9961 - val_loss: 0.1322 - val_accuracy: 0.9722\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0344 - accuracy: 0.9964 - val_loss: 0.1317 - val_accuracy: 0.9726\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0335 - accuracy: 0.9964 - val_loss: 0.1323 - val_accuracy: 0.9716\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0324 - accuracy: 0.9973 - val_loss: 0.1334 - val_accuracy: 0.9714\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9976 - val_loss: 0.1318 - val_accuracy: 0.9730\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0311 - accuracy: 0.9979 - val_loss: 0.1320 - val_accuracy: 0.9734\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0299 - accuracy: 0.9976 - val_loss: 0.1311 - val_accuracy: 0.9728\n",
      "84/84 [==============================] - 1s 5ms/step - loss: 0.3373 - accuracy: 0.9214\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 9ms/step - loss: 2.1256 - accuracy: 0.2658 - val_loss: 1.8633 - val_accuracy: 0.4824\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.6591 - accuracy: 0.6085 - val_loss: 1.5056 - val_accuracy: 0.6720\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.3612 - accuracy: 0.7294 - val_loss: 1.2709 - val_accuracy: 0.7592\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.1633 - accuracy: 0.7846 - val_loss: 1.1125 - val_accuracy: 0.7828\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.0259 - accuracy: 0.8119 - val_loss: 0.9993 - val_accuracy: 0.8052\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.9265 - accuracy: 0.8317 - val_loss: 0.9150 - val_accuracy: 0.8216\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.8514 - accuracy: 0.8422 - val_loss: 0.8507 - val_accuracy: 0.8288\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7925 - accuracy: 0.8530 - val_loss: 0.7990 - val_accuracy: 0.8388\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7447 - accuracy: 0.8578 - val_loss: 0.7575 - val_accuracy: 0.8448\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.7053 - accuracy: 0.8665 - val_loss: 0.7224 - val_accuracy: 0.8506\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6725 - accuracy: 0.8650 - val_loss: 0.6932 - val_accuracy: 0.8526\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.8713 - val_loss: 0.6681 - val_accuracy: 0.8556\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6202 - accuracy: 0.8755 - val_loss: 0.6457 - val_accuracy: 0.8580\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5990 - accuracy: 0.8779 - val_loss: 0.6265 - val_accuracy: 0.8612\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5801 - accuracy: 0.8809 - val_loss: 0.6094 - val_accuracy: 0.8642\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5633 - accuracy: 0.8842 - val_loss: 0.5940 - val_accuracy: 0.8672\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5483 - accuracy: 0.8860 - val_loss: 0.5801 - val_accuracy: 0.8682\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.8884 - val_loss: 0.5676 - val_accuracy: 0.8698\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5222 - accuracy: 0.8890 - val_loss: 0.5562 - val_accuracy: 0.8712\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5109 - accuracy: 0.8911 - val_loss: 0.5457 - val_accuracy: 0.8738\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5003 - accuracy: 0.8920 - val_loss: 0.5359 - val_accuracy: 0.8754\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4905 - accuracy: 0.8944 - val_loss: 0.5273 - val_accuracy: 0.8748\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4816 - accuracy: 0.8932 - val_loss: 0.5189 - val_accuracy: 0.8770\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.4735 - accuracy: 0.8941 - val_loss: 0.5111 - val_accuracy: 0.8782\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4656 - accuracy: 0.8950 - val_loss: 0.5041 - val_accuracy: 0.8788\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 2s 16ms/step - loss: 0.4583 - accuracy: 0.8977 - val_loss: 0.4980 - val_accuracy: 0.8804\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4515 - accuracy: 0.8971 - val_loss: 0.4914 - val_accuracy: 0.8810\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4449 - accuracy: 0.8989 - val_loss: 0.4855 - val_accuracy: 0.8810\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4389 - accuracy: 0.8977 - val_loss: 0.4794 - val_accuracy: 0.8834\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4331 - accuracy: 0.9007 - val_loss: 0.4743 - val_accuracy: 0.8832\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.9019 - val_loss: 0.4690 - val_accuracy: 0.8860\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.9028 - val_loss: 0.4645 - val_accuracy: 0.8844\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4175 - accuracy: 0.9025 - val_loss: 0.4600 - val_accuracy: 0.8860\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4128 - accuracy: 0.9037 - val_loss: 0.4558 - val_accuracy: 0.8864\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4083 - accuracy: 0.9055 - val_loss: 0.4513 - val_accuracy: 0.8886\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4040 - accuracy: 0.9058 - val_loss: 0.4474 - val_accuracy: 0.8888\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 2s 19ms/step - loss: 0.3999 - accuracy: 0.9067 - val_loss: 0.4434 - val_accuracy: 0.8894\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3960 - accuracy: 0.9070 - val_loss: 0.4401 - val_accuracy: 0.8894\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3923 - accuracy: 0.9070 - val_loss: 0.4368 - val_accuracy: 0.8892\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3886 - accuracy: 0.9064 - val_loss: 0.4336 - val_accuracy: 0.8894\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3851 - accuracy: 0.9079 - val_loss: 0.4298 - val_accuracy: 0.8912\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.9085 - val_loss: 0.4267 - val_accuracy: 0.8922\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3784 - accuracy: 0.9094 - val_loss: 0.4240 - val_accuracy: 0.8924\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.9100 - val_loss: 0.4209 - val_accuracy: 0.8930\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.9097 - val_loss: 0.4183 - val_accuracy: 0.8930\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3694 - accuracy: 0.9100 - val_loss: 0.4157 - val_accuracy: 0.8940\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3666 - accuracy: 0.9130 - val_loss: 0.4130 - val_accuracy: 0.8942\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3637 - accuracy: 0.9118 - val_loss: 0.4106 - val_accuracy: 0.8944\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3611 - accuracy: 0.9115 - val_loss: 0.4080 - val_accuracy: 0.8956\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.3586 - accuracy: 0.9139 - val_loss: 0.4058 - val_accuracy: 0.8968\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.3560 - accuracy: 0.9145 - val_loss: 0.4033 - val_accuracy: 0.8968\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 2s 17ms/step - loss: 0.3536 - accuracy: 0.9151 - val_loss: 0.4010 - val_accuracy: 0.8970\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 2s 19ms/step - loss: 0.3513 - accuracy: 0.9151 - val_loss: 0.3992 - val_accuracy: 0.8974\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3490 - accuracy: 0.9166 - val_loss: 0.3970 - val_accuracy: 0.8988\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3468 - accuracy: 0.9166 - val_loss: 0.3948 - val_accuracy: 0.8986\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3445 - accuracy: 0.9175 - val_loss: 0.3930 - val_accuracy: 0.8984\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3424 - accuracy: 0.9169 - val_loss: 0.3911 - val_accuracy: 0.8996\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3404 - accuracy: 0.9166 - val_loss: 0.3891 - val_accuracy: 0.8998\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3383 - accuracy: 0.9178 - val_loss: 0.3873 - val_accuracy: 0.9008\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3363 - accuracy: 0.9187 - val_loss: 0.3856 - val_accuracy: 0.9010\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3344 - accuracy: 0.9193 - val_loss: 0.3840 - val_accuracy: 0.9006\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3326 - accuracy: 0.9178 - val_loss: 0.3822 - val_accuracy: 0.9012\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3307 - accuracy: 0.9190 - val_loss: 0.3804 - val_accuracy: 0.9014\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3290 - accuracy: 0.9199 - val_loss: 0.3789 - val_accuracy: 0.9014\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3272 - accuracy: 0.9193 - val_loss: 0.3776 - val_accuracy: 0.9024\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3255 - accuracy: 0.9205 - val_loss: 0.3768 - val_accuracy: 0.9022\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3239 - accuracy: 0.9202 - val_loss: 0.3746 - val_accuracy: 0.9030\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3222 - accuracy: 0.9205 - val_loss: 0.3729 - val_accuracy: 0.9036\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3206 - accuracy: 0.9217 - val_loss: 0.3716 - val_accuracy: 0.9038\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3190 - accuracy: 0.9220 - val_loss: 0.3704 - val_accuracy: 0.9048\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3175 - accuracy: 0.9226 - val_loss: 0.3690 - val_accuracy: 0.9050\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3160 - accuracy: 0.9232 - val_loss: 0.3676 - val_accuracy: 0.9050\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3145 - accuracy: 0.9229 - val_loss: 0.3662 - val_accuracy: 0.9050\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3130 - accuracy: 0.9235 - val_loss: 0.3650 - val_accuracy: 0.9054\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3116 - accuracy: 0.9226 - val_loss: 0.3635 - val_accuracy: 0.9064\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3102 - accuracy: 0.9238 - val_loss: 0.3624 - val_accuracy: 0.9056\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3089 - accuracy: 0.9226 - val_loss: 0.3614 - val_accuracy: 0.9062\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3076 - accuracy: 0.9247 - val_loss: 0.3601 - val_accuracy: 0.9062\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3062 - accuracy: 0.9244 - val_loss: 0.3585 - val_accuracy: 0.9082\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3050 - accuracy: 0.9256 - val_loss: 0.3576 - val_accuracy: 0.9066\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3035 - accuracy: 0.9250 - val_loss: 0.3566 - val_accuracy: 0.9066\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3024 - accuracy: 0.9253 - val_loss: 0.3555 - val_accuracy: 0.9068\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.9253 - val_loss: 0.3543 - val_accuracy: 0.9074\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2999 - accuracy: 0.9259 - val_loss: 0.3533 - val_accuracy: 0.9078\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2988 - accuracy: 0.9247 - val_loss: 0.3523 - val_accuracy: 0.9080\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.9259 - val_loss: 0.3511 - val_accuracy: 0.9076\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2964 - accuracy: 0.9259 - val_loss: 0.3503 - val_accuracy: 0.9080\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2953 - accuracy: 0.9256 - val_loss: 0.3492 - val_accuracy: 0.9084\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2942 - accuracy: 0.9250 - val_loss: 0.3482 - val_accuracy: 0.9086\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2931 - accuracy: 0.9256 - val_loss: 0.3474 - val_accuracy: 0.9090\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2920 - accuracy: 0.9277 - val_loss: 0.3465 - val_accuracy: 0.9090\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.9262 - val_loss: 0.3455 - val_accuracy: 0.9098\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2898 - accuracy: 0.9280 - val_loss: 0.3447 - val_accuracy: 0.9090\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2888 - accuracy: 0.9280 - val_loss: 0.3439 - val_accuracy: 0.9098\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2878 - accuracy: 0.9283 - val_loss: 0.3430 - val_accuracy: 0.9098\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2867 - accuracy: 0.9268 - val_loss: 0.3424 - val_accuracy: 0.9100\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2858 - accuracy: 0.9286 - val_loss: 0.3414 - val_accuracy: 0.9102\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2848 - accuracy: 0.9295 - val_loss: 0.3405 - val_accuracy: 0.9104\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2838 - accuracy: 0.9301 - val_loss: 0.3399 - val_accuracy: 0.9094\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2830 - accuracy: 0.9280 - val_loss: 0.3390 - val_accuracy: 0.9110\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8728\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 10ms/step - loss: 2.0697 - accuracy: 0.3102 - val_loss: 1.8124 - val_accuracy: 0.5254\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.6460 - accuracy: 0.6118 - val_loss: 1.4757 - val_accuracy: 0.6846\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3722 - accuracy: 0.7213 - val_loss: 1.2552 - val_accuracy: 0.7578\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1887 - accuracy: 0.7660 - val_loss: 1.1057 - val_accuracy: 0.7848\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 1.0609 - accuracy: 0.7876 - val_loss: 0.9964 - val_accuracy: 0.8050\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.9664 - accuracy: 0.8029 - val_loss: 0.9157 - val_accuracy: 0.8158\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8939 - accuracy: 0.8179 - val_loss: 0.8522 - val_accuracy: 0.8246\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.8368 - accuracy: 0.8278 - val_loss: 0.8012 - val_accuracy: 0.8306\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7907 - accuracy: 0.8326 - val_loss: 0.7596 - val_accuracy: 0.8358\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7520 - accuracy: 0.8371 - val_loss: 0.7248 - val_accuracy: 0.8402\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7196 - accuracy: 0.8398 - val_loss: 0.6954 - val_accuracy: 0.8468\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.6920 - accuracy: 0.8467 - val_loss: 0.6700 - val_accuracy: 0.8494\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6680 - accuracy: 0.8530 - val_loss: 0.6474 - val_accuracy: 0.8532\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6467 - accuracy: 0.8548 - val_loss: 0.6278 - val_accuracy: 0.8558\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6278 - accuracy: 0.8581 - val_loss: 0.6104 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6111 - accuracy: 0.8617 - val_loss: 0.5947 - val_accuracy: 0.8610\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5959 - accuracy: 0.8671 - val_loss: 0.5808 - val_accuracy: 0.8638\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5821 - accuracy: 0.8662 - val_loss: 0.5678 - val_accuracy: 0.8668\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5695 - accuracy: 0.8686 - val_loss: 0.5559 - val_accuracy: 0.8712\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.8728 - val_loss: 0.5455 - val_accuracy: 0.8716\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.8728 - val_loss: 0.5356 - val_accuracy: 0.8718\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5376 - accuracy: 0.8743 - val_loss: 0.5261 - val_accuracy: 0.8740\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.8758 - val_loss: 0.5176 - val_accuracy: 0.8760\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5200 - accuracy: 0.8785 - val_loss: 0.5099 - val_accuracy: 0.8782\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5121 - accuracy: 0.8794 - val_loss: 0.5021 - val_accuracy: 0.8804\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5045 - accuracy: 0.8812 - val_loss: 0.4953 - val_accuracy: 0.8818\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4975 - accuracy: 0.8827 - val_loss: 0.4887 - val_accuracy: 0.8828\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.8851 - val_loss: 0.4824 - val_accuracy: 0.8848\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4847 - accuracy: 0.8866 - val_loss: 0.4764 - val_accuracy: 0.8864\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.8884 - val_loss: 0.4711 - val_accuracy: 0.8868\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.8890 - val_loss: 0.4659 - val_accuracy: 0.8880\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.8902 - val_loss: 0.4608 - val_accuracy: 0.8884\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4627 - accuracy: 0.8932 - val_loss: 0.4560 - val_accuracy: 0.8906\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4579 - accuracy: 0.8926 - val_loss: 0.4515 - val_accuracy: 0.8908\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.8935 - val_loss: 0.4473 - val_accuracy: 0.8920\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.8941 - val_loss: 0.4435 - val_accuracy: 0.8928\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4447 - accuracy: 0.8956 - val_loss: 0.4393 - val_accuracy: 0.8932\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.8959 - val_loss: 0.4355 - val_accuracy: 0.8944\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4368 - accuracy: 0.8968 - val_loss: 0.4322 - val_accuracy: 0.8954\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8986 - val_loss: 0.4287 - val_accuracy: 0.8972\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4295 - accuracy: 0.8986 - val_loss: 0.4251 - val_accuracy: 0.8970\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4260 - accuracy: 0.9007 - val_loss: 0.4219 - val_accuracy: 0.8972\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.9007 - val_loss: 0.4188 - val_accuracy: 0.8976\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.9010 - val_loss: 0.4158 - val_accuracy: 0.8980\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.9007 - val_loss: 0.4130 - val_accuracy: 0.8992\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4131 - accuracy: 0.9034 - val_loss: 0.4103 - val_accuracy: 0.8984\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.9025 - val_loss: 0.4073 - val_accuracy: 0.8998\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4074 - accuracy: 0.9025 - val_loss: 0.4048 - val_accuracy: 0.9006\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.9040 - val_loss: 0.4026 - val_accuracy: 0.8996\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4020 - accuracy: 0.9046 - val_loss: 0.4000 - val_accuracy: 0.9014\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3995 - accuracy: 0.9043 - val_loss: 0.3976 - val_accuracy: 0.9012\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3970 - accuracy: 0.9049 - val_loss: 0.3953 - val_accuracy: 0.9016\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3945 - accuracy: 0.9061 - val_loss: 0.3931 - val_accuracy: 0.9016\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3921 - accuracy: 0.9064 - val_loss: 0.3909 - val_accuracy: 0.9032\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3898 - accuracy: 0.9052 - val_loss: 0.3887 - val_accuracy: 0.9036\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.9073 - val_loss: 0.3869 - val_accuracy: 0.9044\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3854 - accuracy: 0.9064 - val_loss: 0.3848 - val_accuracy: 0.9036\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3833 - accuracy: 0.9070 - val_loss: 0.3827 - val_accuracy: 0.9040\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3812 - accuracy: 0.9073 - val_loss: 0.3809 - val_accuracy: 0.9048\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3791 - accuracy: 0.9070 - val_loss: 0.3790 - val_accuracy: 0.9048\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3772 - accuracy: 0.9076 - val_loss: 0.3772 - val_accuracy: 0.9050\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3752 - accuracy: 0.9082 - val_loss: 0.3756 - val_accuracy: 0.9056\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.9082 - val_loss: 0.3740 - val_accuracy: 0.9054\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3714 - accuracy: 0.9085 - val_loss: 0.3721 - val_accuracy: 0.9062\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3696 - accuracy: 0.9085 - val_loss: 0.3706 - val_accuracy: 0.9060\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3679 - accuracy: 0.9085 - val_loss: 0.3690 - val_accuracy: 0.9064\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3662 - accuracy: 0.9094 - val_loss: 0.3674 - val_accuracy: 0.9070\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3645 - accuracy: 0.9085 - val_loss: 0.3659 - val_accuracy: 0.9072\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3628 - accuracy: 0.9106 - val_loss: 0.3645 - val_accuracy: 0.9078\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3612 - accuracy: 0.9109 - val_loss: 0.3630 - val_accuracy: 0.9072\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 3s 24ms/step - loss: 0.3596 - accuracy: 0.9106 - val_loss: 0.3616 - val_accuracy: 0.9080\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.3580 - accuracy: 0.9106 - val_loss: 0.3602 - val_accuracy: 0.9084\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3565 - accuracy: 0.9115 - val_loss: 0.3589 - val_accuracy: 0.9086\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3550 - accuracy: 0.9112 - val_loss: 0.3576 - val_accuracy: 0.9080\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3536 - accuracy: 0.9109 - val_loss: 0.3563 - val_accuracy: 0.9100\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3521 - accuracy: 0.9124 - val_loss: 0.3550 - val_accuracy: 0.9098\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3507 - accuracy: 0.9127 - val_loss: 0.3537 - val_accuracy: 0.9092\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3493 - accuracy: 0.9130 - val_loss: 0.3525 - val_accuracy: 0.9096\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3479 - accuracy: 0.9130 - val_loss: 0.3513 - val_accuracy: 0.9096\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3466 - accuracy: 0.9127 - val_loss: 0.3502 - val_accuracy: 0.9098\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3452 - accuracy: 0.9142 - val_loss: 0.3489 - val_accuracy: 0.9110\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3439 - accuracy: 0.9130 - val_loss: 0.3480 - val_accuracy: 0.9106\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3427 - accuracy: 0.9139 - val_loss: 0.3467 - val_accuracy: 0.9108\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3414 - accuracy: 0.9148 - val_loss: 0.3456 - val_accuracy: 0.9110\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3402 - accuracy: 0.9139 - val_loss: 0.3446 - val_accuracy: 0.9116\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3389 - accuracy: 0.9142 - val_loss: 0.3435 - val_accuracy: 0.9118\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3377 - accuracy: 0.9148 - val_loss: 0.3424 - val_accuracy: 0.9132\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3366 - accuracy: 0.9157 - val_loss: 0.3414 - val_accuracy: 0.9124\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.9154 - val_loss: 0.3403 - val_accuracy: 0.9124\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3343 - accuracy: 0.9151 - val_loss: 0.3394 - val_accuracy: 0.9128\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3332 - accuracy: 0.9175 - val_loss: 0.3385 - val_accuracy: 0.9126\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.3321 - accuracy: 0.9157 - val_loss: 0.3376 - val_accuracy: 0.9132\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3310 - accuracy: 0.9160 - val_loss: 0.3368 - val_accuracy: 0.9132\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3300 - accuracy: 0.9172 - val_loss: 0.3357 - val_accuracy: 0.9136\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3289 - accuracy: 0.9169 - val_loss: 0.3350 - val_accuracy: 0.9138\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.9163 - val_loss: 0.3338 - val_accuracy: 0.9148\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3269 - accuracy: 0.9172 - val_loss: 0.3330 - val_accuracy: 0.9148\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.9190 - val_loss: 0.3322 - val_accuracy: 0.9142\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3248 - accuracy: 0.9175 - val_loss: 0.3313 - val_accuracy: 0.9148\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3237 - accuracy: 0.9184 - val_loss: 0.3304 - val_accuracy: 0.9152\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.9076\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 2.1248 - accuracy: 0.2867 - val_loss: 1.8538 - val_accuracy: 0.4886\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.6695 - accuracy: 0.6032 - val_loss: 1.4999 - val_accuracy: 0.6736\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3790 - accuracy: 0.7244 - val_loss: 1.2711 - val_accuracy: 0.7402\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.1875 - accuracy: 0.7666 - val_loss: 1.1167 - val_accuracy: 0.7810\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 1.0544 - accuracy: 0.7966 - val_loss: 1.0061 - val_accuracy: 0.8008\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.9573 - accuracy: 0.8140 - val_loss: 0.9232 - val_accuracy: 0.8174\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.8837 - accuracy: 0.8266 - val_loss: 0.8596 - val_accuracy: 0.8246\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.8260 - accuracy: 0.8341 - val_loss: 0.8086 - val_accuracy: 0.8336\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7792 - accuracy: 0.8398 - val_loss: 0.7668 - val_accuracy: 0.8384\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.7410 - accuracy: 0.8449 - val_loss: 0.7332 - val_accuracy: 0.8470\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7086 - accuracy: 0.8506 - val_loss: 0.7035 - val_accuracy: 0.8476\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6808 - accuracy: 0.8545 - val_loss: 0.6777 - val_accuracy: 0.8514\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6567 - accuracy: 0.8563 - val_loss: 0.6556 - val_accuracy: 0.8532\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6360 - accuracy: 0.8581 - val_loss: 0.6361 - val_accuracy: 0.8562\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.8617 - val_loss: 0.6187 - val_accuracy: 0.8574\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.6005 - accuracy: 0.8629 - val_loss: 0.6034 - val_accuracy: 0.8606\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5856 - accuracy: 0.8644 - val_loss: 0.5892 - val_accuracy: 0.8624\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5721 - accuracy: 0.8683 - val_loss: 0.5765 - val_accuracy: 0.8632\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5597 - accuracy: 0.8683 - val_loss: 0.5654 - val_accuracy: 0.8662\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.8707 - val_loss: 0.5546 - val_accuracy: 0.8678\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.8725 - val_loss: 0.5449 - val_accuracy: 0.8696\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5285 - accuracy: 0.8737 - val_loss: 0.5356 - val_accuracy: 0.8722\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.8746 - val_loss: 0.5271 - val_accuracy: 0.8726\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5114 - accuracy: 0.8761 - val_loss: 0.5192 - val_accuracy: 0.8754\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5035 - accuracy: 0.8779 - val_loss: 0.5120 - val_accuracy: 0.8760\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4962 - accuracy: 0.8797 - val_loss: 0.5052 - val_accuracy: 0.8762\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.8794 - val_loss: 0.4993 - val_accuracy: 0.8784\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4832 - accuracy: 0.8830 - val_loss: 0.4927 - val_accuracy: 0.8790\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4770 - accuracy: 0.8824 - val_loss: 0.4869 - val_accuracy: 0.8796\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.8839 - val_loss: 0.4812 - val_accuracy: 0.8812\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.8863 - val_loss: 0.4763 - val_accuracy: 0.8816\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.8875 - val_loss: 0.4712 - val_accuracy: 0.8824\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4557 - accuracy: 0.8875 - val_loss: 0.4667 - val_accuracy: 0.8834\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4510 - accuracy: 0.8875 - val_loss: 0.4622 - val_accuracy: 0.8840\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4466 - accuracy: 0.8881 - val_loss: 0.4583 - val_accuracy: 0.8856\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4423 - accuracy: 0.8908 - val_loss: 0.4540 - val_accuracy: 0.8866\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4382 - accuracy: 0.8902 - val_loss: 0.4503 - val_accuracy: 0.8868\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4343 - accuracy: 0.8923 - val_loss: 0.4462 - val_accuracy: 0.8886\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4304 - accuracy: 0.8923 - val_loss: 0.4423 - val_accuracy: 0.8898\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8941 - val_loss: 0.4390 - val_accuracy: 0.8910\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8947 - val_loss: 0.4355 - val_accuracy: 0.8922\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4198 - accuracy: 0.8986 - val_loss: 0.4325 - val_accuracy: 0.8918\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8962 - val_loss: 0.4294 - val_accuracy: 0.8928\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8992 - val_loss: 0.4265 - val_accuracy: 0.8928\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8986 - val_loss: 0.4235 - val_accuracy: 0.8944\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8989 - val_loss: 0.4207 - val_accuracy: 0.8952\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.9019 - val_loss: 0.4180 - val_accuracy: 0.8948\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4019 - accuracy: 0.9013 - val_loss: 0.4155 - val_accuracy: 0.8956\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.9016 - val_loss: 0.4131 - val_accuracy: 0.8954\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3966 - accuracy: 0.9013 - val_loss: 0.4107 - val_accuracy: 0.8966\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3941 - accuracy: 0.9025 - val_loss: 0.4083 - val_accuracy: 0.8964\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3917 - accuracy: 0.9025 - val_loss: 0.4057 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3893 - accuracy: 0.9037 - val_loss: 0.4036 - val_accuracy: 0.8968\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3869 - accuracy: 0.9031 - val_loss: 0.4014 - val_accuracy: 0.8974\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3847 - accuracy: 0.9034 - val_loss: 0.3994 - val_accuracy: 0.8976\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3825 - accuracy: 0.9040 - val_loss: 0.3973 - val_accuracy: 0.8974\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3803 - accuracy: 0.9043 - val_loss: 0.3953 - val_accuracy: 0.8978\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3782 - accuracy: 0.9052 - val_loss: 0.3934 - val_accuracy: 0.8982\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3763 - accuracy: 0.9040 - val_loss: 0.3914 - val_accuracy: 0.8988\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3743 - accuracy: 0.9049 - val_loss: 0.3896 - val_accuracy: 0.8994\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3723 - accuracy: 0.9055 - val_loss: 0.3877 - val_accuracy: 0.8998\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3704 - accuracy: 0.9055 - val_loss: 0.3860 - val_accuracy: 0.8996\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3685 - accuracy: 0.9061 - val_loss: 0.3843 - val_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3667 - accuracy: 0.9064 - val_loss: 0.3824 - val_accuracy: 0.9002\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3650 - accuracy: 0.9076 - val_loss: 0.3809 - val_accuracy: 0.9010\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3632 - accuracy: 0.9073 - val_loss: 0.3794 - val_accuracy: 0.9004\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3616 - accuracy: 0.9076 - val_loss: 0.3777 - val_accuracy: 0.9012\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3599 - accuracy: 0.9091 - val_loss: 0.3762 - val_accuracy: 0.9014\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3582 - accuracy: 0.9082 - val_loss: 0.3747 - val_accuracy: 0.9016\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3566 - accuracy: 0.9094 - val_loss: 0.3732 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3551 - accuracy: 0.9091 - val_loss: 0.3719 - val_accuracy: 0.9020\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3536 - accuracy: 0.9085 - val_loss: 0.3704 - val_accuracy: 0.9022\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3520 - accuracy: 0.9088 - val_loss: 0.3690 - val_accuracy: 0.9014\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3506 - accuracy: 0.9109 - val_loss: 0.3676 - val_accuracy: 0.9024\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3491 - accuracy: 0.9103 - val_loss: 0.3661 - val_accuracy: 0.9030\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3477 - accuracy: 0.9109 - val_loss: 0.3649 - val_accuracy: 0.9032\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3463 - accuracy: 0.9112 - val_loss: 0.3636 - val_accuracy: 0.9032\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3450 - accuracy: 0.9118 - val_loss: 0.3624 - val_accuracy: 0.9040\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3436 - accuracy: 0.9124 - val_loss: 0.3612 - val_accuracy: 0.9046\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3423 - accuracy: 0.9121 - val_loss: 0.3601 - val_accuracy: 0.9046\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3409 - accuracy: 0.9130 - val_loss: 0.3588 - val_accuracy: 0.9046\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3397 - accuracy: 0.9139 - val_loss: 0.3576 - val_accuracy: 0.9048\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3384 - accuracy: 0.9124 - val_loss: 0.3566 - val_accuracy: 0.9052\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.9133 - val_loss: 0.3553 - val_accuracy: 0.9050\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3360 - accuracy: 0.9139 - val_loss: 0.3542 - val_accuracy: 0.9054\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.9133 - val_loss: 0.3531 - val_accuracy: 0.9058\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3336 - accuracy: 0.9136 - val_loss: 0.3521 - val_accuracy: 0.9066\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3324 - accuracy: 0.9142 - val_loss: 0.3510 - val_accuracy: 0.9082\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.9157 - val_loss: 0.3499 - val_accuracy: 0.9082\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3301 - accuracy: 0.9157 - val_loss: 0.3490 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3290 - accuracy: 0.9166 - val_loss: 0.3480 - val_accuracy: 0.9080\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3279 - accuracy: 0.9160 - val_loss: 0.3469 - val_accuracy: 0.9082\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3268 - accuracy: 0.9175 - val_loss: 0.3462 - val_accuracy: 0.9086\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3257 - accuracy: 0.9166 - val_loss: 0.3451 - val_accuracy: 0.9082\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3247 - accuracy: 0.9163 - val_loss: 0.3440 - val_accuracy: 0.9096\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3238 - accuracy: 0.9160 - val_loss: 0.3431 - val_accuracy: 0.9094\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3226 - accuracy: 0.9172 - val_loss: 0.3424 - val_accuracy: 0.9094\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3217 - accuracy: 0.9187 - val_loss: 0.3413 - val_accuracy: 0.9104\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.9187 - val_loss: 0.3404 - val_accuracy: 0.9106\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3197 - accuracy: 0.9187 - val_loss: 0.3397 - val_accuracy: 0.9102\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8926\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 10ms/step - loss: 2.0311 - accuracy: 0.3480 - val_loss: 1.7455 - val_accuracy: 0.5838\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.5426 - accuracy: 0.6799 - val_loss: 1.3930 - val_accuracy: 0.7300\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.2575 - accuracy: 0.7615 - val_loss: 1.1742 - val_accuracy: 0.7830\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.0750 - accuracy: 0.8095 - val_loss: 1.0308 - val_accuracy: 0.8004\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.9515 - accuracy: 0.8242 - val_loss: 0.9295 - val_accuracy: 0.8194\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8629 - accuracy: 0.8401 - val_loss: 0.8543 - val_accuracy: 0.8376\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7945 - accuracy: 0.8533 - val_loss: 0.7965 - val_accuracy: 0.8420\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7423 - accuracy: 0.8584 - val_loss: 0.7508 - val_accuracy: 0.8474\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.8665 - val_loss: 0.7134 - val_accuracy: 0.8534\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6641 - accuracy: 0.8692 - val_loss: 0.6826 - val_accuracy: 0.8548\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6348 - accuracy: 0.8740 - val_loss: 0.6555 - val_accuracy: 0.8594\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6092 - accuracy: 0.8761 - val_loss: 0.6325 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5871 - accuracy: 0.8788 - val_loss: 0.6126 - val_accuracy: 0.8658\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5678 - accuracy: 0.8815 - val_loss: 0.5952 - val_accuracy: 0.8676\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5508 - accuracy: 0.8824 - val_loss: 0.5797 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5356 - accuracy: 0.8848 - val_loss: 0.5660 - val_accuracy: 0.8698\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.8860 - val_loss: 0.5531 - val_accuracy: 0.8714\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.8881 - val_loss: 0.5417 - val_accuracy: 0.8734\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4979 - accuracy: 0.8920 - val_loss: 0.5313 - val_accuracy: 0.8756\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4873 - accuracy: 0.8926 - val_loss: 0.5231 - val_accuracy: 0.8766\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4779 - accuracy: 0.8944 - val_loss: 0.5135 - val_accuracy: 0.8782\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4689 - accuracy: 0.8971 - val_loss: 0.5052 - val_accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4608 - accuracy: 0.8986 - val_loss: 0.4974 - val_accuracy: 0.8818\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4529 - accuracy: 0.8989 - val_loss: 0.4905 - val_accuracy: 0.8840\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4459 - accuracy: 0.9007 - val_loss: 0.4839 - val_accuracy: 0.8856\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.9013 - val_loss: 0.4772 - val_accuracy: 0.8882\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4329 - accuracy: 0.9046 - val_loss: 0.4716 - val_accuracy: 0.8878\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.9034 - val_loss: 0.4662 - val_accuracy: 0.8890\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.9058 - val_loss: 0.4611 - val_accuracy: 0.8890\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.9046 - val_loss: 0.4569 - val_accuracy: 0.8894\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4108 - accuracy: 0.9067 - val_loss: 0.4519 - val_accuracy: 0.8912\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.9076 - val_loss: 0.4478 - val_accuracy: 0.8914\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.9073 - val_loss: 0.4432 - val_accuracy: 0.8928\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3969 - accuracy: 0.9085 - val_loss: 0.4391 - val_accuracy: 0.8938\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3928 - accuracy: 0.9094 - val_loss: 0.4353 - val_accuracy: 0.8942\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3888 - accuracy: 0.9103 - val_loss: 0.4320 - val_accuracy: 0.8952\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3849 - accuracy: 0.9115 - val_loss: 0.4285 - val_accuracy: 0.8954\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3812 - accuracy: 0.9106 - val_loss: 0.4248 - val_accuracy: 0.8948\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3777 - accuracy: 0.9106 - val_loss: 0.4216 - val_accuracy: 0.8964\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3744 - accuracy: 0.9118 - val_loss: 0.4184 - val_accuracy: 0.8962\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3710 - accuracy: 0.9130 - val_loss: 0.4157 - val_accuracy: 0.8972\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3679 - accuracy: 0.9136 - val_loss: 0.4125 - val_accuracy: 0.8982\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3649 - accuracy: 0.9136 - val_loss: 0.4102 - val_accuracy: 0.8994\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3619 - accuracy: 0.9151 - val_loss: 0.4075 - val_accuracy: 0.9002\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3590 - accuracy: 0.9154 - val_loss: 0.4048 - val_accuracy: 0.8996\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3563 - accuracy: 0.9151 - val_loss: 0.4024 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3537 - accuracy: 0.9169 - val_loss: 0.3998 - val_accuracy: 0.9008\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.9166 - val_loss: 0.3977 - val_accuracy: 0.9014\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3486 - accuracy: 0.9178 - val_loss: 0.3954 - val_accuracy: 0.9008\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3461 - accuracy: 0.9184 - val_loss: 0.3934 - val_accuracy: 0.9018\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.9184 - val_loss: 0.3910 - val_accuracy: 0.9020\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3415 - accuracy: 0.9178 - val_loss: 0.3889 - val_accuracy: 0.9026\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3393 - accuracy: 0.9187 - val_loss: 0.3873 - val_accuracy: 0.9022\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.9196 - val_loss: 0.3852 - val_accuracy: 0.9028\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3350 - accuracy: 0.9199 - val_loss: 0.3832 - val_accuracy: 0.9036\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.9199 - val_loss: 0.3814 - val_accuracy: 0.9046\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3310 - accuracy: 0.9187 - val_loss: 0.3793 - val_accuracy: 0.9032\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3290 - accuracy: 0.9199 - val_loss: 0.3778 - val_accuracy: 0.9044\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3271 - accuracy: 0.9211 - val_loss: 0.3763 - val_accuracy: 0.9048\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3252 - accuracy: 0.9208 - val_loss: 0.3744 - val_accuracy: 0.9048\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3235 - accuracy: 0.9214 - val_loss: 0.3725 - val_accuracy: 0.9052\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3218 - accuracy: 0.9223 - val_loss: 0.3708 - val_accuracy: 0.9042\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3200 - accuracy: 0.9211 - val_loss: 0.3697 - val_accuracy: 0.9056\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3183 - accuracy: 0.9223 - val_loss: 0.3684 - val_accuracy: 0.9056\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3166 - accuracy: 0.9223 - val_loss: 0.3665 - val_accuracy: 0.9060\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3151 - accuracy: 0.9226 - val_loss: 0.3652 - val_accuracy: 0.9056\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.3134 - accuracy: 0.9232 - val_loss: 0.3639 - val_accuracy: 0.9066\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3119 - accuracy: 0.9232 - val_loss: 0.3626 - val_accuracy: 0.9060\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3103 - accuracy: 0.9247 - val_loss: 0.3615 - val_accuracy: 0.9058\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3088 - accuracy: 0.9232 - val_loss: 0.3601 - val_accuracy: 0.9064\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3073 - accuracy: 0.9238 - val_loss: 0.3586 - val_accuracy: 0.9068\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3059 - accuracy: 0.9244 - val_loss: 0.3573 - val_accuracy: 0.9072\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3044 - accuracy: 0.9247 - val_loss: 0.3562 - val_accuracy: 0.9070\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.9250 - val_loss: 0.3551 - val_accuracy: 0.9068\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3017 - accuracy: 0.9259 - val_loss: 0.3536 - val_accuracy: 0.9084\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3005 - accuracy: 0.9265 - val_loss: 0.3527 - val_accuracy: 0.9084\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2991 - accuracy: 0.9247 - val_loss: 0.3515 - val_accuracy: 0.9090\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2978 - accuracy: 0.9268 - val_loss: 0.3505 - val_accuracy: 0.9088\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2966 - accuracy: 0.9250 - val_loss: 0.3495 - val_accuracy: 0.9102\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2954 - accuracy: 0.9271 - val_loss: 0.3484 - val_accuracy: 0.9098\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2941 - accuracy: 0.9274 - val_loss: 0.3472 - val_accuracy: 0.9108\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2929 - accuracy: 0.9271 - val_loss: 0.3463 - val_accuracy: 0.9102\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2917 - accuracy: 0.9265 - val_loss: 0.3449 - val_accuracy: 0.9114\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2906 - accuracy: 0.9274 - val_loss: 0.3439 - val_accuracy: 0.9110\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2894 - accuracy: 0.9277 - val_loss: 0.3435 - val_accuracy: 0.9110\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2883 - accuracy: 0.9286 - val_loss: 0.3426 - val_accuracy: 0.9116\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2872 - accuracy: 0.9286 - val_loss: 0.3414 - val_accuracy: 0.9116\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2860 - accuracy: 0.9286 - val_loss: 0.3403 - val_accuracy: 0.9120\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2850 - accuracy: 0.9283 - val_loss: 0.3393 - val_accuracy: 0.9130\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2839 - accuracy: 0.9292 - val_loss: 0.3385 - val_accuracy: 0.9132\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2829 - accuracy: 0.9298 - val_loss: 0.3375 - val_accuracy: 0.9130\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2819 - accuracy: 0.9304 - val_loss: 0.3366 - val_accuracy: 0.9130\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2809 - accuracy: 0.9301 - val_loss: 0.3357 - val_accuracy: 0.9134\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2799 - accuracy: 0.9307 - val_loss: 0.3349 - val_accuracy: 0.9132\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2789 - accuracy: 0.9313 - val_loss: 0.3340 - val_accuracy: 0.9134\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2779 - accuracy: 0.9304 - val_loss: 0.3332 - val_accuracy: 0.9138\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2769 - accuracy: 0.9307 - val_loss: 0.3325 - val_accuracy: 0.9136\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2760 - accuracy: 0.9316 - val_loss: 0.3317 - val_accuracy: 0.9136\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2751 - accuracy: 0.9319 - val_loss: 0.3314 - val_accuracy: 0.9144\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2743 - accuracy: 0.9319 - val_loss: 0.3304 - val_accuracy: 0.9146\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8788\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 2.0992 - accuracy: 0.3126 - val_loss: 1.7980 - val_accuracy: 0.5542\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.6050 - accuracy: 0.6442 - val_loss: 1.4293 - val_accuracy: 0.7032\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3144 - accuracy: 0.7291 - val_loss: 1.1998 - val_accuracy: 0.7588\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.1288 - accuracy: 0.7717 - val_loss: 1.0504 - val_accuracy: 0.7838\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0034 - accuracy: 0.7945 - val_loss: 0.9446 - val_accuracy: 0.7980\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.9130 - accuracy: 0.8056 - val_loss: 0.8678 - val_accuracy: 0.8102\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8450 - accuracy: 0.8152 - val_loss: 0.8083 - val_accuracy: 0.8200\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.7920 - accuracy: 0.8245 - val_loss: 0.7607 - val_accuracy: 0.8282\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7492 - accuracy: 0.8323 - val_loss: 0.7229 - val_accuracy: 0.8354\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7141 - accuracy: 0.8389 - val_loss: 0.6896 - val_accuracy: 0.8420\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6839 - accuracy: 0.8440 - val_loss: 0.6626 - val_accuracy: 0.8462\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6583 - accuracy: 0.8479 - val_loss: 0.6386 - val_accuracy: 0.8512\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6360 - accuracy: 0.8539 - val_loss: 0.6180 - val_accuracy: 0.8550\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6162 - accuracy: 0.8566 - val_loss: 0.5997 - val_accuracy: 0.8600\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5987 - accuracy: 0.8596 - val_loss: 0.5837 - val_accuracy: 0.8642\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5832 - accuracy: 0.8653 - val_loss: 0.5689 - val_accuracy: 0.8680\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.8671 - val_loss: 0.5554 - val_accuracy: 0.8708\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.8725 - val_loss: 0.5435 - val_accuracy: 0.8730\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5445 - accuracy: 0.8749 - val_loss: 0.5330 - val_accuracy: 0.8742\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.8776 - val_loss: 0.5228 - val_accuracy: 0.8774\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5241 - accuracy: 0.8803 - val_loss: 0.5136 - val_accuracy: 0.8786\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5151 - accuracy: 0.8809 - val_loss: 0.5053 - val_accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5064 - accuracy: 0.8830 - val_loss: 0.4976 - val_accuracy: 0.8812\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4987 - accuracy: 0.8839 - val_loss: 0.4899 - val_accuracy: 0.8836\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.8872 - val_loss: 0.4832 - val_accuracy: 0.8846\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4843 - accuracy: 0.8875 - val_loss: 0.4768 - val_accuracy: 0.8852\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4779 - accuracy: 0.8884 - val_loss: 0.4711 - val_accuracy: 0.8850\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.8884 - val_loss: 0.4648 - val_accuracy: 0.8878\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.8899 - val_loss: 0.4595 - val_accuracy: 0.8888\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.8926 - val_loss: 0.4545 - val_accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4553 - accuracy: 0.8944 - val_loss: 0.4495 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4503 - accuracy: 0.8938 - val_loss: 0.4448 - val_accuracy: 0.8914\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4457 - accuracy: 0.8941 - val_loss: 0.4404 - val_accuracy: 0.8918\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4411 - accuracy: 0.8950 - val_loss: 0.4364 - val_accuracy: 0.8922\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4368 - accuracy: 0.8968 - val_loss: 0.4325 - val_accuracy: 0.8926\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4327 - accuracy: 0.8965 - val_loss: 0.4286 - val_accuracy: 0.8934\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.8962 - val_loss: 0.4250 - val_accuracy: 0.8952\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4249 - accuracy: 0.8977 - val_loss: 0.4215 - val_accuracy: 0.8952\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8989 - val_loss: 0.4186 - val_accuracy: 0.8968\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.9001 - val_loss: 0.4149 - val_accuracy: 0.8968\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8995 - val_loss: 0.4118 - val_accuracy: 0.8976\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4113 - accuracy: 0.9007 - val_loss: 0.4088 - val_accuracy: 0.8978\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8989 - val_loss: 0.4061 - val_accuracy: 0.8984\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.9019 - val_loss: 0.4033 - val_accuracy: 0.8992\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.9016 - val_loss: 0.4007 - val_accuracy: 0.9002\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3992 - accuracy: 0.9034 - val_loss: 0.3981 - val_accuracy: 0.9004\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3965 - accuracy: 0.9028 - val_loss: 0.3954 - val_accuracy: 0.8998\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3938 - accuracy: 0.9025 - val_loss: 0.3930 - val_accuracy: 0.9014\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3912 - accuracy: 0.9040 - val_loss: 0.3907 - val_accuracy: 0.9020\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3888 - accuracy: 0.9043 - val_loss: 0.3883 - val_accuracy: 0.9016\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3863 - accuracy: 0.9052 - val_loss: 0.3864 - val_accuracy: 0.9018\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3840 - accuracy: 0.9043 - val_loss: 0.3841 - val_accuracy: 0.9018\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3816 - accuracy: 0.9061 - val_loss: 0.3820 - val_accuracy: 0.9024\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.9052 - val_loss: 0.3799 - val_accuracy: 0.9024\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3772 - accuracy: 0.9061 - val_loss: 0.3781 - val_accuracy: 0.9034\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.9067 - val_loss: 0.3762 - val_accuracy: 0.9040\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3729 - accuracy: 0.9085 - val_loss: 0.3743 - val_accuracy: 0.9046\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3709 - accuracy: 0.9073 - val_loss: 0.3728 - val_accuracy: 0.9050\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3689 - accuracy: 0.9088 - val_loss: 0.3707 - val_accuracy: 0.9058\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3670 - accuracy: 0.9094 - val_loss: 0.3690 - val_accuracy: 0.9056\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3652 - accuracy: 0.9082 - val_loss: 0.3673 - val_accuracy: 0.9060\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3633 - accuracy: 0.9088 - val_loss: 0.3656 - val_accuracy: 0.9068\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3614 - accuracy: 0.9094 - val_loss: 0.3641 - val_accuracy: 0.9072\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3598 - accuracy: 0.9097 - val_loss: 0.3625 - val_accuracy: 0.9078\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3580 - accuracy: 0.9109 - val_loss: 0.3610 - val_accuracy: 0.9070\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3563 - accuracy: 0.9109 - val_loss: 0.3596 - val_accuracy: 0.9066\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3547 - accuracy: 0.9115 - val_loss: 0.3583 - val_accuracy: 0.9080\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3531 - accuracy: 0.9115 - val_loss: 0.3567 - val_accuracy: 0.9078\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3515 - accuracy: 0.9112 - val_loss: 0.3554 - val_accuracy: 0.9082\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3500 - accuracy: 0.9124 - val_loss: 0.3540 - val_accuracy: 0.9084\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3485 - accuracy: 0.9115 - val_loss: 0.3527 - val_accuracy: 0.9088\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3469 - accuracy: 0.9133 - val_loss: 0.3514 - val_accuracy: 0.9084\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3454 - accuracy: 0.9139 - val_loss: 0.3501 - val_accuracy: 0.9092\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.9133 - val_loss: 0.3488 - val_accuracy: 0.9102\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3427 - accuracy: 0.9139 - val_loss: 0.3482 - val_accuracy: 0.9090\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3414 - accuracy: 0.9136 - val_loss: 0.3465 - val_accuracy: 0.9102\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.9145 - val_loss: 0.3452 - val_accuracy: 0.9112\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.9151 - val_loss: 0.3441 - val_accuracy: 0.9116\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3373 - accuracy: 0.9148 - val_loss: 0.3432 - val_accuracy: 0.9108\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3360 - accuracy: 0.9148 - val_loss: 0.3419 - val_accuracy: 0.9112\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3347 - accuracy: 0.9157 - val_loss: 0.3408 - val_accuracy: 0.9122\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3335 - accuracy: 0.9163 - val_loss: 0.3396 - val_accuracy: 0.9120\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3322 - accuracy: 0.9160 - val_loss: 0.3387 - val_accuracy: 0.9120\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3310 - accuracy: 0.9166 - val_loss: 0.3376 - val_accuracy: 0.9126\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.9157 - val_loss: 0.3366 - val_accuracy: 0.9122\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3286 - accuracy: 0.9172 - val_loss: 0.3355 - val_accuracy: 0.9124\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3275 - accuracy: 0.9169 - val_loss: 0.3344 - val_accuracy: 0.9130\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3263 - accuracy: 0.9187 - val_loss: 0.3336 - val_accuracy: 0.9128\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3252 - accuracy: 0.9172 - val_loss: 0.3326 - val_accuracy: 0.9138\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.9187 - val_loss: 0.3320 - val_accuracy: 0.9132\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3230 - accuracy: 0.9178 - val_loss: 0.3309 - val_accuracy: 0.9140\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3220 - accuracy: 0.9178 - val_loss: 0.3299 - val_accuracy: 0.9140\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3209 - accuracy: 0.9190 - val_loss: 0.3290 - val_accuracy: 0.9140\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3198 - accuracy: 0.9184 - val_loss: 0.3282 - val_accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3189 - accuracy: 0.9196 - val_loss: 0.3272 - val_accuracy: 0.9142\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3178 - accuracy: 0.9199 - val_loss: 0.3264 - val_accuracy: 0.9148\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3168 - accuracy: 0.9202 - val_loss: 0.3255 - val_accuracy: 0.9148\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3158 - accuracy: 0.9199 - val_loss: 0.3248 - val_accuracy: 0.9152\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3148 - accuracy: 0.9205 - val_loss: 0.3238 - val_accuracy: 0.9154\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3139 - accuracy: 0.9208 - val_loss: 0.3231 - val_accuracy: 0.9152\n",
      "56/56 [==============================] - 1s 6ms/step - loss: 0.3445 - accuracy: 0.9040\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 1.9827 - accuracy: 0.3785 - val_loss: 1.7121 - val_accuracy: 0.5846\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.5352 - accuracy: 0.6677 - val_loss: 1.3780 - val_accuracy: 0.7128\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 1.2651 - accuracy: 0.7454 - val_loss: 1.1695 - val_accuracy: 0.7626\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.0916 - accuracy: 0.7831 - val_loss: 1.0304 - val_accuracy: 0.7930\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.9723 - accuracy: 0.8071 - val_loss: 0.9318 - val_accuracy: 0.8130\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.8855 - accuracy: 0.8206 - val_loss: 0.8582 - val_accuracy: 0.8194\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8203 - accuracy: 0.8308 - val_loss: 0.8017 - val_accuracy: 0.8300\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7687 - accuracy: 0.8371 - val_loss: 0.7556 - val_accuracy: 0.8358\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.7268 - accuracy: 0.8419 - val_loss: 0.7180 - val_accuracy: 0.8390\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6924 - accuracy: 0.8467 - val_loss: 0.6876 - val_accuracy: 0.8420\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6632 - accuracy: 0.8500 - val_loss: 0.6608 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6380 - accuracy: 0.8533 - val_loss: 0.6379 - val_accuracy: 0.8526\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6170 - accuracy: 0.8581 - val_loss: 0.6181 - val_accuracy: 0.8560\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5979 - accuracy: 0.8605 - val_loss: 0.6010 - val_accuracy: 0.8586\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5809 - accuracy: 0.8650 - val_loss: 0.5849 - val_accuracy: 0.8620\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5658 - accuracy: 0.8674 - val_loss: 0.5711 - val_accuracy: 0.8652\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5523 - accuracy: 0.8704 - val_loss: 0.5586 - val_accuracy: 0.8670\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5400 - accuracy: 0.8722 - val_loss: 0.5467 - val_accuracy: 0.8694\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5288 - accuracy: 0.8731 - val_loss: 0.5363 - val_accuracy: 0.8708\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.8767 - val_loss: 0.5265 - val_accuracy: 0.8724\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5089 - accuracy: 0.8785 - val_loss: 0.5175 - val_accuracy: 0.8736\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5002 - accuracy: 0.8791 - val_loss: 0.5091 - val_accuracy: 0.8756\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4919 - accuracy: 0.8830 - val_loss: 0.5016 - val_accuracy: 0.8770\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4844 - accuracy: 0.8830 - val_loss: 0.4947 - val_accuracy: 0.8782\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4773 - accuracy: 0.8833 - val_loss: 0.4874 - val_accuracy: 0.8804\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4706 - accuracy: 0.8854 - val_loss: 0.4812 - val_accuracy: 0.8806\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4643 - accuracy: 0.8875 - val_loss: 0.4756 - val_accuracy: 0.8822\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4583 - accuracy: 0.8884 - val_loss: 0.4697 - val_accuracy: 0.8828\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4527 - accuracy: 0.8887 - val_loss: 0.4644 - val_accuracy: 0.8840\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4475 - accuracy: 0.8890 - val_loss: 0.4592 - val_accuracy: 0.8848\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4425 - accuracy: 0.8902 - val_loss: 0.4544 - val_accuracy: 0.8856\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4377 - accuracy: 0.8917 - val_loss: 0.4500 - val_accuracy: 0.8870\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4331 - accuracy: 0.8920 - val_loss: 0.4456 - val_accuracy: 0.8872\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4287 - accuracy: 0.8956 - val_loss: 0.4415 - val_accuracy: 0.8888\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4246 - accuracy: 0.8941 - val_loss: 0.4376 - val_accuracy: 0.8910\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4206 - accuracy: 0.8965 - val_loss: 0.4339 - val_accuracy: 0.8916\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8965 - val_loss: 0.4304 - val_accuracy: 0.8924\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8986 - val_loss: 0.4268 - val_accuracy: 0.8932\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8989 - val_loss: 0.4234 - val_accuracy: 0.8942\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8989 - val_loss: 0.4202 - val_accuracy: 0.8942\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4029 - accuracy: 0.9001 - val_loss: 0.4172 - val_accuracy: 0.8942\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3998 - accuracy: 0.8995 - val_loss: 0.4141 - val_accuracy: 0.8944\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3967 - accuracy: 0.8995 - val_loss: 0.4112 - val_accuracy: 0.8950\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3937 - accuracy: 0.9013 - val_loss: 0.4083 - val_accuracy: 0.8966\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3910 - accuracy: 0.9004 - val_loss: 0.4058 - val_accuracy: 0.8968\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3882 - accuracy: 0.9037 - val_loss: 0.4032 - val_accuracy: 0.8970\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3856 - accuracy: 0.9037 - val_loss: 0.4007 - val_accuracy: 0.8970\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3829 - accuracy: 0.9046 - val_loss: 0.3982 - val_accuracy: 0.8978\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3805 - accuracy: 0.9043 - val_loss: 0.3960 - val_accuracy: 0.8986\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3781 - accuracy: 0.9052 - val_loss: 0.3936 - val_accuracy: 0.8990\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.9064 - val_loss: 0.3914 - val_accuracy: 0.8996\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3733 - accuracy: 0.9061 - val_loss: 0.3894 - val_accuracy: 0.8998\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3711 - accuracy: 0.9070 - val_loss: 0.3874 - val_accuracy: 0.9006\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.9067 - val_loss: 0.3852 - val_accuracy: 0.9012\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3669 - accuracy: 0.9073 - val_loss: 0.3833 - val_accuracy: 0.9020\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3649 - accuracy: 0.9082 - val_loss: 0.3814 - val_accuracy: 0.9020\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3628 - accuracy: 0.9091 - val_loss: 0.3794 - val_accuracy: 0.9020\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3609 - accuracy: 0.9088 - val_loss: 0.3775 - val_accuracy: 0.9032\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3590 - accuracy: 0.9085 - val_loss: 0.3760 - val_accuracy: 0.9036\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3571 - accuracy: 0.9118 - val_loss: 0.3742 - val_accuracy: 0.9040\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3553 - accuracy: 0.9106 - val_loss: 0.3726 - val_accuracy: 0.9040\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3535 - accuracy: 0.9118 - val_loss: 0.3709 - val_accuracy: 0.9046\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3517 - accuracy: 0.9115 - val_loss: 0.3693 - val_accuracy: 0.9054\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.9127 - val_loss: 0.3676 - val_accuracy: 0.9052\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3484 - accuracy: 0.9127 - val_loss: 0.3662 - val_accuracy: 0.9054\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3467 - accuracy: 0.9133 - val_loss: 0.3647 - val_accuracy: 0.9060\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.9139 - val_loss: 0.3633 - val_accuracy: 0.9054\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.9130 - val_loss: 0.3616 - val_accuracy: 0.9058\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3420 - accuracy: 0.9139 - val_loss: 0.3602 - val_accuracy: 0.9060\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3405 - accuracy: 0.9139 - val_loss: 0.3590 - val_accuracy: 0.9066\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3390 - accuracy: 0.9142 - val_loss: 0.3578 - val_accuracy: 0.9064\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.9139 - val_loss: 0.3563 - val_accuracy: 0.9070\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3363 - accuracy: 0.9145 - val_loss: 0.3550 - val_accuracy: 0.9076\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3348 - accuracy: 0.9145 - val_loss: 0.3538 - val_accuracy: 0.9076\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.9160 - val_loss: 0.3525 - val_accuracy: 0.9086\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.9163 - val_loss: 0.3512 - val_accuracy: 0.9076\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3308 - accuracy: 0.9157 - val_loss: 0.3501 - val_accuracy: 0.9084\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3295 - accuracy: 0.9157 - val_loss: 0.3489 - val_accuracy: 0.9082\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3282 - accuracy: 0.9160 - val_loss: 0.3477 - val_accuracy: 0.9090\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3270 - accuracy: 0.9166 - val_loss: 0.3465 - val_accuracy: 0.9094\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3257 - accuracy: 0.9178 - val_loss: 0.3456 - val_accuracy: 0.9088\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.9166 - val_loss: 0.3445 - val_accuracy: 0.9092\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3234 - accuracy: 0.9169 - val_loss: 0.3433 - val_accuracy: 0.9096\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3222 - accuracy: 0.9166 - val_loss: 0.3424 - val_accuracy: 0.9102\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.9184 - val_loss: 0.3414 - val_accuracy: 0.9096\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3199 - accuracy: 0.9166 - val_loss: 0.3402 - val_accuracy: 0.9100\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3188 - accuracy: 0.9172 - val_loss: 0.3393 - val_accuracy: 0.9100\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3177 - accuracy: 0.9169 - val_loss: 0.3382 - val_accuracy: 0.9112\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.3165 - accuracy: 0.9181 - val_loss: 0.3375 - val_accuracy: 0.9108\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3155 - accuracy: 0.9190 - val_loss: 0.3364 - val_accuracy: 0.9112\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3145 - accuracy: 0.9184 - val_loss: 0.3354 - val_accuracy: 0.9112\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3134 - accuracy: 0.9193 - val_loss: 0.3346 - val_accuracy: 0.9116\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3124 - accuracy: 0.9199 - val_loss: 0.3339 - val_accuracy: 0.9118\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3114 - accuracy: 0.9193 - val_loss: 0.3329 - val_accuracy: 0.9120\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.9208 - val_loss: 0.3320 - val_accuracy: 0.9122\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.9205 - val_loss: 0.3311 - val_accuracy: 0.9126\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3085 - accuracy: 0.9214 - val_loss: 0.3302 - val_accuracy: 0.9126\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3075 - accuracy: 0.9214 - val_loss: 0.3292 - val_accuracy: 0.9126\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3066 - accuracy: 0.9211 - val_loss: 0.3284 - val_accuracy: 0.9126\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3056 - accuracy: 0.9220 - val_loss: 0.3276 - val_accuracy: 0.9128\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8956\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 1.9719 - accuracy: 0.3822 - val_loss: 1.7211 - val_accuracy: 0.5816\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 1.5423 - accuracy: 0.6607 - val_loss: 1.4058 - val_accuracy: 0.7120\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.2821 - accuracy: 0.7462 - val_loss: 1.2025 - val_accuracy: 0.7620\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1096 - accuracy: 0.7864 - val_loss: 1.0655 - val_accuracy: 0.7888\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.9896 - accuracy: 0.8095 - val_loss: 0.9672 - val_accuracy: 0.8024\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.9012 - accuracy: 0.8254 - val_loss: 0.8917 - val_accuracy: 0.8146\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8336 - accuracy: 0.8344 - val_loss: 0.8331 - val_accuracy: 0.8230\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7797 - accuracy: 0.8401 - val_loss: 0.7869 - val_accuracy: 0.8322\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7361 - accuracy: 0.8470 - val_loss: 0.7482 - val_accuracy: 0.8402\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6993 - accuracy: 0.8563 - val_loss: 0.7155 - val_accuracy: 0.8436\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6688 - accuracy: 0.8593 - val_loss: 0.6882 - val_accuracy: 0.8466\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6422 - accuracy: 0.8647 - val_loss: 0.6648 - val_accuracy: 0.8494\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6192 - accuracy: 0.8656 - val_loss: 0.6434 - val_accuracy: 0.8522\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5987 - accuracy: 0.8683 - val_loss: 0.6249 - val_accuracy: 0.8560\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5807 - accuracy: 0.8713 - val_loss: 0.6083 - val_accuracy: 0.8592\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5643 - accuracy: 0.8749 - val_loss: 0.5944 - val_accuracy: 0.8602\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5500 - accuracy: 0.8764 - val_loss: 0.5802 - val_accuracy: 0.8638\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.8785 - val_loss: 0.5683 - val_accuracy: 0.8656\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5243 - accuracy: 0.8809 - val_loss: 0.5572 - val_accuracy: 0.8674\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.8827 - val_loss: 0.5466 - val_accuracy: 0.8706\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5028 - accuracy: 0.8839 - val_loss: 0.5372 - val_accuracy: 0.8718\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4932 - accuracy: 0.8860 - val_loss: 0.5282 - val_accuracy: 0.8748\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4843 - accuracy: 0.8899 - val_loss: 0.5202 - val_accuracy: 0.8746\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.8887 - val_loss: 0.5123 - val_accuracy: 0.8768\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4682 - accuracy: 0.8926 - val_loss: 0.5053 - val_accuracy: 0.8780\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.8923 - val_loss: 0.4989 - val_accuracy: 0.8790\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4543 - accuracy: 0.8938 - val_loss: 0.4929 - val_accuracy: 0.8796\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4479 - accuracy: 0.8974 - val_loss: 0.4866 - val_accuracy: 0.8816\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4417 - accuracy: 0.8986 - val_loss: 0.4811 - val_accuracy: 0.8818\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4360 - accuracy: 0.8980 - val_loss: 0.4759 - val_accuracy: 0.8820\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4305 - accuracy: 0.8989 - val_loss: 0.4710 - val_accuracy: 0.8842\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.9013 - val_loss: 0.4662 - val_accuracy: 0.8850\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.9022 - val_loss: 0.4616 - val_accuracy: 0.8872\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4156 - accuracy: 0.9037 - val_loss: 0.4573 - val_accuracy: 0.8880\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.9046 - val_loss: 0.4530 - val_accuracy: 0.8882\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.9061 - val_loss: 0.4490 - val_accuracy: 0.8888\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4027 - accuracy: 0.9052 - val_loss: 0.4457 - val_accuracy: 0.8910\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.9088 - val_loss: 0.4417 - val_accuracy: 0.8922\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3950 - accuracy: 0.9085 - val_loss: 0.4382 - val_accuracy: 0.8918\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3914 - accuracy: 0.9091 - val_loss: 0.4349 - val_accuracy: 0.8924\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3878 - accuracy: 0.9088 - val_loss: 0.4315 - val_accuracy: 0.8942\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3845 - accuracy: 0.9109 - val_loss: 0.4286 - val_accuracy: 0.8940\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3810 - accuracy: 0.9097 - val_loss: 0.4255 - val_accuracy: 0.8954\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.9121 - val_loss: 0.4225 - val_accuracy: 0.8952\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.9112 - val_loss: 0.4198 - val_accuracy: 0.8940\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3720 - accuracy: 0.9121 - val_loss: 0.4176 - val_accuracy: 0.8934\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3692 - accuracy: 0.9118 - val_loss: 0.4148 - val_accuracy: 0.8950\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3663 - accuracy: 0.9118 - val_loss: 0.4126 - val_accuracy: 0.8958\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3637 - accuracy: 0.9142 - val_loss: 0.4098 - val_accuracy: 0.8968\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3610 - accuracy: 0.9145 - val_loss: 0.4074 - val_accuracy: 0.8978\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3586 - accuracy: 0.9145 - val_loss: 0.4052 - val_accuracy: 0.8986\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3560 - accuracy: 0.9163 - val_loss: 0.4029 - val_accuracy: 0.8990\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3537 - accuracy: 0.9184 - val_loss: 0.4011 - val_accuracy: 0.8990\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3514 - accuracy: 0.9166 - val_loss: 0.3989 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3492 - accuracy: 0.9157 - val_loss: 0.3965 - val_accuracy: 0.9016\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.9184 - val_loss: 0.3947 - val_accuracy: 0.9012\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3447 - accuracy: 0.9181 - val_loss: 0.3928 - val_accuracy: 0.9016\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3427 - accuracy: 0.9208 - val_loss: 0.3911 - val_accuracy: 0.9024\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3407 - accuracy: 0.9202 - val_loss: 0.3891 - val_accuracy: 0.9028\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3386 - accuracy: 0.9205 - val_loss: 0.3874 - val_accuracy: 0.9036\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3367 - accuracy: 0.9208 - val_loss: 0.3857 - val_accuracy: 0.9034\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.9208 - val_loss: 0.3839 - val_accuracy: 0.9036\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3330 - accuracy: 0.9211 - val_loss: 0.3824 - val_accuracy: 0.9042\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3313 - accuracy: 0.9223 - val_loss: 0.3808 - val_accuracy: 0.9050\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3295 - accuracy: 0.9229 - val_loss: 0.3790 - val_accuracy: 0.9062\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.9238 - val_loss: 0.3776 - val_accuracy: 0.9056\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.9235 - val_loss: 0.3763 - val_accuracy: 0.9054\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.9229 - val_loss: 0.3748 - val_accuracy: 0.9064\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3228 - accuracy: 0.9238 - val_loss: 0.3733 - val_accuracy: 0.9066\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3211 - accuracy: 0.9238 - val_loss: 0.3718 - val_accuracy: 0.9060\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3197 - accuracy: 0.9244 - val_loss: 0.3706 - val_accuracy: 0.9062\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.9247 - val_loss: 0.3692 - val_accuracy: 0.9062\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3166 - accuracy: 0.9244 - val_loss: 0.3677 - val_accuracy: 0.9068\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3152 - accuracy: 0.9241 - val_loss: 0.3667 - val_accuracy: 0.9084\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3138 - accuracy: 0.9250 - val_loss: 0.3659 - val_accuracy: 0.9086\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3124 - accuracy: 0.9259 - val_loss: 0.3642 - val_accuracy: 0.9090\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3109 - accuracy: 0.9262 - val_loss: 0.3629 - val_accuracy: 0.9090\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3096 - accuracy: 0.9262 - val_loss: 0.3616 - val_accuracy: 0.9092\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3082 - accuracy: 0.9265 - val_loss: 0.3604 - val_accuracy: 0.9096\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3069 - accuracy: 0.9262 - val_loss: 0.3593 - val_accuracy: 0.9106\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3056 - accuracy: 0.9268 - val_loss: 0.3585 - val_accuracy: 0.9106\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3044 - accuracy: 0.9265 - val_loss: 0.3572 - val_accuracy: 0.9114\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3032 - accuracy: 0.9271 - val_loss: 0.3560 - val_accuracy: 0.9110\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3019 - accuracy: 0.9280 - val_loss: 0.3548 - val_accuracy: 0.9110\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3007 - accuracy: 0.9280 - val_loss: 0.3537 - val_accuracy: 0.9110\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2995 - accuracy: 0.9271 - val_loss: 0.3525 - val_accuracy: 0.9108\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2984 - accuracy: 0.9286 - val_loss: 0.3519 - val_accuracy: 0.9116\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2972 - accuracy: 0.9286 - val_loss: 0.3507 - val_accuracy: 0.9124\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.9286 - val_loss: 0.3497 - val_accuracy: 0.9108\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2949 - accuracy: 0.9286 - val_loss: 0.3487 - val_accuracy: 0.9120\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2938 - accuracy: 0.9286 - val_loss: 0.3478 - val_accuracy: 0.9122\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2927 - accuracy: 0.9298 - val_loss: 0.3467 - val_accuracy: 0.9126\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2916 - accuracy: 0.9295 - val_loss: 0.3459 - val_accuracy: 0.9132\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2906 - accuracy: 0.9307 - val_loss: 0.3453 - val_accuracy: 0.9132\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2896 - accuracy: 0.9301 - val_loss: 0.3443 - val_accuracy: 0.9134\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2886 - accuracy: 0.9313 - val_loss: 0.3440 - val_accuracy: 0.9126\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2876 - accuracy: 0.9304 - val_loss: 0.3428 - val_accuracy: 0.9138\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2865 - accuracy: 0.9304 - val_loss: 0.3419 - val_accuracy: 0.9142\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2856 - accuracy: 0.9319 - val_loss: 0.3410 - val_accuracy: 0.9146\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2847 - accuracy: 0.9319 - val_loss: 0.3401 - val_accuracy: 0.9144\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.8800\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 2.0988 - accuracy: 0.3192 - val_loss: 1.8286 - val_accuracy: 0.5264\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.6568 - accuracy: 0.6112 - val_loss: 1.4842 - val_accuracy: 0.6878\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.3755 - accuracy: 0.7192 - val_loss: 1.2573 - val_accuracy: 0.7502\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1876 - accuracy: 0.7690 - val_loss: 1.1035 - val_accuracy: 0.7782\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.0575 - accuracy: 0.7888 - val_loss: 0.9941 - val_accuracy: 0.7962\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.9623 - accuracy: 0.8038 - val_loss: 0.9120 - val_accuracy: 0.8116\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8899 - accuracy: 0.8137 - val_loss: 0.8489 - val_accuracy: 0.8204\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8329 - accuracy: 0.8230 - val_loss: 0.7981 - val_accuracy: 0.8284\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7867 - accuracy: 0.8293 - val_loss: 0.7565 - val_accuracy: 0.8376\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7485 - accuracy: 0.8389 - val_loss: 0.7221 - val_accuracy: 0.8440\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7163 - accuracy: 0.8434 - val_loss: 0.6926 - val_accuracy: 0.8470\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6886 - accuracy: 0.8464 - val_loss: 0.6676 - val_accuracy: 0.8526\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6649 - accuracy: 0.8509 - val_loss: 0.6455 - val_accuracy: 0.8538\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6439 - accuracy: 0.8539 - val_loss: 0.6263 - val_accuracy: 0.8584\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6251 - accuracy: 0.8581 - val_loss: 0.6085 - val_accuracy: 0.8612\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6085 - accuracy: 0.8605 - val_loss: 0.5932 - val_accuracy: 0.8640\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5934 - accuracy: 0.8650 - val_loss: 0.5791 - val_accuracy: 0.8664\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5798 - accuracy: 0.8668 - val_loss: 0.5660 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5673 - accuracy: 0.8686 - val_loss: 0.5543 - val_accuracy: 0.8694\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5560 - accuracy: 0.8689 - val_loss: 0.5436 - val_accuracy: 0.8720\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5455 - accuracy: 0.8722 - val_loss: 0.5339 - val_accuracy: 0.8742\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.8737 - val_loss: 0.5249 - val_accuracy: 0.8752\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.8749 - val_loss: 0.5164 - val_accuracy: 0.8762\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5184 - accuracy: 0.8752 - val_loss: 0.5087 - val_accuracy: 0.8784\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.8782 - val_loss: 0.5016 - val_accuracy: 0.8796\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.8779 - val_loss: 0.4945 - val_accuracy: 0.8804\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4963 - accuracy: 0.8806 - val_loss: 0.4880 - val_accuracy: 0.8824\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4898 - accuracy: 0.8818 - val_loss: 0.4820 - val_accuracy: 0.8842\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4836 - accuracy: 0.8833 - val_loss: 0.4763 - val_accuracy: 0.8840\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4777 - accuracy: 0.8845 - val_loss: 0.4711 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4723 - accuracy: 0.8857 - val_loss: 0.4658 - val_accuracy: 0.8870\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.8893 - val_loss: 0.4607 - val_accuracy: 0.8890\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4620 - accuracy: 0.8884 - val_loss: 0.4561 - val_accuracy: 0.8896\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.8911 - val_loss: 0.4516 - val_accuracy: 0.8902\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4527 - accuracy: 0.8926 - val_loss: 0.4474 - val_accuracy: 0.8908\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4483 - accuracy: 0.8935 - val_loss: 0.4432 - val_accuracy: 0.8926\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4441 - accuracy: 0.8941 - val_loss: 0.4394 - val_accuracy: 0.8932\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4401 - accuracy: 0.8950 - val_loss: 0.4357 - val_accuracy: 0.8948\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4364 - accuracy: 0.8971 - val_loss: 0.4323 - val_accuracy: 0.8964\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4326 - accuracy: 0.8974 - val_loss: 0.4290 - val_accuracy: 0.8946\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4290 - accuracy: 0.8977 - val_loss: 0.4253 - val_accuracy: 0.8970\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4255 - accuracy: 0.8986 - val_loss: 0.4224 - val_accuracy: 0.8960\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4222 - accuracy: 0.8995 - val_loss: 0.4192 - val_accuracy: 0.8976\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8995 - val_loss: 0.4162 - val_accuracy: 0.8992\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.9019 - val_loss: 0.4135 - val_accuracy: 0.8994\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4130 - accuracy: 0.9028 - val_loss: 0.4106 - val_accuracy: 0.9012\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4101 - accuracy: 0.9022 - val_loss: 0.4080 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.9034 - val_loss: 0.4056 - val_accuracy: 0.8984\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.9010 - val_loss: 0.4029 - val_accuracy: 0.9018\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4020 - accuracy: 0.9037 - val_loss: 0.4006 - val_accuracy: 0.9020\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3994 - accuracy: 0.9040 - val_loss: 0.3983 - val_accuracy: 0.9030\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3969 - accuracy: 0.9052 - val_loss: 0.3959 - val_accuracy: 0.9034\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3945 - accuracy: 0.9049 - val_loss: 0.3937 - val_accuracy: 0.9036\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3921 - accuracy: 0.9049 - val_loss: 0.3917 - val_accuracy: 0.9038\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3899 - accuracy: 0.9058 - val_loss: 0.3896 - val_accuracy: 0.9042\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.9049 - val_loss: 0.3874 - val_accuracy: 0.9048\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3855 - accuracy: 0.9067 - val_loss: 0.3855 - val_accuracy: 0.9048\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3833 - accuracy: 0.9067 - val_loss: 0.3837 - val_accuracy: 0.9042\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3813 - accuracy: 0.9073 - val_loss: 0.3817 - val_accuracy: 0.9048\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3792 - accuracy: 0.9064 - val_loss: 0.3800 - val_accuracy: 0.9052\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3772 - accuracy: 0.9079 - val_loss: 0.3782 - val_accuracy: 0.9058\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3753 - accuracy: 0.9073 - val_loss: 0.3766 - val_accuracy: 0.9056\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3735 - accuracy: 0.9091 - val_loss: 0.3748 - val_accuracy: 0.9060\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3716 - accuracy: 0.9082 - val_loss: 0.3731 - val_accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3698 - accuracy: 0.9103 - val_loss: 0.3716 - val_accuracy: 0.9066\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.9100 - val_loss: 0.3702 - val_accuracy: 0.9074\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3664 - accuracy: 0.9109 - val_loss: 0.3684 - val_accuracy: 0.9078\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3646 - accuracy: 0.9103 - val_loss: 0.3668 - val_accuracy: 0.9080\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3630 - accuracy: 0.9112 - val_loss: 0.3654 - val_accuracy: 0.9082\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3614 - accuracy: 0.9118 - val_loss: 0.3640 - val_accuracy: 0.9082\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3599 - accuracy: 0.9115 - val_loss: 0.3627 - val_accuracy: 0.9078\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3583 - accuracy: 0.9109 - val_loss: 0.3613 - val_accuracy: 0.9086\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3567 - accuracy: 0.9124 - val_loss: 0.3598 - val_accuracy: 0.9090\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3552 - accuracy: 0.9127 - val_loss: 0.3585 - val_accuracy: 0.9092\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.9118 - val_loss: 0.3571 - val_accuracy: 0.9094\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.9124 - val_loss: 0.3558 - val_accuracy: 0.9094\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3509 - accuracy: 0.9136 - val_loss: 0.3546 - val_accuracy: 0.9098\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.9127 - val_loss: 0.3535 - val_accuracy: 0.9098\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3481 - accuracy: 0.9142 - val_loss: 0.3524 - val_accuracy: 0.9098\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3468 - accuracy: 0.9145 - val_loss: 0.3513 - val_accuracy: 0.9096\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3455 - accuracy: 0.9142 - val_loss: 0.3501 - val_accuracy: 0.9102\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.9142 - val_loss: 0.3489 - val_accuracy: 0.9104\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3428 - accuracy: 0.9142 - val_loss: 0.3476 - val_accuracy: 0.9108\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3417 - accuracy: 0.9148 - val_loss: 0.3465 - val_accuracy: 0.9112\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3404 - accuracy: 0.9148 - val_loss: 0.3457 - val_accuracy: 0.9106\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3393 - accuracy: 0.9145 - val_loss: 0.3445 - val_accuracy: 0.9116\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3381 - accuracy: 0.9148 - val_loss: 0.3436 - val_accuracy: 0.9114\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3368 - accuracy: 0.9169 - val_loss: 0.3426 - val_accuracy: 0.9114\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3356 - accuracy: 0.9166 - val_loss: 0.3414 - val_accuracy: 0.9132\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.9163 - val_loss: 0.3404 - val_accuracy: 0.9138\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.9181 - val_loss: 0.3395 - val_accuracy: 0.9134\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3323 - accuracy: 0.9172 - val_loss: 0.3385 - val_accuracy: 0.9132\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.9178 - val_loss: 0.3375 - val_accuracy: 0.9130\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3301 - accuracy: 0.9178 - val_loss: 0.3367 - val_accuracy: 0.9132\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3290 - accuracy: 0.9178 - val_loss: 0.3357 - val_accuracy: 0.9138\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3280 - accuracy: 0.9184 - val_loss: 0.3349 - val_accuracy: 0.9140\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3270 - accuracy: 0.9184 - val_loss: 0.3340 - val_accuracy: 0.9136\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3259 - accuracy: 0.9178 - val_loss: 0.3332 - val_accuracy: 0.9132\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3249 - accuracy: 0.9181 - val_loss: 0.3323 - val_accuracy: 0.9136\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3239 - accuracy: 0.9181 - val_loss: 0.3315 - val_accuracy: 0.9136\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.9034\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 2.0896 - accuracy: 0.2969 - val_loss: 1.8239 - val_accuracy: 0.5280\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.6367 - accuracy: 0.6269 - val_loss: 1.4782 - val_accuracy: 0.6856\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.3551 - accuracy: 0.7175 - val_loss: 1.2558 - val_accuracy: 0.7470\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1694 - accuracy: 0.7630 - val_loss: 1.1048 - val_accuracy: 0.7742\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.0403 - accuracy: 0.7882 - val_loss: 0.9966 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.9459 - accuracy: 0.8041 - val_loss: 0.9160 - val_accuracy: 0.8046\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8738 - accuracy: 0.8167 - val_loss: 0.8537 - val_accuracy: 0.8182\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.8175 - accuracy: 0.8257 - val_loss: 0.8030 - val_accuracy: 0.8272\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.7717 - accuracy: 0.8332 - val_loss: 0.7620 - val_accuracy: 0.8356\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7338 - accuracy: 0.8416 - val_loss: 0.7280 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7017 - accuracy: 0.8440 - val_loss: 0.6989 - val_accuracy: 0.8452\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.6746 - accuracy: 0.8485 - val_loss: 0.6735 - val_accuracy: 0.8490\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6508 - accuracy: 0.8521 - val_loss: 0.6514 - val_accuracy: 0.8514\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6300 - accuracy: 0.8551 - val_loss: 0.6321 - val_accuracy: 0.8528\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6114 - accuracy: 0.8563 - val_loss: 0.6147 - val_accuracy: 0.8562\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5948 - accuracy: 0.8605 - val_loss: 0.5994 - val_accuracy: 0.8568\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5801 - accuracy: 0.8617 - val_loss: 0.5855 - val_accuracy: 0.8604\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5668 - accuracy: 0.8644 - val_loss: 0.5727 - val_accuracy: 0.8632\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5545 - accuracy: 0.8665 - val_loss: 0.5614 - val_accuracy: 0.8660\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.8686 - val_loss: 0.5507 - val_accuracy: 0.8668\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5331 - accuracy: 0.8683 - val_loss: 0.5413 - val_accuracy: 0.8718\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.8728 - val_loss: 0.5323 - val_accuracy: 0.8710\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5148 - accuracy: 0.8719 - val_loss: 0.5235 - val_accuracy: 0.8718\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5065 - accuracy: 0.8737 - val_loss: 0.5156 - val_accuracy: 0.8744\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4990 - accuracy: 0.8752 - val_loss: 0.5082 - val_accuracy: 0.8758\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.8770 - val_loss: 0.5015 - val_accuracy: 0.8762\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4850 - accuracy: 0.8776 - val_loss: 0.4950 - val_accuracy: 0.8778\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4787 - accuracy: 0.8776 - val_loss: 0.4889 - val_accuracy: 0.8788\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4726 - accuracy: 0.8809 - val_loss: 0.4834 - val_accuracy: 0.8794\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.8821 - val_loss: 0.4782 - val_accuracy: 0.8812\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4617 - accuracy: 0.8827 - val_loss: 0.4729 - val_accuracy: 0.8812\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4564 - accuracy: 0.8848 - val_loss: 0.4681 - val_accuracy: 0.8816\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4517 - accuracy: 0.8851 - val_loss: 0.4634 - val_accuracy: 0.8838\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4470 - accuracy: 0.8872 - val_loss: 0.4588 - val_accuracy: 0.8848\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8890 - val_loss: 0.4547 - val_accuracy: 0.8862\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8908 - val_loss: 0.4504 - val_accuracy: 0.8864\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4342 - accuracy: 0.8932 - val_loss: 0.4471 - val_accuracy: 0.8872\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8911 - val_loss: 0.4429 - val_accuracy: 0.8890\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8944 - val_loss: 0.4393 - val_accuracy: 0.8904\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8953 - val_loss: 0.4358 - val_accuracy: 0.8904\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4195 - accuracy: 0.8968 - val_loss: 0.4328 - val_accuracy: 0.8926\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8971 - val_loss: 0.4299 - val_accuracy: 0.8922\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8986 - val_loss: 0.4265 - val_accuracy: 0.8924\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8986 - val_loss: 0.4236 - val_accuracy: 0.8932\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4067 - accuracy: 0.8992 - val_loss: 0.4206 - val_accuracy: 0.8950\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.9016 - val_loss: 0.4177 - val_accuracy: 0.8956\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4011 - accuracy: 0.9022 - val_loss: 0.4152 - val_accuracy: 0.8958\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3984 - accuracy: 0.9022 - val_loss: 0.4126 - val_accuracy: 0.8968\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.9010 - val_loss: 0.4101 - val_accuracy: 0.8966\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.9022 - val_loss: 0.4076 - val_accuracy: 0.8972\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.9031 - val_loss: 0.4053 - val_accuracy: 0.8976\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3882 - accuracy: 0.9037 - val_loss: 0.4030 - val_accuracy: 0.8978\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.9034 - val_loss: 0.4007 - val_accuracy: 0.8976\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3836 - accuracy: 0.9040 - val_loss: 0.3987 - val_accuracy: 0.8976\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3813 - accuracy: 0.9040 - val_loss: 0.3969 - val_accuracy: 0.8976\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3792 - accuracy: 0.9055 - val_loss: 0.3947 - val_accuracy: 0.8980\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.3771 - accuracy: 0.9064 - val_loss: 0.3926 - val_accuracy: 0.8994\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.9061 - val_loss: 0.3906 - val_accuracy: 0.8998\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3728 - accuracy: 0.9076 - val_loss: 0.3887 - val_accuracy: 0.9004\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.9070 - val_loss: 0.3869 - val_accuracy: 0.9008\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.9079 - val_loss: 0.3854 - val_accuracy: 0.9008\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.9076 - val_loss: 0.3834 - val_accuracy: 0.9018\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3654 - accuracy: 0.9088 - val_loss: 0.3817 - val_accuracy: 0.9018\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.9094 - val_loss: 0.3799 - val_accuracy: 0.9028\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.9100 - val_loss: 0.3782 - val_accuracy: 0.9030\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.9103 - val_loss: 0.3765 - val_accuracy: 0.9036\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3584 - accuracy: 0.9112 - val_loss: 0.3751 - val_accuracy: 0.9034\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.9106 - val_loss: 0.3737 - val_accuracy: 0.9034\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.9109 - val_loss: 0.3721 - val_accuracy: 0.9036\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.9100 - val_loss: 0.3705 - val_accuracy: 0.9046\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3520 - accuracy: 0.9124 - val_loss: 0.3691 - val_accuracy: 0.9042\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.9124 - val_loss: 0.3678 - val_accuracy: 0.9042\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.9121 - val_loss: 0.3664 - val_accuracy: 0.9048\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.9133 - val_loss: 0.3651 - val_accuracy: 0.9060\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3462 - accuracy: 0.9133 - val_loss: 0.3638 - val_accuracy: 0.9056\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.9133 - val_loss: 0.3624 - val_accuracy: 0.9058\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.9139 - val_loss: 0.3612 - val_accuracy: 0.9074\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.9151 - val_loss: 0.3601 - val_accuracy: 0.9064\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3407 - accuracy: 0.9148 - val_loss: 0.3587 - val_accuracy: 0.9076\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.9154 - val_loss: 0.3576 - val_accuracy: 0.9084\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.9169 - val_loss: 0.3565 - val_accuracy: 0.9084\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.9169 - val_loss: 0.3550 - val_accuracy: 0.9092\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3356 - accuracy: 0.9181 - val_loss: 0.3539 - val_accuracy: 0.9096\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.9190 - val_loss: 0.3528 - val_accuracy: 0.9096\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.9190 - val_loss: 0.3518 - val_accuracy: 0.9090\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3320 - accuracy: 0.9190 - val_loss: 0.3507 - val_accuracy: 0.9100\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.9181 - val_loss: 0.3497 - val_accuracy: 0.9110\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.9196 - val_loss: 0.3488 - val_accuracy: 0.9096\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.9184 - val_loss: 0.3477 - val_accuracy: 0.9114\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3274 - accuracy: 0.9205 - val_loss: 0.3468 - val_accuracy: 0.9108\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.9193 - val_loss: 0.3457 - val_accuracy: 0.9114\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.9205 - val_loss: 0.3446 - val_accuracy: 0.9110\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.9202 - val_loss: 0.3436 - val_accuracy: 0.9112\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3230 - accuracy: 0.9208 - val_loss: 0.3426 - val_accuracy: 0.9122\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.9205 - val_loss: 0.3417 - val_accuracy: 0.9120\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.9211 - val_loss: 0.3408 - val_accuracy: 0.9122\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3200 - accuracy: 0.9217 - val_loss: 0.3399 - val_accuracy: 0.9126\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.9214 - val_loss: 0.3389 - val_accuracy: 0.9120\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.9214 - val_loss: 0.3381 - val_accuracy: 0.9122\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.9217 - val_loss: 0.3372 - val_accuracy: 0.9122\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8926\n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 1.7985 - accuracy: 0.4884 - val_loss: 1.1778 - val_accuracy: 0.7602\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.8226 - accuracy: 0.8158 - val_loss: 0.6317 - val_accuracy: 0.8508\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.5144 - accuracy: 0.8776 - val_loss: 0.4923 - val_accuracy: 0.8714\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.4026 - accuracy: 0.8995 - val_loss: 0.4000 - val_accuracy: 0.8930\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3435 - accuracy: 0.9118 - val_loss: 0.3660 - val_accuracy: 0.8996\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3014 - accuracy: 0.9217 - val_loss: 0.3364 - val_accuracy: 0.9118\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.2740 - accuracy: 0.9271 - val_loss: 0.3098 - val_accuracy: 0.9160\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.2537 - accuracy: 0.9325 - val_loss: 0.2928 - val_accuracy: 0.9186\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.2325 - accuracy: 0.9382 - val_loss: 0.3172 - val_accuracy: 0.9066\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.2204 - accuracy: 0.9400 - val_loss: 0.2764 - val_accuracy: 0.9236\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9439 - val_loss: 0.2555 - val_accuracy: 0.9312\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1953 - accuracy: 0.9484 - val_loss: 0.2535 - val_accuracy: 0.9312\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1829 - accuracy: 0.9526 - val_loss: 0.2483 - val_accuracy: 0.9346\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9562 - val_loss: 0.2363 - val_accuracy: 0.9376\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1653 - accuracy: 0.9571 - val_loss: 0.2494 - val_accuracy: 0.9290\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9595 - val_loss: 0.2245 - val_accuracy: 0.9372\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1506 - accuracy: 0.9604 - val_loss: 0.2133 - val_accuracy: 0.9426\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1403 - accuracy: 0.9667 - val_loss: 0.2262 - val_accuracy: 0.9382\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1347 - accuracy: 0.9661 - val_loss: 0.2131 - val_accuracy: 0.9426\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1299 - accuracy: 0.9664 - val_loss: 0.2500 - val_accuracy: 0.9238\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1233 - accuracy: 0.9709 - val_loss: 0.2024 - val_accuracy: 0.9468\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1155 - accuracy: 0.9730 - val_loss: 0.1979 - val_accuracy: 0.9462\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1110 - accuracy: 0.9727 - val_loss: 0.1896 - val_accuracy: 0.9508\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1051 - accuracy: 0.9727 - val_loss: 0.2011 - val_accuracy: 0.9448\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.1030 - accuracy: 0.9766 - val_loss: 0.1859 - val_accuracy: 0.9524\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0959 - accuracy: 0.9769 - val_loss: 0.1912 - val_accuracy: 0.9508\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0906 - accuracy: 0.9793 - val_loss: 0.1918 - val_accuracy: 0.9498\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0880 - accuracy: 0.9811 - val_loss: 0.1808 - val_accuracy: 0.9532\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9820 - val_loss: 0.1745 - val_accuracy: 0.9562\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0782 - accuracy: 0.9823 - val_loss: 0.1740 - val_accuracy: 0.9564\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0749 - accuracy: 0.9838 - val_loss: 0.1719 - val_accuracy: 0.9570\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0715 - accuracy: 0.9841 - val_loss: 0.1705 - val_accuracy: 0.9576\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9880 - val_loss: 0.1682 - val_accuracy: 0.9590\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0643 - accuracy: 0.9877 - val_loss: 0.1720 - val_accuracy: 0.9596\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.9910 - val_loss: 0.1685 - val_accuracy: 0.9580\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0582 - accuracy: 0.9904 - val_loss: 0.1682 - val_accuracy: 0.9604\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9913 - val_loss: 0.1632 - val_accuracy: 0.9616\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9910 - val_loss: 0.1634 - val_accuracy: 0.9620\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0504 - accuracy: 0.9937 - val_loss: 0.1581 - val_accuracy: 0.9630\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.9937 - val_loss: 0.1601 - val_accuracy: 0.9622\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0451 - accuracy: 0.9943 - val_loss: 0.1578 - val_accuracy: 0.9638\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9931 - val_loss: 0.1651 - val_accuracy: 0.9610\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9955 - val_loss: 0.1578 - val_accuracy: 0.9624\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0385 - accuracy: 0.9952 - val_loss: 0.1593 - val_accuracy: 0.9624\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9961 - val_loss: 0.1568 - val_accuracy: 0.9640\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0355 - accuracy: 0.9961 - val_loss: 0.1551 - val_accuracy: 0.9648\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0330 - accuracy: 0.9970 - val_loss: 0.1546 - val_accuracy: 0.9652\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9973 - val_loss: 0.1586 - val_accuracy: 0.9642\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0302 - accuracy: 0.9973 - val_loss: 0.1628 - val_accuracy: 0.9630\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0295 - accuracy: 0.9976 - val_loss: 0.1547 - val_accuracy: 0.9654\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0281 - accuracy: 0.9976 - val_loss: 0.1545 - val_accuracy: 0.9652\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 5441s 16s/step - loss: 0.0264 - accuracy: 0.9988 - val_loss: 0.1586 - val_accuracy: 0.9646\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 0.0255 - accuracy: 0.9988 - val_loss: 0.1561 - val_accuracy: 0.9652\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.0244 - accuracy: 0.9985 - val_loss: 0.1553 - val_accuracy: 0.9652\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0234 - accuracy: 0.9994 - val_loss: 0.1551 - val_accuracy: 0.9664\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0221 - accuracy: 0.9994 - val_loss: 0.1604 - val_accuracy: 0.9658\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0211 - accuracy: 0.9991 - val_loss: 0.1543 - val_accuracy: 0.9664\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0204 - accuracy: 0.9997 - val_loss: 0.1536 - val_accuracy: 0.9668\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0195 - accuracy: 0.9994 - val_loss: 0.1543 - val_accuracy: 0.9658\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9670\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9662\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0175 - accuracy: 0.9997 - val_loss: 0.1526 - val_accuracy: 0.9658\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9660\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9662\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0156 - accuracy: 0.9994 - val_loss: 0.1572 - val_accuracy: 0.9662\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9664\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9672\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9670\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9654\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9664\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9670\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9680\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.4420 - accuracy: 0.9040\n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 4s 9ms/step - loss: 1.7938 - accuracy: 0.4782 - val_loss: 1.2265 - val_accuracy: 0.6842\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.9167 - accuracy: 0.7798 - val_loss: 0.6846 - val_accuracy: 0.8188\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.5946 - accuracy: 0.8434 - val_loss: 0.5077 - val_accuracy: 0.8694\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.4658 - accuracy: 0.8788 - val_loss: 0.4059 - val_accuracy: 0.8958\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3906 - accuracy: 0.8977 - val_loss: 0.3628 - val_accuracy: 0.9024\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3473 - accuracy: 0.9052 - val_loss: 0.3293 - val_accuracy: 0.9124\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3143 - accuracy: 0.9154 - val_loss: 0.3071 - val_accuracy: 0.9188\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2893 - accuracy: 0.9232 - val_loss: 0.2803 - val_accuracy: 0.9234\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2693 - accuracy: 0.9301 - val_loss: 0.2595 - val_accuracy: 0.9318\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.2510 - accuracy: 0.9322 - val_loss: 0.2518 - val_accuracy: 0.9312\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.2383 - accuracy: 0.9355 - val_loss: 0.2369 - val_accuracy: 0.9398\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2217 - accuracy: 0.9421 - val_loss: 0.2292 - val_accuracy: 0.9360\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2106 - accuracy: 0.9406 - val_loss: 0.2196 - val_accuracy: 0.9424\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2015 - accuracy: 0.9490 - val_loss: 0.2096 - val_accuracy: 0.9472\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1904 - accuracy: 0.9535 - val_loss: 0.2049 - val_accuracy: 0.9464\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1827 - accuracy: 0.9532 - val_loss: 0.1957 - val_accuracy: 0.9484\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1737 - accuracy: 0.9568 - val_loss: 0.1951 - val_accuracy: 0.9454\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1637 - accuracy: 0.9583 - val_loss: 0.1912 - val_accuracy: 0.9478\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.1569 - accuracy: 0.9595 - val_loss: 0.1832 - val_accuracy: 0.9522\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1482 - accuracy: 0.9613 - val_loss: 0.1825 - val_accuracy: 0.9542\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1429 - accuracy: 0.9667 - val_loss: 0.1725 - val_accuracy: 0.9530\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1359 - accuracy: 0.9664 - val_loss: 0.1695 - val_accuracy: 0.9544\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1297 - accuracy: 0.9679 - val_loss: 0.1661 - val_accuracy: 0.9568\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1231 - accuracy: 0.9730 - val_loss: 0.1610 - val_accuracy: 0.9564\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1178 - accuracy: 0.9712 - val_loss: 0.1505 - val_accuracy: 0.9618\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1114 - accuracy: 0.9742 - val_loss: 0.1512 - val_accuracy: 0.9624\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1068 - accuracy: 0.9751 - val_loss: 0.1503 - val_accuracy: 0.9622\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1017 - accuracy: 0.9769 - val_loss: 0.1461 - val_accuracy: 0.9622\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0979 - accuracy: 0.9784 - val_loss: 0.1406 - val_accuracy: 0.9642\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0929 - accuracy: 0.9781 - val_loss: 0.1429 - val_accuracy: 0.9630\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0887 - accuracy: 0.9811 - val_loss: 0.1359 - val_accuracy: 0.9670\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0836 - accuracy: 0.9811 - val_loss: 0.1355 - val_accuracy: 0.9674\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0808 - accuracy: 0.9829 - val_loss: 0.1281 - val_accuracy: 0.9694\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0756 - accuracy: 0.9835 - val_loss: 0.1276 - val_accuracy: 0.9694\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0731 - accuracy: 0.9865 - val_loss: 0.1277 - val_accuracy: 0.9692\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0699 - accuracy: 0.9868 - val_loss: 0.1297 - val_accuracy: 0.9688\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0672 - accuracy: 0.9865 - val_loss: 0.1202 - val_accuracy: 0.9714\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0636 - accuracy: 0.9883 - val_loss: 0.1201 - val_accuracy: 0.9696\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0617 - accuracy: 0.9877 - val_loss: 0.1179 - val_accuracy: 0.9724\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0580 - accuracy: 0.9892 - val_loss: 0.1216 - val_accuracy: 0.9708\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0556 - accuracy: 0.9898 - val_loss: 0.1165 - val_accuracy: 0.9724\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0527 - accuracy: 0.9913 - val_loss: 0.1137 - val_accuracy: 0.9726\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0506 - accuracy: 0.9901 - val_loss: 0.1133 - val_accuracy: 0.9728\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9919 - val_loss: 0.1095 - val_accuracy: 0.9738\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0462 - accuracy: 0.9934 - val_loss: 0.1087 - val_accuracy: 0.9746\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0441 - accuracy: 0.9946 - val_loss: 0.1114 - val_accuracy: 0.9742\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0423 - accuracy: 0.9940 - val_loss: 0.1094 - val_accuracy: 0.9744\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0402 - accuracy: 0.9943 - val_loss: 0.1122 - val_accuracy: 0.9738\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0380 - accuracy: 0.9955 - val_loss: 0.1104 - val_accuracy: 0.9754\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0367 - accuracy: 0.9955 - val_loss: 0.1069 - val_accuracy: 0.9756\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0355 - accuracy: 0.9955 - val_loss: 0.1069 - val_accuracy: 0.9758\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0340 - accuracy: 0.9958 - val_loss: 0.1060 - val_accuracy: 0.9754\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9976 - val_loss: 0.1049 - val_accuracy: 0.9764\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9970 - val_loss: 0.1092 - val_accuracy: 0.9762\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0300 - accuracy: 0.9967 - val_loss: 0.1055 - val_accuracy: 0.9764\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0283 - accuracy: 0.9976 - val_loss: 0.1027 - val_accuracy: 0.9774\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9973 - val_loss: 0.1038 - val_accuracy: 0.9776\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0263 - accuracy: 0.9985 - val_loss: 0.1034 - val_accuracy: 0.9774\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0251 - accuracy: 0.9979 - val_loss: 0.1053 - val_accuracy: 0.9770\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0242 - accuracy: 0.9988 - val_loss: 0.1025 - val_accuracy: 0.9774\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9988 - val_loss: 0.1027 - val_accuracy: 0.9776\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0223 - accuracy: 0.9988 - val_loss: 0.1024 - val_accuracy: 0.9776\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 8s 23ms/step - loss: 0.0214 - accuracy: 0.9994 - val_loss: 0.1009 - val_accuracy: 0.9774\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0207 - accuracy: 0.9991 - val_loss: 0.1005 - val_accuracy: 0.9776\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0196 - accuracy: 0.9994 - val_loss: 0.1011 - val_accuracy: 0.9788\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0193 - accuracy: 0.9994 - val_loss: 0.1023 - val_accuracy: 0.9780\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9778\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0178 - accuracy: 0.9994 - val_loss: 0.1029 - val_accuracy: 0.9776\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0172 - accuracy: 0.9997 - val_loss: 0.1014 - val_accuracy: 0.9786\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0166 - accuracy: 0.9997 - val_loss: 0.1008 - val_accuracy: 0.9778\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9778\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0151 - accuracy: 0.9997 - val_loss: 0.1033 - val_accuracy: 0.9772\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9780\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9780\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9778\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9782\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9780\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9784\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9784\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9782\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9788\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9784\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9782\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9776\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9782\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.2789 - accuracy: 0.9346\n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 7s 8ms/step - loss: 1.8814 - accuracy: 0.4619 - val_loss: 1.2993 - val_accuracy: 0.7338\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.9200 - accuracy: 0.7966 - val_loss: 0.6807 - val_accuracy: 0.8284\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.5748 - accuracy: 0.8497 - val_loss: 0.4948 - val_accuracy: 0.8742\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4518 - accuracy: 0.8797 - val_loss: 0.4210 - val_accuracy: 0.8852\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3860 - accuracy: 0.8950 - val_loss: 0.3759 - val_accuracy: 0.8944\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3446 - accuracy: 0.9022 - val_loss: 0.3469 - val_accuracy: 0.9028\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3126 - accuracy: 0.9139 - val_loss: 0.3202 - val_accuracy: 0.9068\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2902 - accuracy: 0.9193 - val_loss: 0.3020 - val_accuracy: 0.9120\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2703 - accuracy: 0.9211 - val_loss: 0.2918 - val_accuracy: 0.9146\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.2537 - accuracy: 0.9244 - val_loss: 0.2673 - val_accuracy: 0.9236\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2395 - accuracy: 0.9340 - val_loss: 0.2556 - val_accuracy: 0.9292\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.2272 - accuracy: 0.9376 - val_loss: 0.2455 - val_accuracy: 0.9326\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2143 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9370\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2026 - accuracy: 0.9454 - val_loss: 0.2334 - val_accuracy: 0.9334\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1927 - accuracy: 0.9478 - val_loss: 0.2274 - val_accuracy: 0.9366\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1831 - accuracy: 0.9493 - val_loss: 0.2191 - val_accuracy: 0.9394\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1724 - accuracy: 0.9541 - val_loss: 0.2073 - val_accuracy: 0.9440\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1663 - accuracy: 0.9550 - val_loss: 0.2028 - val_accuracy: 0.9462\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1567 - accuracy: 0.9577 - val_loss: 0.1981 - val_accuracy: 0.9490\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1504 - accuracy: 0.9589 - val_loss: 0.1961 - val_accuracy: 0.9458\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1418 - accuracy: 0.9625 - val_loss: 0.2132 - val_accuracy: 0.9422\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1369 - accuracy: 0.9628 - val_loss: 0.1914 - val_accuracy: 0.9482\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1287 - accuracy: 0.9670 - val_loss: 0.1877 - val_accuracy: 0.9504\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1256 - accuracy: 0.9676 - val_loss: 0.1718 - val_accuracy: 0.9584\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1178 - accuracy: 0.9721 - val_loss: 0.1707 - val_accuracy: 0.9572\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1113 - accuracy: 0.9760 - val_loss: 0.1675 - val_accuracy: 0.9592\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1082 - accuracy: 0.9721 - val_loss: 0.1622 - val_accuracy: 0.9616\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1007 - accuracy: 0.9784 - val_loss: 0.1757 - val_accuracy: 0.9538\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0972 - accuracy: 0.9793 - val_loss: 0.1556 - val_accuracy: 0.9626\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0931 - accuracy: 0.9805 - val_loss: 0.1569 - val_accuracy: 0.9626\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0885 - accuracy: 0.9805 - val_loss: 0.1528 - val_accuracy: 0.9640\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0851 - accuracy: 0.9826 - val_loss: 0.1490 - val_accuracy: 0.9652\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0803 - accuracy: 0.9841 - val_loss: 0.1508 - val_accuracy: 0.9650\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0754 - accuracy: 0.9844 - val_loss: 0.1488 - val_accuracy: 0.9650\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0731 - accuracy: 0.9859 - val_loss: 0.1552 - val_accuracy: 0.9618\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0697 - accuracy: 0.9871 - val_loss: 0.1423 - val_accuracy: 0.9676\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0653 - accuracy: 0.9898 - val_loss: 0.1473 - val_accuracy: 0.9630\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0624 - accuracy: 0.9892 - val_loss: 0.1424 - val_accuracy: 0.9662\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0600 - accuracy: 0.9898 - val_loss: 0.1418 - val_accuracy: 0.9664\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0567 - accuracy: 0.9910 - val_loss: 0.1355 - val_accuracy: 0.9682\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0548 - accuracy: 0.9916 - val_loss: 0.1332 - val_accuracy: 0.9704\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0521 - accuracy: 0.9904 - val_loss: 0.1359 - val_accuracy: 0.9698\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0488 - accuracy: 0.9937 - val_loss: 0.1349 - val_accuracy: 0.9688\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0469 - accuracy: 0.9940 - val_loss: 0.1368 - val_accuracy: 0.9682\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0448 - accuracy: 0.9943 - val_loss: 0.1305 - val_accuracy: 0.9718\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9955 - val_loss: 0.1285 - val_accuracy: 0.9700\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0402 - accuracy: 0.9949 - val_loss: 0.1311 - val_accuracy: 0.9700\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0388 - accuracy: 0.9952 - val_loss: 0.1291 - val_accuracy: 0.9716\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0364 - accuracy: 0.9970 - val_loss: 0.1324 - val_accuracy: 0.9704\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9967 - val_loss: 0.1292 - val_accuracy: 0.9716\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0334 - accuracy: 0.9985 - val_loss: 0.1297 - val_accuracy: 0.9714\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0325 - accuracy: 0.9976 - val_loss: 0.1268 - val_accuracy: 0.9728\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0308 - accuracy: 0.9982 - val_loss: 0.1309 - val_accuracy: 0.9712\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9973 - val_loss: 0.1275 - val_accuracy: 0.9716\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0281 - accuracy: 0.9982 - val_loss: 0.1280 - val_accuracy: 0.9720\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0268 - accuracy: 0.9988 - val_loss: 0.1279 - val_accuracy: 0.9720\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0259 - accuracy: 0.9991 - val_loss: 0.1278 - val_accuracy: 0.9732\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0246 - accuracy: 0.9994 - val_loss: 0.1259 - val_accuracy: 0.9734\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0239 - accuracy: 0.9994 - val_loss: 0.1273 - val_accuracy: 0.9720\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0229 - accuracy: 0.9994 - val_loss: 0.1259 - val_accuracy: 0.9726\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9994 - val_loss: 0.1263 - val_accuracy: 0.9724\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0208 - accuracy: 0.9994 - val_loss: 0.1270 - val_accuracy: 0.9724\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9997 - val_loss: 0.1285 - val_accuracy: 0.9722\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0201 - accuracy: 0.9994 - val_loss: 0.1250 - val_accuracy: 0.9726\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0192 - accuracy: 0.9994 - val_loss: 0.1264 - val_accuracy: 0.9734\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0182 - accuracy: 0.9997 - val_loss: 0.1250 - val_accuracy: 0.9732\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0175 - accuracy: 0.9997 - val_loss: 0.1260 - val_accuracy: 0.9730\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0174 - accuracy: 0.9994 - val_loss: 0.1263 - val_accuracy: 0.9730\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0166 - accuracy: 0.9994 - val_loss: 0.1269 - val_accuracy: 0.9732\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0158 - accuracy: 0.9997 - val_loss: 0.1301 - val_accuracy: 0.9726\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0154 - accuracy: 0.9997 - val_loss: 0.1267 - val_accuracy: 0.9726\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0148 - accuracy: 0.9997 - val_loss: 0.1275 - val_accuracy: 0.9722\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0144 - accuracy: 0.9997 - val_loss: 0.1277 - val_accuracy: 0.9726\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0138 - accuracy: 0.9997 - val_loss: 0.1269 - val_accuracy: 0.9732\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.3558 - accuracy: 0.9196\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 1.9940 - accuracy: 0.3843 - val_loss: 1.7281 - val_accuracy: 0.5848\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 1.5313 - accuracy: 0.6874 - val_loss: 1.3885 - val_accuracy: 0.7300\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.2542 - accuracy: 0.7774 - val_loss: 1.1760 - val_accuracy: 0.7814\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.0769 - accuracy: 0.8113 - val_loss: 1.0345 - val_accuracy: 0.8088\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.9553 - accuracy: 0.8332 - val_loss: 0.9344 - val_accuracy: 0.8206\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.8666 - accuracy: 0.8449 - val_loss: 0.8602 - val_accuracy: 0.8352\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7999 - accuracy: 0.8575 - val_loss: 0.8026 - val_accuracy: 0.8402\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7473 - accuracy: 0.8599 - val_loss: 0.7571 - val_accuracy: 0.8474\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7049 - accuracy: 0.8662 - val_loss: 0.7197 - val_accuracy: 0.8512\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.6697 - accuracy: 0.8689 - val_loss: 0.6885 - val_accuracy: 0.8542\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6401 - accuracy: 0.8722 - val_loss: 0.6618 - val_accuracy: 0.8604\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6146 - accuracy: 0.8773 - val_loss: 0.6388 - val_accuracy: 0.8612\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5923 - accuracy: 0.8806 - val_loss: 0.6190 - val_accuracy: 0.8628\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5729 - accuracy: 0.8812 - val_loss: 0.6012 - val_accuracy: 0.8634\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5560 - accuracy: 0.8842 - val_loss: 0.5856 - val_accuracy: 0.8670\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5407 - accuracy: 0.8848 - val_loss: 0.5715 - val_accuracy: 0.8682\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5264 - accuracy: 0.8857 - val_loss: 0.5587 - val_accuracy: 0.8704\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5141 - accuracy: 0.8893 - val_loss: 0.5474 - val_accuracy: 0.8726\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5027 - accuracy: 0.8911 - val_loss: 0.5368 - val_accuracy: 0.8742\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4920 - accuracy: 0.8911 - val_loss: 0.5271 - val_accuracy: 0.8756\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4825 - accuracy: 0.8926 - val_loss: 0.5183 - val_accuracy: 0.8762\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.8962 - val_loss: 0.5101 - val_accuracy: 0.8772\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4653 - accuracy: 0.8968 - val_loss: 0.5026 - val_accuracy: 0.8796\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4574 - accuracy: 0.8995 - val_loss: 0.4953 - val_accuracy: 0.8808\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4500 - accuracy: 0.8998 - val_loss: 0.4884 - val_accuracy: 0.8832\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4432 - accuracy: 0.9019 - val_loss: 0.4822 - val_accuracy: 0.8836\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4369 - accuracy: 0.9031 - val_loss: 0.4768 - val_accuracy: 0.8838\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4309 - accuracy: 0.9040 - val_loss: 0.4718 - val_accuracy: 0.8852\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4254 - accuracy: 0.9046 - val_loss: 0.4669 - val_accuracy: 0.8866\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4199 - accuracy: 0.9055 - val_loss: 0.4612 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.9061 - val_loss: 0.4562 - val_accuracy: 0.8874\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4098 - accuracy: 0.9070 - val_loss: 0.4517 - val_accuracy: 0.8884\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4051 - accuracy: 0.9070 - val_loss: 0.4477 - val_accuracy: 0.8894\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4007 - accuracy: 0.9082 - val_loss: 0.4436 - val_accuracy: 0.8902\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3965 - accuracy: 0.9085 - val_loss: 0.4398 - val_accuracy: 0.8910\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3924 - accuracy: 0.9097 - val_loss: 0.4363 - val_accuracy: 0.8926\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3885 - accuracy: 0.9094 - val_loss: 0.4327 - val_accuracy: 0.8928\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.9097 - val_loss: 0.4291 - val_accuracy: 0.8926\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3812 - accuracy: 0.9097 - val_loss: 0.4255 - val_accuracy: 0.8930\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3777 - accuracy: 0.9112 - val_loss: 0.4224 - val_accuracy: 0.8936\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3744 - accuracy: 0.9112 - val_loss: 0.4195 - val_accuracy: 0.8942\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3712 - accuracy: 0.9115 - val_loss: 0.4165 - val_accuracy: 0.8950\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3682 - accuracy: 0.9130 - val_loss: 0.4138 - val_accuracy: 0.8950\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3652 - accuracy: 0.9121 - val_loss: 0.4115 - val_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3623 - accuracy: 0.9139 - val_loss: 0.4086 - val_accuracy: 0.8954\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3595 - accuracy: 0.9142 - val_loss: 0.4062 - val_accuracy: 0.8960\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3569 - accuracy: 0.9136 - val_loss: 0.4035 - val_accuracy: 0.8968\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3544 - accuracy: 0.9151 - val_loss: 0.4013 - val_accuracy: 0.8970\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3518 - accuracy: 0.9145 - val_loss: 0.3992 - val_accuracy: 0.8984\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3494 - accuracy: 0.9163 - val_loss: 0.3969 - val_accuracy: 0.8976\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3472 - accuracy: 0.9163 - val_loss: 0.3949 - val_accuracy: 0.8996\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3448 - accuracy: 0.9175 - val_loss: 0.3930 - val_accuracy: 0.9004\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3425 - accuracy: 0.9190 - val_loss: 0.3912 - val_accuracy: 0.9022\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3403 - accuracy: 0.9196 - val_loss: 0.3892 - val_accuracy: 0.9016\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3381 - accuracy: 0.9187 - val_loss: 0.3871 - val_accuracy: 0.9018\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3360 - accuracy: 0.9211 - val_loss: 0.3850 - val_accuracy: 0.9014\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3341 - accuracy: 0.9205 - val_loss: 0.3832 - val_accuracy: 0.9018\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3320 - accuracy: 0.9205 - val_loss: 0.3816 - val_accuracy: 0.9012\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.9223 - val_loss: 0.3796 - val_accuracy: 0.9028\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3283 - accuracy: 0.9205 - val_loss: 0.3781 - val_accuracy: 0.9026\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3265 - accuracy: 0.9220 - val_loss: 0.3761 - val_accuracy: 0.9032\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3246 - accuracy: 0.9217 - val_loss: 0.3747 - val_accuracy: 0.9044\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3228 - accuracy: 0.9217 - val_loss: 0.3731 - val_accuracy: 0.9040\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.9238 - val_loss: 0.3716 - val_accuracy: 0.9050\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3195 - accuracy: 0.9244 - val_loss: 0.3701 - val_accuracy: 0.9052\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3179 - accuracy: 0.9250 - val_loss: 0.3688 - val_accuracy: 0.9056\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3162 - accuracy: 0.9247 - val_loss: 0.3678 - val_accuracy: 0.9032\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3148 - accuracy: 0.9235 - val_loss: 0.3660 - val_accuracy: 0.9054\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3132 - accuracy: 0.9235 - val_loss: 0.3647 - val_accuracy: 0.9056\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3116 - accuracy: 0.9253 - val_loss: 0.3633 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3102 - accuracy: 0.9259 - val_loss: 0.3620 - val_accuracy: 0.9068\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3087 - accuracy: 0.9262 - val_loss: 0.3608 - val_accuracy: 0.9066\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3073 - accuracy: 0.9259 - val_loss: 0.3597 - val_accuracy: 0.9070\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3060 - accuracy: 0.9271 - val_loss: 0.3584 - val_accuracy: 0.9072\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.9274 - val_loss: 0.3570 - val_accuracy: 0.9068\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3033 - accuracy: 0.9274 - val_loss: 0.3560 - val_accuracy: 0.9076\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3019 - accuracy: 0.9280 - val_loss: 0.3550 - val_accuracy: 0.9076\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3006 - accuracy: 0.9277 - val_loss: 0.3539 - val_accuracy: 0.9080\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2994 - accuracy: 0.9280 - val_loss: 0.3528 - val_accuracy: 0.9086\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2981 - accuracy: 0.9283 - val_loss: 0.3517 - val_accuracy: 0.9092\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2970 - accuracy: 0.9292 - val_loss: 0.3512 - val_accuracy: 0.9082\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2957 - accuracy: 0.9292 - val_loss: 0.3496 - val_accuracy: 0.9088\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2945 - accuracy: 0.9292 - val_loss: 0.3485 - val_accuracy: 0.9094\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2933 - accuracy: 0.9292 - val_loss: 0.3474 - val_accuracy: 0.9098\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2921 - accuracy: 0.9289 - val_loss: 0.3463 - val_accuracy: 0.9100\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2910 - accuracy: 0.9310 - val_loss: 0.3458 - val_accuracy: 0.9088\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2900 - accuracy: 0.9289 - val_loss: 0.3447 - val_accuracy: 0.9092\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2888 - accuracy: 0.9298 - val_loss: 0.3437 - val_accuracy: 0.9098\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2878 - accuracy: 0.9298 - val_loss: 0.3426 - val_accuracy: 0.9094\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2867 - accuracy: 0.9301 - val_loss: 0.3418 - val_accuracy: 0.9100\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2857 - accuracy: 0.9301 - val_loss: 0.3410 - val_accuracy: 0.9104\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2846 - accuracy: 0.9304 - val_loss: 0.3402 - val_accuracy: 0.9090\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2836 - accuracy: 0.9307 - val_loss: 0.3393 - val_accuracy: 0.9094\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2826 - accuracy: 0.9307 - val_loss: 0.3380 - val_accuracy: 0.9110\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2816 - accuracy: 0.9310 - val_loss: 0.3374 - val_accuracy: 0.9102\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2806 - accuracy: 0.9304 - val_loss: 0.3366 - val_accuracy: 0.9102\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2796 - accuracy: 0.9313 - val_loss: 0.3358 - val_accuracy: 0.9106\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2787 - accuracy: 0.9316 - val_loss: 0.3351 - val_accuracy: 0.9106\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2777 - accuracy: 0.9319 - val_loss: 0.3344 - val_accuracy: 0.9108\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2768 - accuracy: 0.9325 - val_loss: 0.3333 - val_accuracy: 0.9108\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8686\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 2.0350 - accuracy: 0.3654 - val_loss: 1.7630 - val_accuracy: 0.5800\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.5905 - accuracy: 0.6586 - val_loss: 1.4228 - val_accuracy: 0.7204\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3188 - accuracy: 0.7414 - val_loss: 1.2073 - val_accuracy: 0.7658\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1410 - accuracy: 0.7771 - val_loss: 1.0626 - val_accuracy: 0.7876\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 1.0197 - accuracy: 0.7972 - val_loss: 0.9596 - val_accuracy: 0.8014\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.9301 - accuracy: 0.8086 - val_loss: 0.8816 - val_accuracy: 0.8166\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.8619 - accuracy: 0.8218 - val_loss: 0.8224 - val_accuracy: 0.8254\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.8087 - accuracy: 0.8305 - val_loss: 0.7738 - val_accuracy: 0.8370\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7647 - accuracy: 0.8389 - val_loss: 0.7347 - val_accuracy: 0.8424\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.7286 - accuracy: 0.8428 - val_loss: 0.7018 - val_accuracy: 0.8496\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.8509 - val_loss: 0.6743 - val_accuracy: 0.8512\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6719 - accuracy: 0.8530 - val_loss: 0.6501 - val_accuracy: 0.8556\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6492 - accuracy: 0.8554 - val_loss: 0.6288 - val_accuracy: 0.8594\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.6293 - accuracy: 0.8611 - val_loss: 0.6105 - val_accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6116 - accuracy: 0.8623 - val_loss: 0.5941 - val_accuracy: 0.8666\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5954 - accuracy: 0.8662 - val_loss: 0.5794 - val_accuracy: 0.8682\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5812 - accuracy: 0.8686 - val_loss: 0.5658 - val_accuracy: 0.8720\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5682 - accuracy: 0.8710 - val_loss: 0.5537 - val_accuracy: 0.8760\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5563 - accuracy: 0.8761 - val_loss: 0.5428 - val_accuracy: 0.8778\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5454 - accuracy: 0.8776 - val_loss: 0.5321 - val_accuracy: 0.8782\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5353 - accuracy: 0.8779 - val_loss: 0.5229 - val_accuracy: 0.8788\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.8785 - val_loss: 0.5141 - val_accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5173 - accuracy: 0.8797 - val_loss: 0.5058 - val_accuracy: 0.8824\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5092 - accuracy: 0.8809 - val_loss: 0.4988 - val_accuracy: 0.8810\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5017 - accuracy: 0.8803 - val_loss: 0.4912 - val_accuracy: 0.8824\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4945 - accuracy: 0.8818 - val_loss: 0.4849 - val_accuracy: 0.8848\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4878 - accuracy: 0.8836 - val_loss: 0.4784 - val_accuracy: 0.8850\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4815 - accuracy: 0.8845 - val_loss: 0.4729 - val_accuracy: 0.8864\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4756 - accuracy: 0.8851 - val_loss: 0.4672 - val_accuracy: 0.8868\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4700 - accuracy: 0.8875 - val_loss: 0.4620 - val_accuracy: 0.8880\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4646 - accuracy: 0.8869 - val_loss: 0.4568 - val_accuracy: 0.8878\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4595 - accuracy: 0.8884 - val_loss: 0.4523 - val_accuracy: 0.8900\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4547 - accuracy: 0.8899 - val_loss: 0.4478 - val_accuracy: 0.8896\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4500 - accuracy: 0.8890 - val_loss: 0.4436 - val_accuracy: 0.8908\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4456 - accuracy: 0.8917 - val_loss: 0.4392 - val_accuracy: 0.8912\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4414 - accuracy: 0.8905 - val_loss: 0.4356 - val_accuracy: 0.8920\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4373 - accuracy: 0.8926 - val_loss: 0.4318 - val_accuracy: 0.8922\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.8932 - val_loss: 0.4281 - val_accuracy: 0.8936\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4296 - accuracy: 0.8959 - val_loss: 0.4247 - val_accuracy: 0.8944\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4260 - accuracy: 0.8959 - val_loss: 0.4216 - val_accuracy: 0.8954\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4226 - accuracy: 0.8971 - val_loss: 0.4183 - val_accuracy: 0.8964\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4192 - accuracy: 0.8989 - val_loss: 0.4151 - val_accuracy: 0.8972\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4159 - accuracy: 0.8977 - val_loss: 0.4122 - val_accuracy: 0.8984\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.9004 - val_loss: 0.4092 - val_accuracy: 0.8988\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4099 - accuracy: 0.9004 - val_loss: 0.4066 - val_accuracy: 0.8990\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4070 - accuracy: 0.9019 - val_loss: 0.4039 - val_accuracy: 0.8992\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4041 - accuracy: 0.9016 - val_loss: 0.4016 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4015 - accuracy: 0.9034 - val_loss: 0.3988 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3986 - accuracy: 0.9022 - val_loss: 0.3965 - val_accuracy: 0.9012\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3961 - accuracy: 0.9034 - val_loss: 0.3942 - val_accuracy: 0.9006\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3936 - accuracy: 0.9043 - val_loss: 0.3918 - val_accuracy: 0.9014\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3912 - accuracy: 0.9052 - val_loss: 0.3896 - val_accuracy: 0.9022\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3888 - accuracy: 0.9058 - val_loss: 0.3874 - val_accuracy: 0.9026\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3865 - accuracy: 0.9040 - val_loss: 0.3852 - val_accuracy: 0.9030\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3843 - accuracy: 0.9073 - val_loss: 0.3833 - val_accuracy: 0.9034\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3821 - accuracy: 0.9067 - val_loss: 0.3815 - val_accuracy: 0.9030\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3800 - accuracy: 0.9067 - val_loss: 0.3796 - val_accuracy: 0.9048\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3779 - accuracy: 0.9088 - val_loss: 0.3776 - val_accuracy: 0.9054\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.3759 - accuracy: 0.9094 - val_loss: 0.3759 - val_accuracy: 0.9056\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3738 - accuracy: 0.9082 - val_loss: 0.3740 - val_accuracy: 0.9068\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3719 - accuracy: 0.9106 - val_loss: 0.3723 - val_accuracy: 0.9064\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3700 - accuracy: 0.9115 - val_loss: 0.3708 - val_accuracy: 0.9060\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3682 - accuracy: 0.9106 - val_loss: 0.3689 - val_accuracy: 0.9076\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3664 - accuracy: 0.9118 - val_loss: 0.3674 - val_accuracy: 0.9078\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3646 - accuracy: 0.9133 - val_loss: 0.3658 - val_accuracy: 0.9088\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3628 - accuracy: 0.9112 - val_loss: 0.3643 - val_accuracy: 0.9086\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3611 - accuracy: 0.9130 - val_loss: 0.3627 - val_accuracy: 0.9092\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3594 - accuracy: 0.9124 - val_loss: 0.3617 - val_accuracy: 0.9100\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3579 - accuracy: 0.9130 - val_loss: 0.3598 - val_accuracy: 0.9104\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3562 - accuracy: 0.9151 - val_loss: 0.3584 - val_accuracy: 0.9104\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3546 - accuracy: 0.9145 - val_loss: 0.3572 - val_accuracy: 0.9096\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3532 - accuracy: 0.9148 - val_loss: 0.3557 - val_accuracy: 0.9112\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3517 - accuracy: 0.9154 - val_loss: 0.3544 - val_accuracy: 0.9112\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3500 - accuracy: 0.9148 - val_loss: 0.3534 - val_accuracy: 0.9108\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3487 - accuracy: 0.9145 - val_loss: 0.3518 - val_accuracy: 0.9120\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3473 - accuracy: 0.9175 - val_loss: 0.3507 - val_accuracy: 0.9120\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3459 - accuracy: 0.9163 - val_loss: 0.3495 - val_accuracy: 0.9122\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3445 - accuracy: 0.9160 - val_loss: 0.3481 - val_accuracy: 0.9122\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3431 - accuracy: 0.9163 - val_loss: 0.3471 - val_accuracy: 0.9124\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3418 - accuracy: 0.9166 - val_loss: 0.3458 - val_accuracy: 0.9126\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3404 - accuracy: 0.9169 - val_loss: 0.3447 - val_accuracy: 0.9128\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3392 - accuracy: 0.9166 - val_loss: 0.3436 - val_accuracy: 0.9132\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3379 - accuracy: 0.9169 - val_loss: 0.3426 - val_accuracy: 0.9138\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3367 - accuracy: 0.9175 - val_loss: 0.3415 - val_accuracy: 0.9132\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3355 - accuracy: 0.9178 - val_loss: 0.3405 - val_accuracy: 0.9144\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3343 - accuracy: 0.9190 - val_loss: 0.3396 - val_accuracy: 0.9136\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.9178 - val_loss: 0.3390 - val_accuracy: 0.9140\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3320 - accuracy: 0.9184 - val_loss: 0.3375 - val_accuracy: 0.9146\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3308 - accuracy: 0.9193 - val_loss: 0.3365 - val_accuracy: 0.9142\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3297 - accuracy: 0.9196 - val_loss: 0.3355 - val_accuracy: 0.9154\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3286 - accuracy: 0.9196 - val_loss: 0.3345 - val_accuracy: 0.9152\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3274 - accuracy: 0.9196 - val_loss: 0.3335 - val_accuracy: 0.9156\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3264 - accuracy: 0.9205 - val_loss: 0.3327 - val_accuracy: 0.9154\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.9193 - val_loss: 0.3317 - val_accuracy: 0.9158\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3242 - accuracy: 0.9205 - val_loss: 0.3309 - val_accuracy: 0.9168\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3232 - accuracy: 0.9220 - val_loss: 0.3300 - val_accuracy: 0.9160\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3222 - accuracy: 0.9220 - val_loss: 0.3291 - val_accuracy: 0.9164\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3212 - accuracy: 0.9208 - val_loss: 0.3283 - val_accuracy: 0.9162\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3202 - accuracy: 0.9223 - val_loss: 0.3275 - val_accuracy: 0.9170\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3192 - accuracy: 0.9208 - val_loss: 0.3265 - val_accuracy: 0.9172\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.9076\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 2.0752 - accuracy: 0.3263 - val_loss: 1.7830 - val_accuracy: 0.5580\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.5949 - accuracy: 0.6422 - val_loss: 1.4306 - val_accuracy: 0.7036\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3103 - accuracy: 0.7430 - val_loss: 1.2083 - val_accuracy: 0.7566\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.1270 - accuracy: 0.7762 - val_loss: 1.0621 - val_accuracy: 0.7798\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 1.0018 - accuracy: 0.7945 - val_loss: 0.9580 - val_accuracy: 0.7986\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.9118 - accuracy: 0.8068 - val_loss: 0.8819 - val_accuracy: 0.8110\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.8436 - accuracy: 0.8140 - val_loss: 0.8227 - val_accuracy: 0.8206\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7901 - accuracy: 0.8227 - val_loss: 0.7762 - val_accuracy: 0.8288\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7471 - accuracy: 0.8341 - val_loss: 0.7373 - val_accuracy: 0.8368\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7115 - accuracy: 0.8416 - val_loss: 0.7050 - val_accuracy: 0.8404\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6814 - accuracy: 0.8458 - val_loss: 0.6780 - val_accuracy: 0.8448\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6558 - accuracy: 0.8500 - val_loss: 0.6545 - val_accuracy: 0.8508\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6333 - accuracy: 0.8554 - val_loss: 0.6338 - val_accuracy: 0.8534\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6138 - accuracy: 0.8596 - val_loss: 0.6158 - val_accuracy: 0.8582\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5965 - accuracy: 0.8626 - val_loss: 0.5999 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5809 - accuracy: 0.8635 - val_loss: 0.5852 - val_accuracy: 0.8622\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5670 - accuracy: 0.8695 - val_loss: 0.5716 - val_accuracy: 0.8636\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5543 - accuracy: 0.8677 - val_loss: 0.5598 - val_accuracy: 0.8662\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5427 - accuracy: 0.8704 - val_loss: 0.5491 - val_accuracy: 0.8690\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5321 - accuracy: 0.8746 - val_loss: 0.5389 - val_accuracy: 0.8684\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5224 - accuracy: 0.8740 - val_loss: 0.5295 - val_accuracy: 0.8708\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5134 - accuracy: 0.8770 - val_loss: 0.5212 - val_accuracy: 0.8716\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5049 - accuracy: 0.8782 - val_loss: 0.5130 - val_accuracy: 0.8728\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.8767 - val_loss: 0.5060 - val_accuracy: 0.8762\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4898 - accuracy: 0.8818 - val_loss: 0.4989 - val_accuracy: 0.8778\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4829 - accuracy: 0.8821 - val_loss: 0.4924 - val_accuracy: 0.8786\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4765 - accuracy: 0.8830 - val_loss: 0.4861 - val_accuracy: 0.8802\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4705 - accuracy: 0.8863 - val_loss: 0.4803 - val_accuracy: 0.8804\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4645 - accuracy: 0.8863 - val_loss: 0.4746 - val_accuracy: 0.8820\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4591 - accuracy: 0.8890 - val_loss: 0.4694 - val_accuracy: 0.8830\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4538 - accuracy: 0.8902 - val_loss: 0.4644 - val_accuracy: 0.8832\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.4489 - accuracy: 0.8902 - val_loss: 0.4599 - val_accuracy: 0.8844\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4442 - accuracy: 0.8908 - val_loss: 0.4559 - val_accuracy: 0.8846\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4398 - accuracy: 0.8911 - val_loss: 0.4513 - val_accuracy: 0.8858\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8932 - val_loss: 0.4470 - val_accuracy: 0.8862\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.8932 - val_loss: 0.4433 - val_accuracy: 0.8864\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8941 - val_loss: 0.4396 - val_accuracy: 0.8882\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8965 - val_loss: 0.4357 - val_accuracy: 0.8880\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4199 - accuracy: 0.8965 - val_loss: 0.4323 - val_accuracy: 0.8892\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8962 - val_loss: 0.4291 - val_accuracy: 0.8904\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4131 - accuracy: 0.8989 - val_loss: 0.4259 - val_accuracy: 0.8910\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8986 - val_loss: 0.4229 - val_accuracy: 0.8918\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.9004 - val_loss: 0.4200 - val_accuracy: 0.8920\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4037 - accuracy: 0.9004 - val_loss: 0.4171 - val_accuracy: 0.8928\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.9007 - val_loss: 0.4144 - val_accuracy: 0.8930\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3979 - accuracy: 0.9013 - val_loss: 0.4117 - val_accuracy: 0.8930\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.9013 - val_loss: 0.4092 - val_accuracy: 0.8944\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.9010 - val_loss: 0.4065 - val_accuracy: 0.8950\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3900 - accuracy: 0.9022 - val_loss: 0.4040 - val_accuracy: 0.8958\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.9031 - val_loss: 0.4020 - val_accuracy: 0.8966\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3851 - accuracy: 0.9034 - val_loss: 0.3999 - val_accuracy: 0.8966\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3827 - accuracy: 0.9043 - val_loss: 0.3974 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3804 - accuracy: 0.9046 - val_loss: 0.3952 - val_accuracy: 0.8966\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3782 - accuracy: 0.9049 - val_loss: 0.3932 - val_accuracy: 0.8974\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.9046 - val_loss: 0.3909 - val_accuracy: 0.8984\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3738 - accuracy: 0.9055 - val_loss: 0.3889 - val_accuracy: 0.8988\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.9052 - val_loss: 0.3870 - val_accuracy: 0.8992\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.9058 - val_loss: 0.3851 - val_accuracy: 0.8990\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.9064 - val_loss: 0.3836 - val_accuracy: 0.9004\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.9073 - val_loss: 0.3817 - val_accuracy: 0.9004\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3639 - accuracy: 0.9079 - val_loss: 0.3800 - val_accuracy: 0.9002\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.9064 - val_loss: 0.3781 - val_accuracy: 0.9008\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.9079 - val_loss: 0.3767 - val_accuracy: 0.9006\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3586 - accuracy: 0.9082 - val_loss: 0.3749 - val_accuracy: 0.9016\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.9097 - val_loss: 0.3736 - val_accuracy: 0.9008\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3553 - accuracy: 0.9094 - val_loss: 0.3718 - val_accuracy: 0.9026\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.9106 - val_loss: 0.3703 - val_accuracy: 0.9026\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.9100 - val_loss: 0.3688 - val_accuracy: 0.9032\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3505 - accuracy: 0.9124 - val_loss: 0.3674 - val_accuracy: 0.9042\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.9121 - val_loss: 0.3659 - val_accuracy: 0.9044\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.9124 - val_loss: 0.3645 - val_accuracy: 0.9044\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3459 - accuracy: 0.9118 - val_loss: 0.3631 - val_accuracy: 0.9050\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.9130 - val_loss: 0.3618 - val_accuracy: 0.9048\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.9127 - val_loss: 0.3606 - val_accuracy: 0.9054\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3416 - accuracy: 0.9139 - val_loss: 0.3593 - val_accuracy: 0.9052\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.9136 - val_loss: 0.3581 - val_accuracy: 0.9056\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.9133 - val_loss: 0.3568 - val_accuracy: 0.9056\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3375 - accuracy: 0.9145 - val_loss: 0.3556 - val_accuracy: 0.9064\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.9142 - val_loss: 0.3543 - val_accuracy: 0.9070\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.9148 - val_loss: 0.3531 - val_accuracy: 0.9074\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3337 - accuracy: 0.9166 - val_loss: 0.3522 - val_accuracy: 0.9076\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.9142 - val_loss: 0.3509 - val_accuracy: 0.9086\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3313 - accuracy: 0.9157 - val_loss: 0.3497 - val_accuracy: 0.9076\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.9151 - val_loss: 0.3486 - val_accuracy: 0.9078\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.3287 - accuracy: 0.9163 - val_loss: 0.3475 - val_accuracy: 0.9078\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3275 - accuracy: 0.9163 - val_loss: 0.3467 - val_accuracy: 0.9076\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3264 - accuracy: 0.9151 - val_loss: 0.3455 - val_accuracy: 0.9088\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3252 - accuracy: 0.9160 - val_loss: 0.3446 - val_accuracy: 0.9086\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.9160 - val_loss: 0.3435 - val_accuracy: 0.9084\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3230 - accuracy: 0.9166 - val_loss: 0.3426 - val_accuracy: 0.9088\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.9172 - val_loss: 0.3416 - val_accuracy: 0.9094\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3209 - accuracy: 0.9178 - val_loss: 0.3407 - val_accuracy: 0.9094\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.9169 - val_loss: 0.3399 - val_accuracy: 0.9096\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3188 - accuracy: 0.9184 - val_loss: 0.3390 - val_accuracy: 0.9106\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.9190 - val_loss: 0.3379 - val_accuracy: 0.9104\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9187 - val_loss: 0.3370 - val_accuracy: 0.9106\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3156 - accuracy: 0.9196 - val_loss: 0.3362 - val_accuracy: 0.9106\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.9187 - val_loss: 0.3352 - val_accuracy: 0.9108\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3138 - accuracy: 0.9190 - val_loss: 0.3345 - val_accuracy: 0.9110\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.9199 - val_loss: 0.3335 - val_accuracy: 0.9106\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8926\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 10ms/step - loss: 2.2778 - accuracy: 0.1428 - val_loss: 2.2273 - val_accuracy: 0.1988\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 2.1684 - accuracy: 0.2667 - val_loss: 2.1196 - val_accuracy: 0.3244\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 2.0495 - accuracy: 0.3894 - val_loss: 1.9927 - val_accuracy: 0.4432\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.9075 - accuracy: 0.5056 - val_loss: 1.8407 - val_accuracy: 0.5478\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 1.7417 - accuracy: 0.5986 - val_loss: 1.6672 - val_accuracy: 0.6284\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.5585 - accuracy: 0.6637 - val_loss: 1.4841 - val_accuracy: 0.6886\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.3759 - accuracy: 0.7192 - val_loss: 1.3112 - val_accuracy: 0.7246\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.2101 - accuracy: 0.7570 - val_loss: 1.1599 - val_accuracy: 0.7536\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 1.0685 - accuracy: 0.7876 - val_loss: 1.0357 - val_accuracy: 0.7814\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.9531 - accuracy: 0.8095 - val_loss: 0.9327 - val_accuracy: 0.8022\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.8593 - accuracy: 0.8245 - val_loss: 0.8500 - val_accuracy: 0.8196\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.7839 - accuracy: 0.8407 - val_loss: 0.7836 - val_accuracy: 0.8232\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7226 - accuracy: 0.8452 - val_loss: 0.7296 - val_accuracy: 0.8340\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6727 - accuracy: 0.8536 - val_loss: 0.6862 - val_accuracy: 0.8414\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6305 - accuracy: 0.8623 - val_loss: 0.6483 - val_accuracy: 0.8488\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5951 - accuracy: 0.8659 - val_loss: 0.6173 - val_accuracy: 0.8528\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5646 - accuracy: 0.8698 - val_loss: 0.5887 - val_accuracy: 0.8582\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.8773 - val_loss: 0.5655 - val_accuracy: 0.8628\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5151 - accuracy: 0.8791 - val_loss: 0.5459 - val_accuracy: 0.8638\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4938 - accuracy: 0.8851 - val_loss: 0.5255 - val_accuracy: 0.8686\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4757 - accuracy: 0.8851 - val_loss: 0.5098 - val_accuracy: 0.8732\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.8893 - val_loss: 0.4946 - val_accuracy: 0.8724\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4435 - accuracy: 0.8890 - val_loss: 0.4795 - val_accuracy: 0.8796\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4301 - accuracy: 0.8935 - val_loss: 0.4663 - val_accuracy: 0.8826\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4168 - accuracy: 0.8962 - val_loss: 0.4560 - val_accuracy: 0.8830\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8977 - val_loss: 0.4468 - val_accuracy: 0.8844\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3955 - accuracy: 0.9010 - val_loss: 0.4354 - val_accuracy: 0.8870\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3849 - accuracy: 0.9052 - val_loss: 0.4277 - val_accuracy: 0.8886\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3759 - accuracy: 0.9052 - val_loss: 0.4191 - val_accuracy: 0.8896\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3673 - accuracy: 0.9061 - val_loss: 0.4131 - val_accuracy: 0.8924\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3592 - accuracy: 0.9076 - val_loss: 0.4048 - val_accuracy: 0.8932\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3515 - accuracy: 0.9109 - val_loss: 0.3970 - val_accuracy: 0.8962\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3439 - accuracy: 0.9127 - val_loss: 0.3910 - val_accuracy: 0.8966\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.9148 - val_loss: 0.3853 - val_accuracy: 0.8976\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3314 - accuracy: 0.9160 - val_loss: 0.3791 - val_accuracy: 0.8986\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3252 - accuracy: 0.9175 - val_loss: 0.3745 - val_accuracy: 0.8996\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3188 - accuracy: 0.9181 - val_loss: 0.3690 - val_accuracy: 0.9024\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3136 - accuracy: 0.9151 - val_loss: 0.3633 - val_accuracy: 0.9050\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3085 - accuracy: 0.9190 - val_loss: 0.3599 - val_accuracy: 0.9042\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.9217 - val_loss: 0.3535 - val_accuracy: 0.9042\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2987 - accuracy: 0.9223 - val_loss: 0.3496 - val_accuracy: 0.9056\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2936 - accuracy: 0.9241 - val_loss: 0.3482 - val_accuracy: 0.9048\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2893 - accuracy: 0.9232 - val_loss: 0.3419 - val_accuracy: 0.9082\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2855 - accuracy: 0.9244 - val_loss: 0.3395 - val_accuracy: 0.9072\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2812 - accuracy: 0.9259 - val_loss: 0.3371 - val_accuracy: 0.9090\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 8s 70ms/step - loss: 0.2775 - accuracy: 0.9277 - val_loss: 0.3311 - val_accuracy: 0.9112\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 3s 26ms/step - loss: 0.2729 - accuracy: 0.9295 - val_loss: 0.3296 - val_accuracy: 0.9094\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2697 - accuracy: 0.9280 - val_loss: 0.3256 - val_accuracy: 0.9108\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2657 - accuracy: 0.9295 - val_loss: 0.3210 - val_accuracy: 0.9114\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2622 - accuracy: 0.9316 - val_loss: 0.3209 - val_accuracy: 0.9152\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2594 - accuracy: 0.9331 - val_loss: 0.3181 - val_accuracy: 0.9124\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2560 - accuracy: 0.9310 - val_loss: 0.3151 - val_accuracy: 0.9140\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2528 - accuracy: 0.9331 - val_loss: 0.3135 - val_accuracy: 0.9136\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2495 - accuracy: 0.9337 - val_loss: 0.3083 - val_accuracy: 0.9160\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2466 - accuracy: 0.9352 - val_loss: 0.3054 - val_accuracy: 0.9158\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2432 - accuracy: 0.9382 - val_loss: 0.3038 - val_accuracy: 0.9162\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2404 - accuracy: 0.9385 - val_loss: 0.3004 - val_accuracy: 0.9176\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2377 - accuracy: 0.9397 - val_loss: 0.2994 - val_accuracy: 0.9178\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2349 - accuracy: 0.9397 - val_loss: 0.2988 - val_accuracy: 0.9174\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2328 - accuracy: 0.9388 - val_loss: 0.2986 - val_accuracy: 0.9164\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2303 - accuracy: 0.9379 - val_loss: 0.2930 - val_accuracy: 0.9200\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9415 - val_loss: 0.2912 - val_accuracy: 0.9210\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2252 - accuracy: 0.9409 - val_loss: 0.2886 - val_accuracy: 0.9200\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9403 - val_loss: 0.2868 - val_accuracy: 0.9208\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2201 - accuracy: 0.9427 - val_loss: 0.2845 - val_accuracy: 0.9214\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2179 - accuracy: 0.9430 - val_loss: 0.2858 - val_accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2160 - accuracy: 0.9430 - val_loss: 0.2825 - val_accuracy: 0.9218\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2133 - accuracy: 0.9436 - val_loss: 0.2781 - val_accuracy: 0.9234\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2110 - accuracy: 0.9460 - val_loss: 0.2768 - val_accuracy: 0.9228\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2093 - accuracy: 0.9436 - val_loss: 0.2757 - val_accuracy: 0.9238\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9469 - val_loss: 0.2740 - val_accuracy: 0.9250\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2046 - accuracy: 0.9451 - val_loss: 0.2715 - val_accuracy: 0.9254\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9460 - val_loss: 0.2704 - val_accuracy: 0.9266\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2010 - accuracy: 0.9481 - val_loss: 0.2687 - val_accuracy: 0.9272\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1986 - accuracy: 0.9472 - val_loss: 0.2659 - val_accuracy: 0.9276\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1971 - accuracy: 0.9481 - val_loss: 0.2659 - val_accuracy: 0.9286\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1950 - accuracy: 0.9490 - val_loss: 0.2642 - val_accuracy: 0.9274\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1931 - accuracy: 0.9508 - val_loss: 0.2622 - val_accuracy: 0.9282\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1917 - accuracy: 0.9511 - val_loss: 0.2606 - val_accuracy: 0.9292\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1893 - accuracy: 0.9520 - val_loss: 0.2693 - val_accuracy: 0.9236\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1892 - accuracy: 0.9517 - val_loss: 0.2590 - val_accuracy: 0.9290\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1864 - accuracy: 0.9541 - val_loss: 0.2572 - val_accuracy: 0.9306\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1845 - accuracy: 0.9544 - val_loss: 0.2558 - val_accuracy: 0.9318\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1827 - accuracy: 0.9550 - val_loss: 0.2551 - val_accuracy: 0.9306\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1816 - accuracy: 0.9553 - val_loss: 0.2553 - val_accuracy: 0.9316\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1795 - accuracy: 0.9565 - val_loss: 0.2534 - val_accuracy: 0.9308\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1782 - accuracy: 0.9559 - val_loss: 0.2507 - val_accuracy: 0.9322\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1762 - accuracy: 0.9574 - val_loss: 0.2503 - val_accuracy: 0.9332\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1747 - accuracy: 0.9586 - val_loss: 0.2497 - val_accuracy: 0.9318\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1734 - accuracy: 0.9577 - val_loss: 0.2470 - val_accuracy: 0.9318\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1718 - accuracy: 0.9577 - val_loss: 0.2459 - val_accuracy: 0.9344\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1704 - accuracy: 0.9592 - val_loss: 0.2451 - val_accuracy: 0.9344\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1691 - accuracy: 0.9580 - val_loss: 0.2444 - val_accuracy: 0.9320\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1679 - accuracy: 0.9583 - val_loss: 0.2424 - val_accuracy: 0.9336\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1657 - accuracy: 0.9598 - val_loss: 0.2422 - val_accuracy: 0.9350\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1645 - accuracy: 0.9589 - val_loss: 0.2401 - val_accuracy: 0.9356\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1633 - accuracy: 0.9601 - val_loss: 0.2393 - val_accuracy: 0.9362\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1621 - accuracy: 0.9610 - val_loss: 0.2381 - val_accuracy: 0.9360\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.1607 - accuracy: 0.9613 - val_loss: 0.2368 - val_accuracy: 0.9368\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1594 - accuracy: 0.9619 - val_loss: 0.2377 - val_accuracy: 0.9350\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8812\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 10ms/step - loss: 2.3103 - accuracy: 0.0984 - val_loss: 2.2128 - val_accuracy: 0.1726\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 2.1407 - accuracy: 0.2643 - val_loss: 2.0610 - val_accuracy: 0.3484\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.9917 - accuracy: 0.4392 - val_loss: 1.9086 - val_accuracy: 0.5070\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1804s 16s/step - loss: 1.8382 - accuracy: 0.5410 - val_loss: 1.7528 - val_accuracy: 0.5838\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 3s 26ms/step - loss: 1.6819 - accuracy: 0.6136 - val_loss: 1.5957 - val_accuracy: 0.6380\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 3s 23ms/step - loss: 1.5255 - accuracy: 0.6631 - val_loss: 1.4394 - val_accuracy: 0.6872\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 3s 26ms/step - loss: 1.3725 - accuracy: 0.6985 - val_loss: 1.2896 - val_accuracy: 0.7290\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 2s 21ms/step - loss: 1.2298 - accuracy: 0.7348 - val_loss: 1.1527 - val_accuracy: 0.7596\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 4s 36ms/step - loss: 1.1034 - accuracy: 0.7630 - val_loss: 1.0359 - val_accuracy: 0.7758\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 2s 21ms/step - loss: 0.9967 - accuracy: 0.7762 - val_loss: 0.9394 - val_accuracy: 0.7974\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 0.9082 - accuracy: 0.7969 - val_loss: 0.8595 - val_accuracy: 0.8060\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.8360 - accuracy: 0.8083 - val_loss: 0.7969 - val_accuracy: 0.8130\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.8239 - val_loss: 0.7399 - val_accuracy: 0.8282\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 0.7260 - accuracy: 0.8344 - val_loss: 0.6936 - val_accuracy: 0.8374\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6832 - accuracy: 0.8395 - val_loss: 0.6551 - val_accuracy: 0.8424\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 0.6467 - accuracy: 0.8464 - val_loss: 0.6220 - val_accuracy: 0.8460\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.6159 - accuracy: 0.8491 - val_loss: 0.5938 - val_accuracy: 0.8530\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 2s 22ms/step - loss: 0.5877 - accuracy: 0.8563 - val_loss: 0.5673 - val_accuracy: 0.8568\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.5638 - accuracy: 0.8587 - val_loss: 0.5452 - val_accuracy: 0.8630\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.5419 - accuracy: 0.8638 - val_loss: 0.5251 - val_accuracy: 0.8660\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5226 - accuracy: 0.8689 - val_loss: 0.5101 - val_accuracy: 0.8680\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.5053 - accuracy: 0.8713 - val_loss: 0.4906 - val_accuracy: 0.8732\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.4892 - accuracy: 0.8764 - val_loss: 0.4777 - val_accuracy: 0.8760\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4747 - accuracy: 0.8800 - val_loss: 0.4619 - val_accuracy: 0.8812\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4609 - accuracy: 0.8815 - val_loss: 0.4509 - val_accuracy: 0.8824\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4491 - accuracy: 0.8848 - val_loss: 0.4394 - val_accuracy: 0.8860\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 2s 18ms/step - loss: 0.4377 - accuracy: 0.8875 - val_loss: 0.4296 - val_accuracy: 0.8884\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.4274 - accuracy: 0.8899 - val_loss: 0.4192 - val_accuracy: 0.8936\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4170 - accuracy: 0.8914 - val_loss: 0.4100 - val_accuracy: 0.8930\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4077 - accuracy: 0.8944 - val_loss: 0.4028 - val_accuracy: 0.8954\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3988 - accuracy: 0.8947 - val_loss: 0.3931 - val_accuracy: 0.8976\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3906 - accuracy: 0.8974 - val_loss: 0.3872 - val_accuracy: 0.8990\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3826 - accuracy: 0.8986 - val_loss: 0.3926 - val_accuracy: 0.8952\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3774 - accuracy: 0.9025 - val_loss: 0.3724 - val_accuracy: 0.9034\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3690 - accuracy: 0.9037 - val_loss: 0.3657 - val_accuracy: 0.9066\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3625 - accuracy: 0.9052 - val_loss: 0.3610 - val_accuracy: 0.9064\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3561 - accuracy: 0.9097 - val_loss: 0.3559 - val_accuracy: 0.9090\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3506 - accuracy: 0.9121 - val_loss: 0.3519 - val_accuracy: 0.9094\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.3450 - accuracy: 0.9112 - val_loss: 0.3450 - val_accuracy: 0.9102\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3393 - accuracy: 0.9124 - val_loss: 0.3396 - val_accuracy: 0.9120\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3339 - accuracy: 0.9139 - val_loss: 0.3394 - val_accuracy: 0.9104\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3290 - accuracy: 0.9133 - val_loss: 0.3309 - val_accuracy: 0.9154\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.9178 - val_loss: 0.3283 - val_accuracy: 0.9160\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3194 - accuracy: 0.9190 - val_loss: 0.3215 - val_accuracy: 0.9162\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.3151 - accuracy: 0.9181 - val_loss: 0.3182 - val_accuracy: 0.9200\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3110 - accuracy: 0.9199 - val_loss: 0.3236 - val_accuracy: 0.9178\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3076 - accuracy: 0.9229 - val_loss: 0.3108 - val_accuracy: 0.9198\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.3030 - accuracy: 0.9229 - val_loss: 0.3103 - val_accuracy: 0.9186\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2993 - accuracy: 0.9217 - val_loss: 0.3035 - val_accuracy: 0.9202\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.2952 - accuracy: 0.9232 - val_loss: 0.3005 - val_accuracy: 0.9212\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 2s 18ms/step - loss: 0.2919 - accuracy: 0.9250 - val_loss: 0.2985 - val_accuracy: 0.9216\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2887 - accuracy: 0.9250 - val_loss: 0.2961 - val_accuracy: 0.9192\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 2s 22ms/step - loss: 0.2856 - accuracy: 0.9235 - val_loss: 0.2936 - val_accuracy: 0.9220\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 3s 24ms/step - loss: 0.2818 - accuracy: 0.9247 - val_loss: 0.2941 - val_accuracy: 0.9230\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 3s 26ms/step - loss: 0.2791 - accuracy: 0.9265 - val_loss: 0.2874 - val_accuracy: 0.9250\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 3s 25ms/step - loss: 0.2756 - accuracy: 0.9271 - val_loss: 0.2840 - val_accuracy: 0.9254\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 0.2724 - accuracy: 0.9298 - val_loss: 0.2838 - val_accuracy: 0.9274\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.2699 - accuracy: 0.9292 - val_loss: 0.2814 - val_accuracy: 0.9234\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2675 - accuracy: 0.9295 - val_loss: 0.2777 - val_accuracy: 0.9272\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 2s 17ms/step - loss: 0.2638 - accuracy: 0.9319 - val_loss: 0.2754 - val_accuracy: 0.9274\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2614 - accuracy: 0.9313 - val_loss: 0.2725 - val_accuracy: 0.9286\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2589 - accuracy: 0.9340 - val_loss: 0.2768 - val_accuracy: 0.9274\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2569 - accuracy: 0.9322 - val_loss: 0.2693 - val_accuracy: 0.9302\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2543 - accuracy: 0.9355 - val_loss: 0.2678 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 0.2511 - accuracy: 0.9346 - val_loss: 0.2659 - val_accuracy: 0.9312\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2491 - accuracy: 0.9373 - val_loss: 0.2634 - val_accuracy: 0.9322\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2465 - accuracy: 0.9367 - val_loss: 0.2636 - val_accuracy: 0.9298\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 2s 16ms/step - loss: 0.2451 - accuracy: 0.9355 - val_loss: 0.2584 - val_accuracy: 0.9328\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2423 - accuracy: 0.9373 - val_loss: 0.2574 - val_accuracy: 0.9330\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2399 - accuracy: 0.9391 - val_loss: 0.2548 - val_accuracy: 0.9332\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2379 - accuracy: 0.9385 - val_loss: 0.2534 - val_accuracy: 0.9334\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2356 - accuracy: 0.9394 - val_loss: 0.2558 - val_accuracy: 0.9308\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2342 - accuracy: 0.9388 - val_loss: 0.2502 - val_accuracy: 0.9336\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2319 - accuracy: 0.9403 - val_loss: 0.2483 - val_accuracy: 0.9358\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2297 - accuracy: 0.9418 - val_loss: 0.2469 - val_accuracy: 0.9352\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.2272 - accuracy: 0.9403 - val_loss: 0.2469 - val_accuracy: 0.9356\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2255 - accuracy: 0.9406 - val_loss: 0.2472 - val_accuracy: 0.9338\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 0.2234 - accuracy: 0.9427 - val_loss: 0.2445 - val_accuracy: 0.9348\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 0.2219 - accuracy: 0.9418 - val_loss: 0.2416 - val_accuracy: 0.9378\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 2s 17ms/step - loss: 0.2200 - accuracy: 0.9418 - val_loss: 0.2404 - val_accuracy: 0.9374\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2185 - accuracy: 0.9415 - val_loss: 0.2378 - val_accuracy: 0.9380\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2162 - accuracy: 0.9448 - val_loss: 0.2378 - val_accuracy: 0.9382\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.2150 - accuracy: 0.9457 - val_loss: 0.2352 - val_accuracy: 0.9390\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 3s 27ms/step - loss: 0.2130 - accuracy: 0.9442 - val_loss: 0.2334 - val_accuracy: 0.9400\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 4s 38ms/step - loss: 0.2116 - accuracy: 0.9454 - val_loss: 0.2367 - val_accuracy: 0.9360\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 0.2104 - accuracy: 0.9457 - val_loss: 0.2322 - val_accuracy: 0.9396\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2081 - accuracy: 0.9487 - val_loss: 0.2295 - val_accuracy: 0.9402\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2066 - accuracy: 0.9469 - val_loss: 0.2287 - val_accuracy: 0.9404\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 0.2048 - accuracy: 0.9463 - val_loss: 0.2277 - val_accuracy: 0.9416\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2037 - accuracy: 0.9478 - val_loss: 0.2288 - val_accuracy: 0.9394\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2019 - accuracy: 0.9481 - val_loss: 0.2264 - val_accuracy: 0.9416\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.2002 - accuracy: 0.9487 - val_loss: 0.2239 - val_accuracy: 0.9414\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.1984 - accuracy: 0.9511 - val_loss: 0.2246 - val_accuracy: 0.9430\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.1972 - accuracy: 0.9514 - val_loss: 0.2215 - val_accuracy: 0.9430\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.1958 - accuracy: 0.9499 - val_loss: 0.2224 - val_accuracy: 0.9434\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.1944 - accuracy: 0.9502 - val_loss: 0.2192 - val_accuracy: 0.9440\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.1924 - accuracy: 0.9508 - val_loss: 0.2184 - val_accuracy: 0.9440\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1910 - accuracy: 0.9508 - val_loss: 0.2169 - val_accuracy: 0.9434\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1899 - accuracy: 0.9526 - val_loss: 0.2170 - val_accuracy: 0.9434\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.1885 - accuracy: 0.9523 - val_loss: 0.2169 - val_accuracy: 0.9442\n",
      "56/56 [==============================] - 1s 6ms/step - loss: 0.2788 - accuracy: 0.9256\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 2.2644 - accuracy: 0.1998 - val_loss: 2.2000 - val_accuracy: 0.2844\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 2.1317 - accuracy: 0.3524 - val_loss: 2.0652 - val_accuracy: 0.3950\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 1.9831 - accuracy: 0.4562 - val_loss: 1.9069 - val_accuracy: 0.4976\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.8135 - accuracy: 0.5405 - val_loss: 1.7306 - val_accuracy: 0.5816\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.6324 - accuracy: 0.6236 - val_loss: 1.5512 - val_accuracy: 0.6354\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 1.4560 - accuracy: 0.6725 - val_loss: 1.3807 - val_accuracy: 0.6790\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.2937 - accuracy: 0.7127 - val_loss: 1.2282 - val_accuracy: 0.7180\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.1504 - accuracy: 0.7442 - val_loss: 1.0979 - val_accuracy: 0.7562\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 1.0297 - accuracy: 0.7744 - val_loss: 0.9868 - val_accuracy: 0.7808\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.9283 - accuracy: 0.7948 - val_loss: 0.8962 - val_accuracy: 0.7956\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.8450 - accuracy: 0.8140 - val_loss: 0.8195 - val_accuracy: 0.8110\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7763 - accuracy: 0.8236 - val_loss: 0.7591 - val_accuracy: 0.8170\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7196 - accuracy: 0.8341 - val_loss: 0.7084 - val_accuracy: 0.8242\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.6727 - accuracy: 0.8392 - val_loss: 0.6636 - val_accuracy: 0.8362\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6319 - accuracy: 0.8497 - val_loss: 0.6278 - val_accuracy: 0.8436\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5984 - accuracy: 0.8554 - val_loss: 0.5964 - val_accuracy: 0.8496\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5692 - accuracy: 0.8611 - val_loss: 0.5698 - val_accuracy: 0.8572\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5440 - accuracy: 0.8680 - val_loss: 0.5452 - val_accuracy: 0.8628\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5213 - accuracy: 0.8722 - val_loss: 0.5244 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.5009 - accuracy: 0.8779 - val_loss: 0.5067 - val_accuracy: 0.8700\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4834 - accuracy: 0.8785 - val_loss: 0.4895 - val_accuracy: 0.8746\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4675 - accuracy: 0.8851 - val_loss: 0.4734 - val_accuracy: 0.8794\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4530 - accuracy: 0.8857 - val_loss: 0.4603 - val_accuracy: 0.8842\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.4396 - accuracy: 0.8908 - val_loss: 0.4488 - val_accuracy: 0.8878\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4283 - accuracy: 0.8926 - val_loss: 0.4365 - val_accuracy: 0.8890\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4166 - accuracy: 0.8941 - val_loss: 0.4277 - val_accuracy: 0.8912\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.8983 - val_loss: 0.4192 - val_accuracy: 0.8892\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3980 - accuracy: 0.8989 - val_loss: 0.4116 - val_accuracy: 0.8926\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3899 - accuracy: 0.8989 - val_loss: 0.4008 - val_accuracy: 0.8952\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3805 - accuracy: 0.9004 - val_loss: 0.3957 - val_accuracy: 0.8968\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3731 - accuracy: 0.9043 - val_loss: 0.3864 - val_accuracy: 0.8976\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3660 - accuracy: 0.9052 - val_loss: 0.3805 - val_accuracy: 0.8976\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3598 - accuracy: 0.9052 - val_loss: 0.3755 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3536 - accuracy: 0.9076 - val_loss: 0.3674 - val_accuracy: 0.9022\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3472 - accuracy: 0.9097 - val_loss: 0.3627 - val_accuracy: 0.9026\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3410 - accuracy: 0.9106 - val_loss: 0.3579 - val_accuracy: 0.9038\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.3359 - accuracy: 0.9094 - val_loss: 0.3514 - val_accuracy: 0.9062\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3304 - accuracy: 0.9124 - val_loss: 0.3476 - val_accuracy: 0.9064\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3256 - accuracy: 0.9157 - val_loss: 0.3430 - val_accuracy: 0.9078\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3211 - accuracy: 0.9166 - val_loss: 0.3397 - val_accuracy: 0.9080\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3163 - accuracy: 0.9163 - val_loss: 0.3342 - val_accuracy: 0.9104\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3127 - accuracy: 0.9181 - val_loss: 0.3302 - val_accuracy: 0.9094\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3081 - accuracy: 0.9175 - val_loss: 0.3265 - val_accuracy: 0.9116\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3033 - accuracy: 0.9199 - val_loss: 0.3261 - val_accuracy: 0.9112\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3006 - accuracy: 0.9196 - val_loss: 0.3190 - val_accuracy: 0.9142\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2968 - accuracy: 0.9205 - val_loss: 0.3165 - val_accuracy: 0.9162\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2925 - accuracy: 0.9226 - val_loss: 0.3145 - val_accuracy: 0.9164\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2896 - accuracy: 0.9241 - val_loss: 0.3105 - val_accuracy: 0.9158\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2861 - accuracy: 0.9247 - val_loss: 0.3076 - val_accuracy: 0.9186\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2828 - accuracy: 0.9259 - val_loss: 0.3045 - val_accuracy: 0.9198\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2798 - accuracy: 0.9265 - val_loss: 0.3024 - val_accuracy: 0.9188\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2765 - accuracy: 0.9250 - val_loss: 0.2988 - val_accuracy: 0.9190\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2738 - accuracy: 0.9271 - val_loss: 0.2969 - val_accuracy: 0.9200\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2704 - accuracy: 0.9286 - val_loss: 0.2938 - val_accuracy: 0.9180\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2682 - accuracy: 0.9280 - val_loss: 0.2930 - val_accuracy: 0.9196\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2653 - accuracy: 0.9286 - val_loss: 0.2887 - val_accuracy: 0.9208\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2621 - accuracy: 0.9313 - val_loss: 0.2866 - val_accuracy: 0.9210\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2600 - accuracy: 0.9304 - val_loss: 0.2838 - val_accuracy: 0.9232\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2569 - accuracy: 0.9310 - val_loss: 0.2828 - val_accuracy: 0.9224\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2543 - accuracy: 0.9316 - val_loss: 0.2823 - val_accuracy: 0.9218\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2526 - accuracy: 0.9328 - val_loss: 0.2782 - val_accuracy: 0.9256\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2500 - accuracy: 0.9334 - val_loss: 0.2755 - val_accuracy: 0.9262\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2473 - accuracy: 0.9358 - val_loss: 0.2742 - val_accuracy: 0.9270\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2449 - accuracy: 0.9352 - val_loss: 0.2725 - val_accuracy: 0.9258\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2424 - accuracy: 0.9373 - val_loss: 0.2695 - val_accuracy: 0.9264\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2406 - accuracy: 0.9364 - val_loss: 0.2691 - val_accuracy: 0.9288\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2383 - accuracy: 0.9367 - val_loss: 0.2664 - val_accuracy: 0.9282\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2361 - accuracy: 0.9388 - val_loss: 0.2642 - val_accuracy: 0.9288\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2338 - accuracy: 0.9376 - val_loss: 0.2629 - val_accuracy: 0.9294\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2320 - accuracy: 0.9394 - val_loss: 0.2611 - val_accuracy: 0.9298\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2301 - accuracy: 0.9397 - val_loss: 0.2616 - val_accuracy: 0.9272\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2282 - accuracy: 0.9403 - val_loss: 0.2581 - val_accuracy: 0.9304\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2260 - accuracy: 0.9391 - val_loss: 0.2566 - val_accuracy: 0.9312\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2240 - accuracy: 0.9415 - val_loss: 0.2546 - val_accuracy: 0.9312\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2222 - accuracy: 0.9409 - val_loss: 0.2540 - val_accuracy: 0.9324\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2202 - accuracy: 0.9442 - val_loss: 0.2515 - val_accuracy: 0.9314\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2184 - accuracy: 0.9430 - val_loss: 0.2509 - val_accuracy: 0.9328\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2163 - accuracy: 0.9418 - val_loss: 0.2541 - val_accuracy: 0.9314\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.2159 - accuracy: 0.9457 - val_loss: 0.2474 - val_accuracy: 0.9342\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2131 - accuracy: 0.9457 - val_loss: 0.2456 - val_accuracy: 0.9334\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2111 - accuracy: 0.9451 - val_loss: 0.2459 - val_accuracy: 0.9332\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2096 - accuracy: 0.9466 - val_loss: 0.2447 - val_accuracy: 0.9328\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 0.2079 - accuracy: 0.9463 - val_loss: 0.2448 - val_accuracy: 0.9338\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.2064 - accuracy: 0.9445 - val_loss: 0.2403 - val_accuracy: 0.9352\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2045 - accuracy: 0.9466 - val_loss: 0.2435 - val_accuracy: 0.9360\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2040 - accuracy: 0.9463 - val_loss: 0.2379 - val_accuracy: 0.9350\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2014 - accuracy: 0.9472 - val_loss: 0.2427 - val_accuracy: 0.9352\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.2006 - accuracy: 0.9481 - val_loss: 0.2359 - val_accuracy: 0.9348\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.1982 - accuracy: 0.9463 - val_loss: 0.2342 - val_accuracy: 0.9364\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1968 - accuracy: 0.9490 - val_loss: 0.2329 - val_accuracy: 0.9368\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1951 - accuracy: 0.9487 - val_loss: 0.2329 - val_accuracy: 0.9370\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1936 - accuracy: 0.9481 - val_loss: 0.2313 - val_accuracy: 0.9380\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.1922 - accuracy: 0.9505 - val_loss: 0.2295 - val_accuracy: 0.9374\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1910 - accuracy: 0.9502 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1894 - accuracy: 0.9502 - val_loss: 0.2280 - val_accuracy: 0.9380\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1874 - accuracy: 0.9514 - val_loss: 0.2267 - val_accuracy: 0.9388\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.1865 - accuracy: 0.9508 - val_loss: 0.2251 - val_accuracy: 0.9398\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1852 - accuracy: 0.9508 - val_loss: 0.2245 - val_accuracy: 0.9384\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1835 - accuracy: 0.9505 - val_loss: 0.2246 - val_accuracy: 0.9404\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1824 - accuracy: 0.9538 - val_loss: 0.2278 - val_accuracy: 0.9390\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.9100\n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 4s 9ms/step - loss: 2.0676 - accuracy: 0.3093 - val_loss: 1.7894 - val_accuracy: 0.5262\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.4500 - accuracy: 0.6616 - val_loss: 1.1646 - val_accuracy: 0.7346\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.9496 - accuracy: 0.7831 - val_loss: 0.8166 - val_accuracy: 0.8100\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.6970 - accuracy: 0.8323 - val_loss: 0.6551 - val_accuracy: 0.8306\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.5642 - accuracy: 0.8593 - val_loss: 0.5512 - val_accuracy: 0.8610\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.4815 - accuracy: 0.8830 - val_loss: 0.4881 - val_accuracy: 0.8728\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4271 - accuracy: 0.8920 - val_loss: 0.4453 - val_accuracy: 0.8826\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3870 - accuracy: 0.9055 - val_loss: 0.4124 - val_accuracy: 0.8904\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3548 - accuracy: 0.9100 - val_loss: 0.3880 - val_accuracy: 0.8968\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.3308 - accuracy: 0.9148 - val_loss: 0.3712 - val_accuracy: 0.8982\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3100 - accuracy: 0.9184 - val_loss: 0.3524 - val_accuracy: 0.9044\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2933 - accuracy: 0.9244 - val_loss: 0.3377 - val_accuracy: 0.9080\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2796 - accuracy: 0.9259 - val_loss: 0.3277 - val_accuracy: 0.9092\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.2661 - accuracy: 0.9310 - val_loss: 0.3116 - val_accuracy: 0.9146\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2539 - accuracy: 0.9340 - val_loss: 0.3013 - val_accuracy: 0.9196\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2447 - accuracy: 0.9361 - val_loss: 0.2968 - val_accuracy: 0.9194\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2345 - accuracy: 0.9412 - val_loss: 0.2920 - val_accuracy: 0.9188\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2273 - accuracy: 0.9409 - val_loss: 0.2803 - val_accuracy: 0.9254\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2180 - accuracy: 0.9424 - val_loss: 0.2778 - val_accuracy: 0.9246\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2110 - accuracy: 0.9445 - val_loss: 0.2694 - val_accuracy: 0.9276\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2045 - accuracy: 0.9439 - val_loss: 0.2646 - val_accuracy: 0.9286\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1981 - accuracy: 0.9484 - val_loss: 0.2606 - val_accuracy: 0.9284\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1919 - accuracy: 0.9496 - val_loss: 0.2573 - val_accuracy: 0.9304\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1868 - accuracy: 0.9523 - val_loss: 0.2534 - val_accuracy: 0.9326\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1807 - accuracy: 0.9493 - val_loss: 0.2502 - val_accuracy: 0.9332\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1765 - accuracy: 0.9556 - val_loss: 0.2423 - val_accuracy: 0.9354\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1716 - accuracy: 0.9556 - val_loss: 0.2402 - val_accuracy: 0.9342\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1661 - accuracy: 0.9559 - val_loss: 0.2350 - val_accuracy: 0.9380\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1622 - accuracy: 0.9592 - val_loss: 0.2305 - val_accuracy: 0.9380\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1580 - accuracy: 0.9595 - val_loss: 0.2303 - val_accuracy: 0.9382\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1520 - accuracy: 0.9613 - val_loss: 0.2267 - val_accuracy: 0.9378\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1494 - accuracy: 0.9628 - val_loss: 0.2324 - val_accuracy: 0.9366\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.1455 - accuracy: 0.9643 - val_loss: 0.2209 - val_accuracy: 0.9408\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1408 - accuracy: 0.9640 - val_loss: 0.2174 - val_accuracy: 0.9432\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1379 - accuracy: 0.9634 - val_loss: 0.2188 - val_accuracy: 0.9428\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1351 - accuracy: 0.9670 - val_loss: 0.2121 - val_accuracy: 0.9446\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1316 - accuracy: 0.9676 - val_loss: 0.2131 - val_accuracy: 0.9410\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1271 - accuracy: 0.9682 - val_loss: 0.2127 - val_accuracy: 0.9430\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1239 - accuracy: 0.9703 - val_loss: 0.2211 - val_accuracy: 0.9380\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1222 - accuracy: 0.9703 - val_loss: 0.2090 - val_accuracy: 0.9442\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1193 - accuracy: 0.9706 - val_loss: 0.2060 - val_accuracy: 0.9472\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1160 - accuracy: 0.9748 - val_loss: 0.1995 - val_accuracy: 0.9476\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1131 - accuracy: 0.9724 - val_loss: 0.1993 - val_accuracy: 0.9480\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1102 - accuracy: 0.9754 - val_loss: 0.1998 - val_accuracy: 0.9476\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.1072 - accuracy: 0.9748 - val_loss: 0.1951 - val_accuracy: 0.9496\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.1045 - accuracy: 0.9766 - val_loss: 0.1967 - val_accuracy: 0.9480\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1027 - accuracy: 0.9763 - val_loss: 0.1944 - val_accuracy: 0.9502\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1003 - accuracy: 0.9778 - val_loss: 0.1910 - val_accuracy: 0.9518\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0972 - accuracy: 0.9802 - val_loss: 0.1933 - val_accuracy: 0.9496\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0953 - accuracy: 0.9781 - val_loss: 0.1886 - val_accuracy: 0.9526\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0931 - accuracy: 0.9799 - val_loss: 0.1869 - val_accuracy: 0.9542\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0907 - accuracy: 0.9820 - val_loss: 0.1874 - val_accuracy: 0.9542\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0883 - accuracy: 0.9829 - val_loss: 0.1834 - val_accuracy: 0.9536\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.0861 - accuracy: 0.9838 - val_loss: 0.1838 - val_accuracy: 0.9550\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0838 - accuracy: 0.9838 - val_loss: 0.1850 - val_accuracy: 0.9540\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0823 - accuracy: 0.9838 - val_loss: 0.1805 - val_accuracy: 0.9548\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0801 - accuracy: 0.9850 - val_loss: 0.1820 - val_accuracy: 0.9550\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0776 - accuracy: 0.9847 - val_loss: 0.1787 - val_accuracy: 0.9574\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0760 - accuracy: 0.9865 - val_loss: 0.1791 - val_accuracy: 0.9556\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0738 - accuracy: 0.9859 - val_loss: 0.1776 - val_accuracy: 0.9566\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0719 - accuracy: 0.9856 - val_loss: 0.1760 - val_accuracy: 0.9566\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0701 - accuracy: 0.9871 - val_loss: 0.1743 - val_accuracy: 0.9576\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0682 - accuracy: 0.9874 - val_loss: 0.1743 - val_accuracy: 0.9576\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0664 - accuracy: 0.9886 - val_loss: 0.1717 - val_accuracy: 0.9580\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0655 - accuracy: 0.9868 - val_loss: 0.1751 - val_accuracy: 0.9584\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0640 - accuracy: 0.9883 - val_loss: 0.1718 - val_accuracy: 0.9592\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0620 - accuracy: 0.9892 - val_loss: 0.1728 - val_accuracy: 0.9600\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0607 - accuracy: 0.9901 - val_loss: 0.1705 - val_accuracy: 0.9588\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0588 - accuracy: 0.9907 - val_loss: 0.1705 - val_accuracy: 0.9604\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0577 - accuracy: 0.9904 - val_loss: 0.1696 - val_accuracy: 0.9596\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0565 - accuracy: 0.9907 - val_loss: 0.1668 - val_accuracy: 0.9606\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0545 - accuracy: 0.9913 - val_loss: 0.1680 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0534 - accuracy: 0.9916 - val_loss: 0.1672 - val_accuracy: 0.9606\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0519 - accuracy: 0.9913 - val_loss: 0.1659 - val_accuracy: 0.9612\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0509 - accuracy: 0.9922 - val_loss: 0.1657 - val_accuracy: 0.9618\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0495 - accuracy: 0.9931 - val_loss: 0.1653 - val_accuracy: 0.9614\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0482 - accuracy: 0.9934 - val_loss: 0.1628 - val_accuracy: 0.9616\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0468 - accuracy: 0.9928 - val_loss: 0.1648 - val_accuracy: 0.9614\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0459 - accuracy: 0.9934 - val_loss: 0.1629 - val_accuracy: 0.9624\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0444 - accuracy: 0.9937 - val_loss: 0.1642 - val_accuracy: 0.9616\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0437 - accuracy: 0.9943 - val_loss: 0.1620 - val_accuracy: 0.9618\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0427 - accuracy: 0.9931 - val_loss: 0.1610 - val_accuracy: 0.9618\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0415 - accuracy: 0.9940 - val_loss: 0.1610 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0402 - accuracy: 0.9943 - val_loss: 0.1654 - val_accuracy: 0.9624\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0392 - accuracy: 0.9949 - val_loss: 0.1602 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0383 - accuracy: 0.9946 - val_loss: 0.1607 - val_accuracy: 0.9638\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0374 - accuracy: 0.9949 - val_loss: 0.1645 - val_accuracy: 0.9628\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0366 - accuracy: 0.9961 - val_loss: 0.1619 - val_accuracy: 0.9626\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0359 - accuracy: 0.9955 - val_loss: 0.1604 - val_accuracy: 0.9646\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0345 - accuracy: 0.9958 - val_loss: 0.1591 - val_accuracy: 0.9656\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0341 - accuracy: 0.9970 - val_loss: 0.1597 - val_accuracy: 0.9640\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0331 - accuracy: 0.9961 - val_loss: 0.1590 - val_accuracy: 0.9652\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0324 - accuracy: 0.9973 - val_loss: 0.1595 - val_accuracy: 0.9646\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0316 - accuracy: 0.9970 - val_loss: 0.1586 - val_accuracy: 0.9652\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0307 - accuracy: 0.9976 - val_loss: 0.1583 - val_accuracy: 0.9654\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0299 - accuracy: 0.9976 - val_loss: 0.1613 - val_accuracy: 0.9648\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0297 - accuracy: 0.9976 - val_loss: 0.1582 - val_accuracy: 0.9658\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0286 - accuracy: 0.9979 - val_loss: 0.1576 - val_accuracy: 0.9658\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0280 - accuracy: 0.9991 - val_loss: 0.1591 - val_accuracy: 0.9654\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0275 - accuracy: 0.9985 - val_loss: 0.1591 - val_accuracy: 0.9660\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.4262 - accuracy: 0.9004\n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 6s 15ms/step - loss: 2.1803 - accuracy: 0.2838 - val_loss: 1.9609 - val_accuracy: 0.5044\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.6838 - accuracy: 0.6109 - val_loss: 1.3757 - val_accuracy: 0.7040\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.1500 - accuracy: 0.7570 - val_loss: 0.9311 - val_accuracy: 0.8088\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.8149 - accuracy: 0.8158 - val_loss: 0.6925 - val_accuracy: 0.8340\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.6355 - accuracy: 0.8467 - val_loss: 0.5679 - val_accuracy: 0.8616\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.5346 - accuracy: 0.8671 - val_loss: 0.4861 - val_accuracy: 0.8776\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.4701 - accuracy: 0.8818 - val_loss: 0.4381 - val_accuracy: 0.8896\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.4237 - accuracy: 0.8929 - val_loss: 0.4006 - val_accuracy: 0.8932\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3898 - accuracy: 0.8974 - val_loss: 0.3725 - val_accuracy: 0.9028\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3634 - accuracy: 0.9067 - val_loss: 0.3717 - val_accuracy: 0.8986\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3425 - accuracy: 0.9094 - val_loss: 0.3302 - val_accuracy: 0.9132\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3243 - accuracy: 0.9166 - val_loss: 0.3148 - val_accuracy: 0.9166\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3095 - accuracy: 0.9199 - val_loss: 0.3034 - val_accuracy: 0.9194\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2964 - accuracy: 0.9214 - val_loss: 0.2968 - val_accuracy: 0.9228\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2844 - accuracy: 0.9250 - val_loss: 0.2827 - val_accuracy: 0.9242\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2740 - accuracy: 0.9292 - val_loss: 0.2763 - val_accuracy: 0.9288\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2636 - accuracy: 0.9325 - val_loss: 0.2740 - val_accuracy: 0.9258\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2556 - accuracy: 0.9316 - val_loss: 0.2602 - val_accuracy: 0.9324\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2465 - accuracy: 0.9391 - val_loss: 0.2554 - val_accuracy: 0.9322\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2386 - accuracy: 0.9394 - val_loss: 0.2496 - val_accuracy: 0.9352\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2319 - accuracy: 0.9436 - val_loss: 0.2430 - val_accuracy: 0.9368\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2255 - accuracy: 0.9451 - val_loss: 0.2349 - val_accuracy: 0.9414\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2177 - accuracy: 0.9460 - val_loss: 0.2306 - val_accuracy: 0.9428\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2111 - accuracy: 0.9487 - val_loss: 0.2277 - val_accuracy: 0.9410\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.2051 - accuracy: 0.9499 - val_loss: 0.2290 - val_accuracy: 0.9414\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.1989 - accuracy: 0.9508 - val_loss: 0.2181 - val_accuracy: 0.9454\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1931 - accuracy: 0.9523 - val_loss: 0.2309 - val_accuracy: 0.9406\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1892 - accuracy: 0.9550 - val_loss: 0.2084 - val_accuracy: 0.9466\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1831 - accuracy: 0.9535 - val_loss: 0.2101 - val_accuracy: 0.9452\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1778 - accuracy: 0.9559 - val_loss: 0.2048 - val_accuracy: 0.9458\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1742 - accuracy: 0.9565 - val_loss: 0.1980 - val_accuracy: 0.9492\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1690 - accuracy: 0.9610 - val_loss: 0.1999 - val_accuracy: 0.9474\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1640 - accuracy: 0.9583 - val_loss: 0.1933 - val_accuracy: 0.9514\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1616 - accuracy: 0.9592 - val_loss: 0.1893 - val_accuracy: 0.9500\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1569 - accuracy: 0.9616 - val_loss: 0.1878 - val_accuracy: 0.9516\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1521 - accuracy: 0.9628 - val_loss: 0.1871 - val_accuracy: 0.9498\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1481 - accuracy: 0.9628 - val_loss: 0.1827 - val_accuracy: 0.9530\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1446 - accuracy: 0.9652 - val_loss: 0.1778 - val_accuracy: 0.9538\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1408 - accuracy: 0.9649 - val_loss: 0.1764 - val_accuracy: 0.9546\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1373 - accuracy: 0.9649 - val_loss: 0.1721 - val_accuracy: 0.9560\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1327 - accuracy: 0.9688 - val_loss: 0.1716 - val_accuracy: 0.9538\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1301 - accuracy: 0.9673 - val_loss: 0.1740 - val_accuracy: 0.9536\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1273 - accuracy: 0.9700 - val_loss: 0.1701 - val_accuracy: 0.9538\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1229 - accuracy: 0.9700 - val_loss: 0.1640 - val_accuracy: 0.9576\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1191 - accuracy: 0.9703 - val_loss: 0.1628 - val_accuracy: 0.9564\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1168 - accuracy: 0.9715 - val_loss: 0.1602 - val_accuracy: 0.9574\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1134 - accuracy: 0.9742 - val_loss: 0.1578 - val_accuracy: 0.9576\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1102 - accuracy: 0.9751 - val_loss: 0.1574 - val_accuracy: 0.9586\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1073 - accuracy: 0.9742 - val_loss: 0.1561 - val_accuracy: 0.9596\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1047 - accuracy: 0.9754 - val_loss: 0.1515 - val_accuracy: 0.9590\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.1024 - accuracy: 0.9751 - val_loss: 0.1531 - val_accuracy: 0.9616\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0991 - accuracy: 0.9763 - val_loss: 0.1497 - val_accuracy: 0.9610\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0967 - accuracy: 0.9787 - val_loss: 0.1476 - val_accuracy: 0.9612\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0948 - accuracy: 0.9793 - val_loss: 0.1459 - val_accuracy: 0.9624\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0920 - accuracy: 0.9784 - val_loss: 0.1445 - val_accuracy: 0.9628\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0896 - accuracy: 0.9790 - val_loss: 0.1434 - val_accuracy: 0.9628\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0871 - accuracy: 0.9826 - val_loss: 0.1421 - val_accuracy: 0.9638\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0852 - accuracy: 0.9820 - val_loss: 0.1432 - val_accuracy: 0.9632\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0832 - accuracy: 0.9817 - val_loss: 0.1424 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0810 - accuracy: 0.9841 - val_loss: 0.1377 - val_accuracy: 0.9652\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0787 - accuracy: 0.9847 - val_loss: 0.1348 - val_accuracy: 0.9666\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0761 - accuracy: 0.9850 - val_loss: 0.1353 - val_accuracy: 0.9662\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0743 - accuracy: 0.9847 - val_loss: 0.1353 - val_accuracy: 0.9668\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0722 - accuracy: 0.9859 - val_loss: 0.1346 - val_accuracy: 0.9678\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0707 - accuracy: 0.9865 - val_loss: 0.1319 - val_accuracy: 0.9678\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0690 - accuracy: 0.9871 - val_loss: 0.1321 - val_accuracy: 0.9672\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0675 - accuracy: 0.9877 - val_loss: 0.1317 - val_accuracy: 0.9670\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0653 - accuracy: 0.9889 - val_loss: 0.1298 - val_accuracy: 0.9682\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0635 - accuracy: 0.9883 - val_loss: 0.1285 - val_accuracy: 0.9684\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0622 - accuracy: 0.9889 - val_loss: 0.1284 - val_accuracy: 0.9696\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0603 - accuracy: 0.9892 - val_loss: 0.1266 - val_accuracy: 0.9696\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0583 - accuracy: 0.9913 - val_loss: 0.1243 - val_accuracy: 0.9696\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0572 - accuracy: 0.9898 - val_loss: 0.1252 - val_accuracy: 0.9704\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0558 - accuracy: 0.9910 - val_loss: 0.1270 - val_accuracy: 0.9700\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0543 - accuracy: 0.9913 - val_loss: 0.1232 - val_accuracy: 0.9702\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0529 - accuracy: 0.9916 - val_loss: 0.1220 - val_accuracy: 0.9716\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0519 - accuracy: 0.9934 - val_loss: 0.1214 - val_accuracy: 0.9700\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0503 - accuracy: 0.9925 - val_loss: 0.1246 - val_accuracy: 0.9704\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0491 - accuracy: 0.9934 - val_loss: 0.1213 - val_accuracy: 0.9714\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0484 - accuracy: 0.9934 - val_loss: 0.1211 - val_accuracy: 0.9714\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0465 - accuracy: 0.9934 - val_loss: 0.1196 - val_accuracy: 0.9730\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0457 - accuracy: 0.9946 - val_loss: 0.1185 - val_accuracy: 0.9726\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0441 - accuracy: 0.9940 - val_loss: 0.1182 - val_accuracy: 0.9726\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0436 - accuracy: 0.9943 - val_loss: 0.1189 - val_accuracy: 0.9722\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0422 - accuracy: 0.9958 - val_loss: 0.1183 - val_accuracy: 0.9740\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0418 - accuracy: 0.9952 - val_loss: 0.1165 - val_accuracy: 0.9726\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0408 - accuracy: 0.9952 - val_loss: 0.1181 - val_accuracy: 0.9726\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0397 - accuracy: 0.9961 - val_loss: 0.1194 - val_accuracy: 0.9712\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0388 - accuracy: 0.9964 - val_loss: 0.1169 - val_accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0379 - accuracy: 0.9955 - val_loss: 0.1172 - val_accuracy: 0.9734\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0366 - accuracy: 0.9958 - val_loss: 0.1167 - val_accuracy: 0.9720\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0362 - accuracy: 0.9967 - val_loss: 0.1150 - val_accuracy: 0.9726\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0353 - accuracy: 0.9961 - val_loss: 0.1151 - val_accuracy: 0.9716\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0346 - accuracy: 0.9967 - val_loss: 0.1159 - val_accuracy: 0.9738\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0337 - accuracy: 0.9976 - val_loss: 0.1133 - val_accuracy: 0.9730\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0327 - accuracy: 0.9976 - val_loss: 0.1162 - val_accuracy: 0.9736\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0322 - accuracy: 0.9973 - val_loss: 0.1133 - val_accuracy: 0.9738\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9976 - val_loss: 0.1139 - val_accuracy: 0.9730\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0306 - accuracy: 0.9982 - val_loss: 0.1139 - val_accuracy: 0.9736\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0302 - accuracy: 0.9976 - val_loss: 0.1144 - val_accuracy: 0.9726\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2843 - accuracy: 0.9238\n",
      "Epoch 1/100\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 2.0964 - accuracy: 0.3647 - val_loss: 1.8075 - val_accuracy: 0.5410\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 1.4979 - accuracy: 0.6485 - val_loss: 1.2139 - val_accuracy: 0.7256\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 1.0061 - accuracy: 0.7840 - val_loss: 0.8456 - val_accuracy: 0.8100\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.7412 - accuracy: 0.8275 - val_loss: 0.6589 - val_accuracy: 0.8386\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.6018 - accuracy: 0.8503 - val_loss: 0.5527 - val_accuracy: 0.8636\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.5165 - accuracy: 0.8698 - val_loss: 0.4872 - val_accuracy: 0.8740\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.4595 - accuracy: 0.8845 - val_loss: 0.4427 - val_accuracy: 0.8810\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.4196 - accuracy: 0.8878 - val_loss: 0.4067 - val_accuracy: 0.8902\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.3880 - accuracy: 0.8956 - val_loss: 0.3798 - val_accuracy: 0.8996\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3617 - accuracy: 0.9037 - val_loss: 0.3613 - val_accuracy: 0.9006\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3414 - accuracy: 0.9070 - val_loss: 0.3430 - val_accuracy: 0.9092\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3245 - accuracy: 0.9127 - val_loss: 0.3298 - val_accuracy: 0.9128\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3077 - accuracy: 0.9151 - val_loss: 0.3233 - val_accuracy: 0.9124\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2966 - accuracy: 0.9178 - val_loss: 0.3033 - val_accuracy: 0.9168\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.2846 - accuracy: 0.9208 - val_loss: 0.2998 - val_accuracy: 0.9166\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2745 - accuracy: 0.9220 - val_loss: 0.2876 - val_accuracy: 0.9226\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.2648 - accuracy: 0.9250 - val_loss: 0.2790 - val_accuracy: 0.9242\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2545 - accuracy: 0.9295 - val_loss: 0.2739 - val_accuracy: 0.9244\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2470 - accuracy: 0.9325 - val_loss: 0.2645 - val_accuracy: 0.9252\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2388 - accuracy: 0.9343 - val_loss: 0.2556 - val_accuracy: 0.9296\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.2304 - accuracy: 0.9376 - val_loss: 0.2510 - val_accuracy: 0.9318\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.2241 - accuracy: 0.9385 - val_loss: 0.2522 - val_accuracy: 0.9302\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2175 - accuracy: 0.9418 - val_loss: 0.2408 - val_accuracy: 0.9346\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.2107 - accuracy: 0.9433 - val_loss: 0.2352 - val_accuracy: 0.9368\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2039 - accuracy: 0.9463 - val_loss: 0.2287 - val_accuracy: 0.9386\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1975 - accuracy: 0.9487 - val_loss: 0.2269 - val_accuracy: 0.9382\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.1931 - accuracy: 0.9469 - val_loss: 0.2238 - val_accuracy: 0.9384\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1882 - accuracy: 0.9505 - val_loss: 0.2193 - val_accuracy: 0.9414\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1830 - accuracy: 0.9502 - val_loss: 0.2152 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1763 - accuracy: 0.9547 - val_loss: 0.2112 - val_accuracy: 0.9422\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1721 - accuracy: 0.9544 - val_loss: 0.2120 - val_accuracy: 0.9406\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.1684 - accuracy: 0.9553 - val_loss: 0.2029 - val_accuracy: 0.9454\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1631 - accuracy: 0.9562 - val_loss: 0.2034 - val_accuracy: 0.9454\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.1587 - accuracy: 0.9574 - val_loss: 0.1990 - val_accuracy: 0.9474\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1546 - accuracy: 0.9586 - val_loss: 0.1974 - val_accuracy: 0.9486\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.1508 - accuracy: 0.9601 - val_loss: 0.1917 - val_accuracy: 0.9478\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1477 - accuracy: 0.9607 - val_loss: 0.1884 - val_accuracy: 0.9496\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1427 - accuracy: 0.9628 - val_loss: 0.1894 - val_accuracy: 0.9498\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1395 - accuracy: 0.9649 - val_loss: 0.1835 - val_accuracy: 0.9518\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1362 - accuracy: 0.9655 - val_loss: 0.1817 - val_accuracy: 0.9540\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.1332 - accuracy: 0.9670 - val_loss: 0.1789 - val_accuracy: 0.9540\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1293 - accuracy: 0.9691 - val_loss: 0.1787 - val_accuracy: 0.9546\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1254 - accuracy: 0.9676 - val_loss: 0.1745 - val_accuracy: 0.9558\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1231 - accuracy: 0.9691 - val_loss: 0.1717 - val_accuracy: 0.9566\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1207 - accuracy: 0.9703 - val_loss: 0.1693 - val_accuracy: 0.9560\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.1167 - accuracy: 0.9724 - val_loss: 0.1680 - val_accuracy: 0.9576\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1147 - accuracy: 0.9724 - val_loss: 0.1654 - val_accuracy: 0.9590\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.1107 - accuracy: 0.9742 - val_loss: 0.1639 - val_accuracy: 0.9590\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1081 - accuracy: 0.9730 - val_loss: 0.1628 - val_accuracy: 0.9598\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1059 - accuracy: 0.9745 - val_loss: 0.1615 - val_accuracy: 0.9586\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1036 - accuracy: 0.9760 - val_loss: 0.1597 - val_accuracy: 0.9592\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.1003 - accuracy: 0.9769 - val_loss: 0.1584 - val_accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0991 - accuracy: 0.9766 - val_loss: 0.1557 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0958 - accuracy: 0.9802 - val_loss: 0.1574 - val_accuracy: 0.9614\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.1557 - val_accuracy: 0.9618\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0916 - accuracy: 0.9808 - val_loss: 0.1521 - val_accuracy: 0.9638\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0897 - accuracy: 0.9820 - val_loss: 0.1508 - val_accuracy: 0.9646\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0873 - accuracy: 0.9829 - val_loss: 0.1519 - val_accuracy: 0.9646\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0853 - accuracy: 0.9829 - val_loss: 0.1485 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 7s 22ms/step - loss: 0.0828 - accuracy: 0.9859 - val_loss: 0.1469 - val_accuracy: 0.9654\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0811 - accuracy: 0.9856 - val_loss: 0.1470 - val_accuracy: 0.9654\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0794 - accuracy: 0.9847 - val_loss: 0.1446 - val_accuracy: 0.9658\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0770 - accuracy: 0.9865 - val_loss: 0.1437 - val_accuracy: 0.9654\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0755 - accuracy: 0.9874 - val_loss: 0.1436 - val_accuracy: 0.9668\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0736 - accuracy: 0.9874 - val_loss: 0.1412 - val_accuracy: 0.9674\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0717 - accuracy: 0.9883 - val_loss: 0.1416 - val_accuracy: 0.9664\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0698 - accuracy: 0.9871 - val_loss: 0.1426 - val_accuracy: 0.9660\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0677 - accuracy: 0.9868 - val_loss: 0.1434 - val_accuracy: 0.9676\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0666 - accuracy: 0.9892 - val_loss: 0.1412 - val_accuracy: 0.9670\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0648 - accuracy: 0.9892 - val_loss: 0.1388 - val_accuracy: 0.9672\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0633 - accuracy: 0.9892 - val_loss: 0.1366 - val_accuracy: 0.9692\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0616 - accuracy: 0.9904 - val_loss: 0.1375 - val_accuracy: 0.9680\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0603 - accuracy: 0.9910 - val_loss: 0.1361 - val_accuracy: 0.9682\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0591 - accuracy: 0.9904 - val_loss: 0.1351 - val_accuracy: 0.9692\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9913 - val_loss: 0.1346 - val_accuracy: 0.9690\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0564 - accuracy: 0.9916 - val_loss: 0.1335 - val_accuracy: 0.9702\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0547 - accuracy: 0.9919 - val_loss: 0.1334 - val_accuracy: 0.9696\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0539 - accuracy: 0.9922 - val_loss: 0.1319 - val_accuracy: 0.9708\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0524 - accuracy: 0.9922 - val_loss: 0.1316 - val_accuracy: 0.9712\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0512 - accuracy: 0.9931 - val_loss: 0.1313 - val_accuracy: 0.9712\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0499 - accuracy: 0.9934 - val_loss: 0.1312 - val_accuracy: 0.9710\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0485 - accuracy: 0.9940 - val_loss: 0.1313 - val_accuracy: 0.9698\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.9937 - val_loss: 0.1294 - val_accuracy: 0.9710\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0467 - accuracy: 0.9946 - val_loss: 0.1288 - val_accuracy: 0.9716\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0457 - accuracy: 0.9946 - val_loss: 0.1283 - val_accuracy: 0.9720\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.0446 - accuracy: 0.9946 - val_loss: 0.1282 - val_accuracy: 0.9714\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0437 - accuracy: 0.9952 - val_loss: 0.1293 - val_accuracy: 0.9712\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.0427 - accuracy: 0.9958 - val_loss: 0.1268 - val_accuracy: 0.9718\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 3s 7ms/step - loss: 0.0414 - accuracy: 0.9949 - val_loss: 0.1279 - val_accuracy: 0.9720\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0402 - accuracy: 0.9958 - val_loss: 0.1273 - val_accuracy: 0.9714\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0397 - accuracy: 0.9961 - val_loss: 0.1259 - val_accuracy: 0.9722\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0387 - accuracy: 0.9955 - val_loss: 0.1258 - val_accuracy: 0.9724\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9955 - val_loss: 0.1253 - val_accuracy: 0.9728\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9967 - val_loss: 0.1264 - val_accuracy: 0.9722\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9967 - val_loss: 0.1249 - val_accuracy: 0.9732\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0352 - accuracy: 0.9976 - val_loss: 0.1285 - val_accuracy: 0.9716\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9973 - val_loss: 0.1242 - val_accuracy: 0.9734\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0336 - accuracy: 0.9970 - val_loss: 0.1255 - val_accuracy: 0.9732\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0333 - accuracy: 0.9970 - val_loss: 0.1239 - val_accuracy: 0.9736\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0326 - accuracy: 0.9982 - val_loss: 0.1242 - val_accuracy: 0.9736\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.3107 - accuracy: 0.9256\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 9ms/step - loss: 2.1769 - accuracy: 0.2454 - val_loss: 1.9603 - val_accuracy: 0.4068\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.7891 - accuracy: 0.5536 - val_loss: 1.6459 - val_accuracy: 0.6494\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.5159 - accuracy: 0.6970 - val_loss: 1.4219 - val_accuracy: 0.7292\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.3199 - accuracy: 0.7585 - val_loss: 1.2588 - val_accuracy: 0.7654\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.1766 - accuracy: 0.7870 - val_loss: 1.1381 - val_accuracy: 0.7872\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 1.0685 - accuracy: 0.8086 - val_loss: 1.0457 - val_accuracy: 0.8036\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.9845 - accuracy: 0.8182 - val_loss: 0.9732 - val_accuracy: 0.8144\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.9176 - accuracy: 0.8284 - val_loss: 0.9140 - val_accuracy: 0.8224\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.8626 - accuracy: 0.8383 - val_loss: 0.8651 - val_accuracy: 0.8276\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.8170 - accuracy: 0.8413 - val_loss: 0.8248 - val_accuracy: 0.8350\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7785 - accuracy: 0.8494 - val_loss: 0.7899 - val_accuracy: 0.8384\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7453 - accuracy: 0.8542 - val_loss: 0.7598 - val_accuracy: 0.8460\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7163 - accuracy: 0.8605 - val_loss: 0.7338 - val_accuracy: 0.8472\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.8620 - val_loss: 0.7104 - val_accuracy: 0.8518\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6684 - accuracy: 0.8674 - val_loss: 0.6899 - val_accuracy: 0.8564\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6484 - accuracy: 0.8719 - val_loss: 0.6713 - val_accuracy: 0.8594\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6304 - accuracy: 0.8770 - val_loss: 0.6548 - val_accuracy: 0.8608\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.8779 - val_loss: 0.6396 - val_accuracy: 0.8636\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5989 - accuracy: 0.8800 - val_loss: 0.6261 - val_accuracy: 0.8646\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5851 - accuracy: 0.8815 - val_loss: 0.6133 - val_accuracy: 0.8668\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.8842 - val_loss: 0.6014 - val_accuracy: 0.8676\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5609 - accuracy: 0.8854 - val_loss: 0.5906 - val_accuracy: 0.8704\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5503 - accuracy: 0.8875 - val_loss: 0.5805 - val_accuracy: 0.8712\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.8860 - val_loss: 0.5719 - val_accuracy: 0.8720\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.8890 - val_loss: 0.5628 - val_accuracy: 0.8736\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5222 - accuracy: 0.8890 - val_loss: 0.5546 - val_accuracy: 0.8738\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.8890 - val_loss: 0.5468 - val_accuracy: 0.8746\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5061 - accuracy: 0.8899 - val_loss: 0.5398 - val_accuracy: 0.8758\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.8914 - val_loss: 0.5331 - val_accuracy: 0.8756\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.8908 - val_loss: 0.5267 - val_accuracy: 0.8762\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.8926 - val_loss: 0.5209 - val_accuracy: 0.8776\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.8926 - val_loss: 0.5145 - val_accuracy: 0.8780\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8929 - val_loss: 0.5090 - val_accuracy: 0.8786\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.8935 - val_loss: 0.5045 - val_accuracy: 0.8794\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.8941 - val_loss: 0.4991 - val_accuracy: 0.8804\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4572 - accuracy: 0.8950 - val_loss: 0.4945 - val_accuracy: 0.8814\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4523 - accuracy: 0.8965 - val_loss: 0.4900 - val_accuracy: 0.8818\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 0.8965 - val_loss: 0.4859 - val_accuracy: 0.8818\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4432 - accuracy: 0.8968 - val_loss: 0.4817 - val_accuracy: 0.8838\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.8986 - val_loss: 0.4777 - val_accuracy: 0.8834\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8986 - val_loss: 0.4735 - val_accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.9001 - val_loss: 0.4698 - val_accuracy: 0.8856\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4270 - accuracy: 0.9007 - val_loss: 0.4665 - val_accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.9019 - val_loss: 0.4629 - val_accuracy: 0.8870\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4197 - accuracy: 0.9004 - val_loss: 0.4598 - val_accuracy: 0.8868\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4162 - accuracy: 0.9019 - val_loss: 0.4564 - val_accuracy: 0.8884\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4129 - accuracy: 0.9019 - val_loss: 0.4534 - val_accuracy: 0.8888\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4097 - accuracy: 0.9022 - val_loss: 0.4504 - val_accuracy: 0.8892\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.9031 - val_loss: 0.4473 - val_accuracy: 0.8892\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.9043 - val_loss: 0.4447 - val_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.9046 - val_loss: 0.4423 - val_accuracy: 0.8902\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3977 - accuracy: 0.9046 - val_loss: 0.4395 - val_accuracy: 0.8910\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3950 - accuracy: 0.9058 - val_loss: 0.4371 - val_accuracy: 0.8918\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3924 - accuracy: 0.9064 - val_loss: 0.4348 - val_accuracy: 0.8920\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3897 - accuracy: 0.9067 - val_loss: 0.4322 - val_accuracy: 0.8928\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3872 - accuracy: 0.9070 - val_loss: 0.4299 - val_accuracy: 0.8930\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3847 - accuracy: 0.9076 - val_loss: 0.4277 - val_accuracy: 0.8930\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.9073 - val_loss: 0.4254 - val_accuracy: 0.8936\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.9079 - val_loss: 0.4233 - val_accuracy: 0.8940\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.9088 - val_loss: 0.4213 - val_accuracy: 0.8940\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.9097 - val_loss: 0.4191 - val_accuracy: 0.8942\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.9100 - val_loss: 0.4172 - val_accuracy: 0.8946\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.9103 - val_loss: 0.4154 - val_accuracy: 0.8944\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.9103 - val_loss: 0.4133 - val_accuracy: 0.8948\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.9097 - val_loss: 0.4114 - val_accuracy: 0.8952\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3651 - accuracy: 0.9106 - val_loss: 0.4096 - val_accuracy: 0.8954\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3632 - accuracy: 0.9106 - val_loss: 0.4080 - val_accuracy: 0.8954\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3613 - accuracy: 0.9109 - val_loss: 0.4063 - val_accuracy: 0.8958\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3594 - accuracy: 0.9121 - val_loss: 0.4046 - val_accuracy: 0.8958\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3577 - accuracy: 0.9124 - val_loss: 0.4029 - val_accuracy: 0.8962\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3559 - accuracy: 0.9130 - val_loss: 0.4013 - val_accuracy: 0.8964\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3542 - accuracy: 0.9130 - val_loss: 0.3999 - val_accuracy: 0.8962\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3525 - accuracy: 0.9121 - val_loss: 0.3983 - val_accuracy: 0.8970\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3508 - accuracy: 0.9142 - val_loss: 0.3970 - val_accuracy: 0.8974\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.9142 - val_loss: 0.3955 - val_accuracy: 0.8974\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.9142 - val_loss: 0.3939 - val_accuracy: 0.8976\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.9145 - val_loss: 0.3924 - val_accuracy: 0.8982\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.9139 - val_loss: 0.3912 - val_accuracy: 0.8982\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.9145 - val_loss: 0.3898 - val_accuracy: 0.8984\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3414 - accuracy: 0.9145 - val_loss: 0.3885 - val_accuracy: 0.8992\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.9154 - val_loss: 0.3872 - val_accuracy: 0.8990\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.9154 - val_loss: 0.3860 - val_accuracy: 0.8996\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.9154 - val_loss: 0.3848 - val_accuracy: 0.8996\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3357 - accuracy: 0.9157 - val_loss: 0.3836 - val_accuracy: 0.9004\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3344 - accuracy: 0.9166 - val_loss: 0.3824 - val_accuracy: 0.9006\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3331 - accuracy: 0.9163 - val_loss: 0.3811 - val_accuracy: 0.9006\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3318 - accuracy: 0.9172 - val_loss: 0.3800 - val_accuracy: 0.9012\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3305 - accuracy: 0.9175 - val_loss: 0.3787 - val_accuracy: 0.9010\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3292 - accuracy: 0.9169 - val_loss: 0.3776 - val_accuracy: 0.9008\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3279 - accuracy: 0.9172 - val_loss: 0.3771 - val_accuracy: 0.9014\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3268 - accuracy: 0.9184 - val_loss: 0.3756 - val_accuracy: 0.9020\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.9196 - val_loss: 0.3745 - val_accuracy: 0.9024\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3243 - accuracy: 0.9187 - val_loss: 0.3734 - val_accuracy: 0.9026\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3232 - accuracy: 0.9187 - val_loss: 0.3723 - val_accuracy: 0.9028\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3220 - accuracy: 0.9193 - val_loss: 0.3713 - val_accuracy: 0.9034\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3209 - accuracy: 0.9190 - val_loss: 0.3706 - val_accuracy: 0.9030\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3198 - accuracy: 0.9208 - val_loss: 0.3694 - val_accuracy: 0.9036\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3187 - accuracy: 0.9202 - val_loss: 0.3684 - val_accuracy: 0.9038\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3176 - accuracy: 0.9199 - val_loss: 0.3674 - val_accuracy: 0.9040\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3164 - accuracy: 0.9205 - val_loss: 0.3663 - val_accuracy: 0.9038\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.8692\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 3s 24ms/step - loss: 2.1365 - accuracy: 0.2598 - val_loss: 1.9200 - val_accuracy: 0.4698\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.7692 - accuracy: 0.5689 - val_loss: 1.6213 - val_accuracy: 0.6534\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 1.5176 - accuracy: 0.6796 - val_loss: 1.4092 - val_accuracy: 0.7200\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 1.3362 - accuracy: 0.7336 - val_loss: 1.2543 - val_accuracy: 0.7534\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 1.2018 - accuracy: 0.7663 - val_loss: 1.1382 - val_accuracy: 0.7796\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 1.0997 - accuracy: 0.7846 - val_loss: 1.0478 - val_accuracy: 0.7966\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 1.0188 - accuracy: 0.8002 - val_loss: 0.9755 - val_accuracy: 0.8072\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.9540 - accuracy: 0.8083 - val_loss: 0.9173 - val_accuracy: 0.8152\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.9007 - accuracy: 0.8158 - val_loss: 0.8689 - val_accuracy: 0.8210\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.8560 - accuracy: 0.8230 - val_loss: 0.8275 - val_accuracy: 0.8276\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.8179 - accuracy: 0.8275 - val_loss: 0.7927 - val_accuracy: 0.8350\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7853 - accuracy: 0.8320 - val_loss: 0.7626 - val_accuracy: 0.8380\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.7569 - accuracy: 0.8377 - val_loss: 0.7357 - val_accuracy: 0.8416\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.7317 - accuracy: 0.8431 - val_loss: 0.7122 - val_accuracy: 0.8466\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.7095 - accuracy: 0.8464 - val_loss: 0.6910 - val_accuracy: 0.8490\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6894 - accuracy: 0.8479 - val_loss: 0.6723 - val_accuracy: 0.8512\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.6714 - accuracy: 0.8506 - val_loss: 0.6552 - val_accuracy: 0.8524\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.6550 - accuracy: 0.8515 - val_loss: 0.6396 - val_accuracy: 0.8554\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.8551 - val_loss: 0.6257 - val_accuracy: 0.8590\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6265 - accuracy: 0.8563 - val_loss: 0.6129 - val_accuracy: 0.8616\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.6140 - accuracy: 0.8611 - val_loss: 0.6009 - val_accuracy: 0.8636\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.8620 - val_loss: 0.5898 - val_accuracy: 0.8658\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5916 - accuracy: 0.8635 - val_loss: 0.5798 - val_accuracy: 0.8682\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.8665 - val_loss: 0.5701 - val_accuracy: 0.8690\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.8680 - val_loss: 0.5612 - val_accuracy: 0.8712\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.8719 - val_loss: 0.5529 - val_accuracy: 0.8724\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5552 - accuracy: 0.8719 - val_loss: 0.5449 - val_accuracy: 0.8742\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5474 - accuracy: 0.8722 - val_loss: 0.5376 - val_accuracy: 0.8754\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5401 - accuracy: 0.8728 - val_loss: 0.5304 - val_accuracy: 0.8774\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8761 - val_loss: 0.5238 - val_accuracy: 0.8774\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.8770 - val_loss: 0.5177 - val_accuracy: 0.8776\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.8767 - val_loss: 0.5117 - val_accuracy: 0.8788\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.8770 - val_loss: 0.5059 - val_accuracy: 0.8800\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.8794 - val_loss: 0.5007 - val_accuracy: 0.8812\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.8788 - val_loss: 0.4956 - val_accuracy: 0.8818\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.8797 - val_loss: 0.4907 - val_accuracy: 0.8838\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4933 - accuracy: 0.8815 - val_loss: 0.4861 - val_accuracy: 0.8858\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4886 - accuracy: 0.8833 - val_loss: 0.4817 - val_accuracy: 0.8872\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.8848 - val_loss: 0.4772 - val_accuracy: 0.8864\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.4797 - accuracy: 0.8851 - val_loss: 0.4732 - val_accuracy: 0.8874\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.8854 - val_loss: 0.4694 - val_accuracy: 0.8870\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.8854 - val_loss: 0.4655 - val_accuracy: 0.8886\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4675 - accuracy: 0.8872 - val_loss: 0.4617 - val_accuracy: 0.8892\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8866 - val_loss: 0.4584 - val_accuracy: 0.8902\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.8893 - val_loss: 0.4548 - val_accuracy: 0.8896\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.4568 - accuracy: 0.8890 - val_loss: 0.4516 - val_accuracy: 0.8910\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.8899 - val_loss: 0.4483 - val_accuracy: 0.8918\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8914 - val_loss: 0.4455 - val_accuracy: 0.8928\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4470 - accuracy: 0.8923 - val_loss: 0.4424 - val_accuracy: 0.8926\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.8923 - val_loss: 0.4395 - val_accuracy: 0.8940\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8938 - val_loss: 0.4367 - val_accuracy: 0.8946\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8938 - val_loss: 0.4340 - val_accuracy: 0.8944\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8950 - val_loss: 0.4315 - val_accuracy: 0.8956\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8962 - val_loss: 0.4289 - val_accuracy: 0.8958\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8962 - val_loss: 0.4264 - val_accuracy: 0.8960\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8965 - val_loss: 0.4240 - val_accuracy: 0.8960\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8974 - val_loss: 0.4216 - val_accuracy: 0.8972\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8983 - val_loss: 0.4194 - val_accuracy: 0.8984\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8995 - val_loss: 0.4172 - val_accuracy: 0.8974\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8998 - val_loss: 0.4152 - val_accuracy: 0.8980\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8995 - val_loss: 0.4130 - val_accuracy: 0.8992\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8998 - val_loss: 0.4109 - val_accuracy: 0.8996\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8995 - val_loss: 0.4089 - val_accuracy: 0.8994\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.9004 - val_loss: 0.4071 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.9010 - val_loss: 0.4052 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.9010 - val_loss: 0.4033 - val_accuracy: 0.8998\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.9013 - val_loss: 0.4015 - val_accuracy: 0.9002\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4011 - accuracy: 0.9025 - val_loss: 0.3996 - val_accuracy: 0.9014\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.9019 - val_loss: 0.3979 - val_accuracy: 0.9016\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3973 - accuracy: 0.9043 - val_loss: 0.3962 - val_accuracy: 0.9020\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.9037 - val_loss: 0.3946 - val_accuracy: 0.9024\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3938 - accuracy: 0.9037 - val_loss: 0.3930 - val_accuracy: 0.9032\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.9049 - val_loss: 0.3915 - val_accuracy: 0.9038\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.9058 - val_loss: 0.3898 - val_accuracy: 0.9042\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.9058 - val_loss: 0.3883 - val_accuracy: 0.9044\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.9061 - val_loss: 0.3868 - val_accuracy: 0.9056\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.9070 - val_loss: 0.3854 - val_accuracy: 0.9054\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.9073 - val_loss: 0.3840 - val_accuracy: 0.9052\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3823 - accuracy: 0.9073 - val_loss: 0.3826 - val_accuracy: 0.9054\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.9082 - val_loss: 0.3812 - val_accuracy: 0.9054\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3793 - accuracy: 0.9082 - val_loss: 0.3799 - val_accuracy: 0.9058\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3778 - accuracy: 0.9079 - val_loss: 0.3785 - val_accuracy: 0.9066\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3765 - accuracy: 0.9085 - val_loss: 0.3773 - val_accuracy: 0.9068\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.9085 - val_loss: 0.3760 - val_accuracy: 0.9066\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3737 - accuracy: 0.9088 - val_loss: 0.3748 - val_accuracy: 0.9068\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3723 - accuracy: 0.9091 - val_loss: 0.3735 - val_accuracy: 0.9074\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3709 - accuracy: 0.9100 - val_loss: 0.3723 - val_accuracy: 0.9076\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3697 - accuracy: 0.9100 - val_loss: 0.3711 - val_accuracy: 0.9082\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3683 - accuracy: 0.9106 - val_loss: 0.3702 - val_accuracy: 0.9084\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.9103 - val_loss: 0.3689 - val_accuracy: 0.9094\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3658 - accuracy: 0.9115 - val_loss: 0.3679 - val_accuracy: 0.9090\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.9109 - val_loss: 0.3667 - val_accuracy: 0.9096\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.9124 - val_loss: 0.3655 - val_accuracy: 0.9094\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.9115 - val_loss: 0.3645 - val_accuracy: 0.9094\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3609 - accuracy: 0.9115 - val_loss: 0.3633 - val_accuracy: 0.9094\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.9115 - val_loss: 0.3623 - val_accuracy: 0.9096\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3586 - accuracy: 0.9127 - val_loss: 0.3613 - val_accuracy: 0.9094\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.9127 - val_loss: 0.3603 - val_accuracy: 0.9098\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3563 - accuracy: 0.9133 - val_loss: 0.3593 - val_accuracy: 0.9102\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.9124 - val_loss: 0.3583 - val_accuracy: 0.9104\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.9052\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 2.0456 - accuracy: 0.3839 - val_loss: 1.8565 - val_accuracy: 0.5394\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.7078 - accuracy: 0.6134 - val_loss: 1.5812 - val_accuracy: 0.6564\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.4719 - accuracy: 0.6926 - val_loss: 1.3832 - val_accuracy: 0.7126\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.3004 - accuracy: 0.7340 - val_loss: 1.2385 - val_accuracy: 0.7452\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.1724 - accuracy: 0.7615 - val_loss: 1.1283 - val_accuracy: 0.7710\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 1.0746 - accuracy: 0.7837 - val_loss: 1.0424 - val_accuracy: 0.7876\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.9973 - accuracy: 0.7984 - val_loss: 0.9738 - val_accuracy: 0.7994\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.9348 - accuracy: 0.8095 - val_loss: 0.9178 - val_accuracy: 0.8110\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.8834 - accuracy: 0.8179 - val_loss: 0.8715 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.8401 - accuracy: 0.8287 - val_loss: 0.8318 - val_accuracy: 0.8276\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.8033 - accuracy: 0.8326 - val_loss: 0.7981 - val_accuracy: 0.8318\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7713 - accuracy: 0.8377 - val_loss: 0.7685 - val_accuracy: 0.8378\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7434 - accuracy: 0.8407 - val_loss: 0.7427 - val_accuracy: 0.8394\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.7189 - accuracy: 0.8446 - val_loss: 0.7196 - val_accuracy: 0.8416\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6970 - accuracy: 0.8458 - val_loss: 0.6991 - val_accuracy: 0.8440\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6774 - accuracy: 0.8509 - val_loss: 0.6806 - val_accuracy: 0.8470\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6599 - accuracy: 0.8527 - val_loss: 0.6640 - val_accuracy: 0.8494\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.8554 - val_loss: 0.6490 - val_accuracy: 0.8506\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.6293 - accuracy: 0.8587 - val_loss: 0.6353 - val_accuracy: 0.8528\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6159 - accuracy: 0.8602 - val_loss: 0.6225 - val_accuracy: 0.8560\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.6034 - accuracy: 0.8629 - val_loss: 0.6108 - val_accuracy: 0.8578\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5921 - accuracy: 0.8647 - val_loss: 0.6000 - val_accuracy: 0.8594\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5814 - accuracy: 0.8674 - val_loss: 0.5897 - val_accuracy: 0.8606\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5716 - accuracy: 0.8686 - val_loss: 0.5805 - val_accuracy: 0.8618\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5623 - accuracy: 0.8695 - val_loss: 0.5716 - val_accuracy: 0.8668\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.5536 - accuracy: 0.8728 - val_loss: 0.5633 - val_accuracy: 0.8656\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.5455 - accuracy: 0.8725 - val_loss: 0.5555 - val_accuracy: 0.8688\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.5378 - accuracy: 0.8746 - val_loss: 0.5482 - val_accuracy: 0.8688\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.5306 - accuracy: 0.8776 - val_loss: 0.5414 - val_accuracy: 0.8686\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.8758 - val_loss: 0.5347 - val_accuracy: 0.8714\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.8776 - val_loss: 0.5284 - val_accuracy: 0.8726\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.8791 - val_loss: 0.5225 - val_accuracy: 0.8730\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.8794 - val_loss: 0.5171 - val_accuracy: 0.8742\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.8818 - val_loss: 0.5118 - val_accuracy: 0.8738\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4944 - accuracy: 0.8839 - val_loss: 0.5068 - val_accuracy: 0.8744\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4893 - accuracy: 0.8827 - val_loss: 0.5018 - val_accuracy: 0.8760\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.4845 - accuracy: 0.8836 - val_loss: 0.4971 - val_accuracy: 0.8770\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4799 - accuracy: 0.8845 - val_loss: 0.4927 - val_accuracy: 0.8776\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4754 - accuracy: 0.8863 - val_loss: 0.4884 - val_accuracy: 0.8786\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.8854 - val_loss: 0.4843 - val_accuracy: 0.8790\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.8863 - val_loss: 0.4803 - val_accuracy: 0.8796\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.8872 - val_loss: 0.4766 - val_accuracy: 0.8806\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4592 - accuracy: 0.8887 - val_loss: 0.4730 - val_accuracy: 0.8802\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8884 - val_loss: 0.4694 - val_accuracy: 0.8812\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.4520 - accuracy: 0.8902 - val_loss: 0.4659 - val_accuracy: 0.8822\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8902 - val_loss: 0.4626 - val_accuracy: 0.8832\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8920 - val_loss: 0.4596 - val_accuracy: 0.8826\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.4420 - accuracy: 0.8929 - val_loss: 0.4565 - val_accuracy: 0.8838\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.4390 - accuracy: 0.8917 - val_loss: 0.4536 - val_accuracy: 0.8850\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 2s 17ms/step - loss: 0.4360 - accuracy: 0.8932 - val_loss: 0.4507 - val_accuracy: 0.8856\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8932 - val_loss: 0.4480 - val_accuracy: 0.8860\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4303 - accuracy: 0.8941 - val_loss: 0.4452 - val_accuracy: 0.8868\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.4275 - accuracy: 0.8956 - val_loss: 0.4426 - val_accuracy: 0.8864\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.4249 - accuracy: 0.8959 - val_loss: 0.4401 - val_accuracy: 0.8878\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4222 - accuracy: 0.8965 - val_loss: 0.4376 - val_accuracy: 0.8878\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 0.4198 - accuracy: 0.8968 - val_loss: 0.4352 - val_accuracy: 0.8882\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.4173 - accuracy: 0.8983 - val_loss: 0.4329 - val_accuracy: 0.8886\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4148 - accuracy: 0.8989 - val_loss: 0.4306 - val_accuracy: 0.8894\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8989 - val_loss: 0.4283 - val_accuracy: 0.8896\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.4103 - accuracy: 0.8995 - val_loss: 0.4262 - val_accuracy: 0.8898\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.9007 - val_loss: 0.4242 - val_accuracy: 0.8894\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.9001 - val_loss: 0.4221 - val_accuracy: 0.8924\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.4038 - accuracy: 0.9004 - val_loss: 0.4202 - val_accuracy: 0.8924\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.9010 - val_loss: 0.4184 - val_accuracy: 0.8920\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.9022 - val_loss: 0.4165 - val_accuracy: 0.8928\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3977 - accuracy: 0.9007 - val_loss: 0.4146 - val_accuracy: 0.8932\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.9016 - val_loss: 0.4126 - val_accuracy: 0.8938\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3939 - accuracy: 0.9019 - val_loss: 0.4108 - val_accuracy: 0.8944\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.9034 - val_loss: 0.4091 - val_accuracy: 0.8944\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3903 - accuracy: 0.9028 - val_loss: 0.4074 - val_accuracy: 0.8952\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3885 - accuracy: 0.9037 - val_loss: 0.4057 - val_accuracy: 0.8956\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3868 - accuracy: 0.9037 - val_loss: 0.4040 - val_accuracy: 0.8958\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.3851 - accuracy: 0.9058 - val_loss: 0.4024 - val_accuracy: 0.8964\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.9049 - val_loss: 0.4007 - val_accuracy: 0.8976\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.3818 - accuracy: 0.9061 - val_loss: 0.3992 - val_accuracy: 0.8976\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.9064 - val_loss: 0.3977 - val_accuracy: 0.8972\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3786 - accuracy: 0.9073 - val_loss: 0.3963 - val_accuracy: 0.8978\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.9079 - val_loss: 0.3948 - val_accuracy: 0.8978\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.9073 - val_loss: 0.3933 - val_accuracy: 0.8986\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.3741 - accuracy: 0.9073 - val_loss: 0.3920 - val_accuracy: 0.8984\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.9079 - val_loss: 0.3906 - val_accuracy: 0.8984\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3712 - accuracy: 0.9079 - val_loss: 0.3893 - val_accuracy: 0.8986\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3698 - accuracy: 0.9088 - val_loss: 0.3882 - val_accuracy: 0.8988\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3684 - accuracy: 0.9091 - val_loss: 0.3868 - val_accuracy: 0.8990\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3670 - accuracy: 0.9091 - val_loss: 0.3855 - val_accuracy: 0.8996\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.3657 - accuracy: 0.9091 - val_loss: 0.3843 - val_accuracy: 0.8996\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3644 - accuracy: 0.9091 - val_loss: 0.3830 - val_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.3631 - accuracy: 0.9088 - val_loss: 0.3818 - val_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.3618 - accuracy: 0.9091 - val_loss: 0.3806 - val_accuracy: 0.9002\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.9097 - val_loss: 0.3795 - val_accuracy: 0.9008\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.9100 - val_loss: 0.3782 - val_accuracy: 0.9008\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.9100 - val_loss: 0.3771 - val_accuracy: 0.9008\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.9091 - val_loss: 0.3760 - val_accuracy: 0.9010\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.9103 - val_loss: 0.3749 - val_accuracy: 0.9008\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.3545 - accuracy: 0.9100 - val_loss: 0.3739 - val_accuracy: 0.9012\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.9103 - val_loss: 0.3728 - val_accuracy: 0.9020\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.9103 - val_loss: 0.3717 - val_accuracy: 0.9016\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.9112 - val_loss: 0.3707 - val_accuracy: 0.9022\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.9115 - val_loss: 0.3697 - val_accuracy: 0.9022\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.9109 - val_loss: 0.3687 - val_accuracy: 0.9022\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8836\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 2s 7ms/step - loss: 2.1341 - accuracy: 0.2826 - val_loss: 1.9186 - val_accuracy: 0.4920\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 1.7191 - accuracy: 0.5926 - val_loss: 1.5480 - val_accuracy: 0.6634\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 1.3789 - accuracy: 0.7099 - val_loss: 1.2569 - val_accuracy: 0.7392\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 1.1242 - accuracy: 0.7690 - val_loss: 1.0478 - val_accuracy: 0.7786\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.9456 - accuracy: 0.8029 - val_loss: 0.9034 - val_accuracy: 0.8106\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.8207 - accuracy: 0.8329 - val_loss: 0.8006 - val_accuracy: 0.8274\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.7303 - accuracy: 0.8503 - val_loss: 0.7246 - val_accuracy: 0.8422\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.6611 - accuracy: 0.8632 - val_loss: 0.6687 - val_accuracy: 0.8540\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.6088 - accuracy: 0.8731 - val_loss: 0.6202 - val_accuracy: 0.8590\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.5656 - accuracy: 0.8803 - val_loss: 0.5843 - val_accuracy: 0.8654\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.5310 - accuracy: 0.8821 - val_loss: 0.5531 - val_accuracy: 0.8692\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5012 - accuracy: 0.8878 - val_loss: 0.5270 - val_accuracy: 0.8722\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.4764 - accuracy: 0.8902 - val_loss: 0.5056 - val_accuracy: 0.8758\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.4551 - accuracy: 0.8920 - val_loss: 0.4855 - val_accuracy: 0.8798\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8992 - val_loss: 0.4689 - val_accuracy: 0.8834\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.9016 - val_loss: 0.4545 - val_accuracy: 0.8864\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.9037 - val_loss: 0.4420 - val_accuracy: 0.8876\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3922 - accuracy: 0.9064 - val_loss: 0.4288 - val_accuracy: 0.8910\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3804 - accuracy: 0.9067 - val_loss: 0.4185 - val_accuracy: 0.8932\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3695 - accuracy: 0.9109 - val_loss: 0.4084 - val_accuracy: 0.8948\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3590 - accuracy: 0.9127 - val_loss: 0.4007 - val_accuracy: 0.8962\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3504 - accuracy: 0.9121 - val_loss: 0.3939 - val_accuracy: 0.8972\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3420 - accuracy: 0.9139 - val_loss: 0.3844 - val_accuracy: 0.8996\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.9160 - val_loss: 0.3774 - val_accuracy: 0.9004\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3271 - accuracy: 0.9157 - val_loss: 0.3715 - val_accuracy: 0.9016\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3204 - accuracy: 0.9196 - val_loss: 0.3650 - val_accuracy: 0.9038\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3140 - accuracy: 0.9190 - val_loss: 0.3595 - val_accuracy: 0.9040\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3079 - accuracy: 0.9214 - val_loss: 0.3543 - val_accuracy: 0.9062\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3022 - accuracy: 0.9241 - val_loss: 0.3512 - val_accuracy: 0.9060\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.2970 - accuracy: 0.9214 - val_loss: 0.3454 - val_accuracy: 0.9068\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2922 - accuracy: 0.9244 - val_loss: 0.3407 - val_accuracy: 0.9088\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2872 - accuracy: 0.9262 - val_loss: 0.3361 - val_accuracy: 0.9106\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2826 - accuracy: 0.9262 - val_loss: 0.3327 - val_accuracy: 0.9112\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2785 - accuracy: 0.9292 - val_loss: 0.3288 - val_accuracy: 0.9128\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2745 - accuracy: 0.9289 - val_loss: 0.3253 - val_accuracy: 0.9130\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2703 - accuracy: 0.9292 - val_loss: 0.3234 - val_accuracy: 0.9126\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2663 - accuracy: 0.9325 - val_loss: 0.3190 - val_accuracy: 0.9134\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2629 - accuracy: 0.9328 - val_loss: 0.3158 - val_accuracy: 0.9144\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2592 - accuracy: 0.9322 - val_loss: 0.3122 - val_accuracy: 0.9178\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2562 - accuracy: 0.9343 - val_loss: 0.3108 - val_accuracy: 0.9168\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2529 - accuracy: 0.9346 - val_loss: 0.3067 - val_accuracy: 0.9184\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2497 - accuracy: 0.9373 - val_loss: 0.3064 - val_accuracy: 0.9180\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.2467 - accuracy: 0.9346 - val_loss: 0.3019 - val_accuracy: 0.9184\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2440 - accuracy: 0.9379 - val_loss: 0.2997 - val_accuracy: 0.9196\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2409 - accuracy: 0.9379 - val_loss: 0.2974 - val_accuracy: 0.9202\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 0.2383 - accuracy: 0.9388 - val_loss: 0.2942 - val_accuracy: 0.9204\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2357 - accuracy: 0.9412 - val_loss: 0.2927 - val_accuracy: 0.9214\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2330 - accuracy: 0.9406 - val_loss: 0.2908 - val_accuracy: 0.9224\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2303 - accuracy: 0.9406 - val_loss: 0.2881 - val_accuracy: 0.9210\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2281 - accuracy: 0.9412 - val_loss: 0.2865 - val_accuracy: 0.9230\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2253 - accuracy: 0.9415 - val_loss: 0.2851 - val_accuracy: 0.9246\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2234 - accuracy: 0.9442 - val_loss: 0.2822 - val_accuracy: 0.9242\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2211 - accuracy: 0.9439 - val_loss: 0.2805 - val_accuracy: 0.9248\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2186 - accuracy: 0.9460 - val_loss: 0.2791 - val_accuracy: 0.9254\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2165 - accuracy: 0.9430 - val_loss: 0.2782 - val_accuracy: 0.9266\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9463 - val_loss: 0.2751 - val_accuracy: 0.9260\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2126 - accuracy: 0.9460 - val_loss: 0.2742 - val_accuracy: 0.9264\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2104 - accuracy: 0.9469 - val_loss: 0.2726 - val_accuracy: 0.9276\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2083 - accuracy: 0.9484 - val_loss: 0.2713 - val_accuracy: 0.9274\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2066 - accuracy: 0.9472 - val_loss: 0.2689 - val_accuracy: 0.9276\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2044 - accuracy: 0.9493 - val_loss: 0.2678 - val_accuracy: 0.9286\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9496 - val_loss: 0.2654 - val_accuracy: 0.9276\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 3s 21ms/step - loss: 0.2010 - accuracy: 0.9484 - val_loss: 0.2641 - val_accuracy: 0.9290\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.1992 - accuracy: 0.9517 - val_loss: 0.2635 - val_accuracy: 0.9282\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.1974 - accuracy: 0.9511 - val_loss: 0.2616 - val_accuracy: 0.9302\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.1956 - accuracy: 0.9505 - val_loss: 0.2596 - val_accuracy: 0.9298\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1939 - accuracy: 0.9517 - val_loss: 0.2590 - val_accuracy: 0.9304\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1923 - accuracy: 0.9541 - val_loss: 0.2576 - val_accuracy: 0.9304\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.1907 - accuracy: 0.9514 - val_loss: 0.2561 - val_accuracy: 0.9324\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1888 - accuracy: 0.9529 - val_loss: 0.2551 - val_accuracy: 0.9306\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1877 - accuracy: 0.9544 - val_loss: 0.2536 - val_accuracy: 0.9326\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.1859 - accuracy: 0.9547 - val_loss: 0.2537 - val_accuracy: 0.9332\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.1846 - accuracy: 0.9544 - val_loss: 0.2513 - val_accuracy: 0.9328\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.1830 - accuracy: 0.9556 - val_loss: 0.2502 - val_accuracy: 0.9338\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1812 - accuracy: 0.9559 - val_loss: 0.2488 - val_accuracy: 0.9330\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1801 - accuracy: 0.9547 - val_loss: 0.2481 - val_accuracy: 0.9350\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.1785 - accuracy: 0.9562 - val_loss: 0.2472 - val_accuracy: 0.9346\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.1771 - accuracy: 0.9550 - val_loss: 0.2467 - val_accuracy: 0.9334\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1758 - accuracy: 0.9571 - val_loss: 0.2444 - val_accuracy: 0.9350\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1744 - accuracy: 0.9580 - val_loss: 0.2432 - val_accuracy: 0.9358\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.1729 - accuracy: 0.9592 - val_loss: 0.2431 - val_accuracy: 0.9356\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 0.1717 - accuracy: 0.9571 - val_loss: 0.2419 - val_accuracy: 0.9360\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.1704 - accuracy: 0.9589 - val_loss: 0.2402 - val_accuracy: 0.9368\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 4s 27ms/step - loss: 0.1689 - accuracy: 0.9577 - val_loss: 0.2390 - val_accuracy: 0.9372\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.1678 - accuracy: 0.9589 - val_loss: 0.2381 - val_accuracy: 0.9380\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.1663 - accuracy: 0.9598 - val_loss: 0.2374 - val_accuracy: 0.9380\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.9622 - val_loss: 0.2364 - val_accuracy: 0.9378\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1640 - accuracy: 0.9610 - val_loss: 0.2361 - val_accuracy: 0.9380\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1627 - accuracy: 0.9610 - val_loss: 0.2357 - val_accuracy: 0.9378\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1616 - accuracy: 0.9610 - val_loss: 0.2335 - val_accuracy: 0.9388\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1601 - accuracy: 0.9616 - val_loss: 0.2326 - val_accuracy: 0.9388\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1592 - accuracy: 0.9616 - val_loss: 0.2319 - val_accuracy: 0.9388\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.1579 - accuracy: 0.9634 - val_loss: 0.2311 - val_accuracy: 0.9402\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1569 - accuracy: 0.9637 - val_loss: 0.2304 - val_accuracy: 0.9406\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.9631 - val_loss: 0.2293 - val_accuracy: 0.9402\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1546 - accuracy: 0.9640 - val_loss: 0.2285 - val_accuracy: 0.9400\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1535 - accuracy: 0.9643 - val_loss: 0.2276 - val_accuracy: 0.9404\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1524 - accuracy: 0.9655 - val_loss: 0.2269 - val_accuracy: 0.9402\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1514 - accuracy: 0.9637 - val_loss: 0.2262 - val_accuracy: 0.9406\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1501 - accuracy: 0.9643 - val_loss: 0.2255 - val_accuracy: 0.9410\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8914\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 2.0941 - accuracy: 0.3213 - val_loss: 1.8534 - val_accuracy: 0.5236\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 1.6834 - accuracy: 0.6037 - val_loss: 1.5018 - val_accuracy: 0.6828\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 1.3705 - accuracy: 0.7192 - val_loss: 1.2267 - val_accuracy: 0.7624\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1.1328 - accuracy: 0.7744 - val_loss: 1.0249 - val_accuracy: 0.7948\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.9610 - accuracy: 0.8002 - val_loss: 0.8811 - val_accuracy: 0.8154\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.8389 - accuracy: 0.8242 - val_loss: 0.7772 - val_accuracy: 0.8322\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.7496 - accuracy: 0.8368 - val_loss: 0.7012 - val_accuracy: 0.8440\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.6830 - accuracy: 0.8521 - val_loss: 0.6442 - val_accuracy: 0.8546\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.6311 - accuracy: 0.8611 - val_loss: 0.5992 - val_accuracy: 0.8596\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5905 - accuracy: 0.8656 - val_loss: 0.5626 - val_accuracy: 0.8680\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5568 - accuracy: 0.8725 - val_loss: 0.5334 - val_accuracy: 0.8714\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.8755 - val_loss: 0.5077 - val_accuracy: 0.8774\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5054 - accuracy: 0.8803 - val_loss: 0.4875 - val_accuracy: 0.8812\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.4850 - accuracy: 0.8848 - val_loss: 0.4690 - val_accuracy: 0.8842\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.4669 - accuracy: 0.8863 - val_loss: 0.4525 - val_accuracy: 0.8874\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.4514 - accuracy: 0.8908 - val_loss: 0.4385 - val_accuracy: 0.8896\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.4374 - accuracy: 0.8935 - val_loss: 0.4258 - val_accuracy: 0.8914\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.4250 - accuracy: 0.8953 - val_loss: 0.4143 - val_accuracy: 0.8948\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.4136 - accuracy: 0.8971 - val_loss: 0.4043 - val_accuracy: 0.8970\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.4035 - accuracy: 0.8992 - val_loss: 0.3949 - val_accuracy: 0.8982\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.3943 - accuracy: 0.9031 - val_loss: 0.3869 - val_accuracy: 0.9016\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.3854 - accuracy: 0.9052 - val_loss: 0.3790 - val_accuracy: 0.9040\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.3772 - accuracy: 0.9064 - val_loss: 0.3720 - val_accuracy: 0.9036\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3700 - accuracy: 0.9058 - val_loss: 0.3652 - val_accuracy: 0.9060\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3630 - accuracy: 0.9082 - val_loss: 0.3591 - val_accuracy: 0.9086\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.3563 - accuracy: 0.9109 - val_loss: 0.3546 - val_accuracy: 0.9086\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3501 - accuracy: 0.9127 - val_loss: 0.3488 - val_accuracy: 0.9104\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.3447 - accuracy: 0.9118 - val_loss: 0.3432 - val_accuracy: 0.9112\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.3390 - accuracy: 0.9130 - val_loss: 0.3384 - val_accuracy: 0.9128\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.3338 - accuracy: 0.9163 - val_loss: 0.3339 - val_accuracy: 0.9128\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3292 - accuracy: 0.9172 - val_loss: 0.3292 - val_accuracy: 0.9146\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3240 - accuracy: 0.9178 - val_loss: 0.3254 - val_accuracy: 0.9150\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.3197 - accuracy: 0.9190 - val_loss: 0.3220 - val_accuracy: 0.9162\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.3157 - accuracy: 0.9202 - val_loss: 0.3178 - val_accuracy: 0.9166\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3113 - accuracy: 0.9193 - val_loss: 0.3158 - val_accuracy: 0.9184\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3074 - accuracy: 0.9211 - val_loss: 0.3107 - val_accuracy: 0.9178\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3035 - accuracy: 0.9217 - val_loss: 0.3086 - val_accuracy: 0.9210\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3002 - accuracy: 0.9229 - val_loss: 0.3046 - val_accuracy: 0.9200\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2961 - accuracy: 0.9253 - val_loss: 0.3022 - val_accuracy: 0.9204\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2927 - accuracy: 0.9241 - val_loss: 0.2994 - val_accuracy: 0.9202\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2891 - accuracy: 0.9259 - val_loss: 0.2964 - val_accuracy: 0.9198\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2864 - accuracy: 0.9256 - val_loss: 0.2937 - val_accuracy: 0.9212\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2832 - accuracy: 0.9268 - val_loss: 0.2909 - val_accuracy: 0.9218\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2803 - accuracy: 0.9262 - val_loss: 0.2885 - val_accuracy: 0.9232\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2770 - accuracy: 0.9274 - val_loss: 0.2857 - val_accuracy: 0.9234\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2743 - accuracy: 0.9280 - val_loss: 0.2832 - val_accuracy: 0.9230\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2714 - accuracy: 0.9274 - val_loss: 0.2817 - val_accuracy: 0.9256\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2686 - accuracy: 0.9328 - val_loss: 0.2787 - val_accuracy: 0.9248\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2656 - accuracy: 0.9310 - val_loss: 0.2779 - val_accuracy: 0.9272\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2631 - accuracy: 0.9325 - val_loss: 0.2750 - val_accuracy: 0.9272\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2609 - accuracy: 0.9322 - val_loss: 0.2729 - val_accuracy: 0.9284\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2583 - accuracy: 0.9340 - val_loss: 0.2707 - val_accuracy: 0.9292\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2557 - accuracy: 0.9340 - val_loss: 0.2696 - val_accuracy: 0.9300\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 2s 14ms/step - loss: 0.2538 - accuracy: 0.9358 - val_loss: 0.2668 - val_accuracy: 0.9286\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2510 - accuracy: 0.9370 - val_loss: 0.2652 - val_accuracy: 0.9274\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2491 - accuracy: 0.9358 - val_loss: 0.2637 - val_accuracy: 0.9318\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2468 - accuracy: 0.9382 - val_loss: 0.2611 - val_accuracy: 0.9292\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2447 - accuracy: 0.9373 - val_loss: 0.2593 - val_accuracy: 0.9300\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2425 - accuracy: 0.9388 - val_loss: 0.2587 - val_accuracy: 0.9316\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2404 - accuracy: 0.9406 - val_loss: 0.2562 - val_accuracy: 0.9320\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2384 - accuracy: 0.9394 - val_loss: 0.2547 - val_accuracy: 0.9326\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2363 - accuracy: 0.9403 - val_loss: 0.2530 - val_accuracy: 0.9332\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2344 - accuracy: 0.9418 - val_loss: 0.2523 - val_accuracy: 0.9334\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2326 - accuracy: 0.9427 - val_loss: 0.2506 - val_accuracy: 0.9338\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2305 - accuracy: 0.9433 - val_loss: 0.2483 - val_accuracy: 0.9340\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2286 - accuracy: 0.9439 - val_loss: 0.2476 - val_accuracy: 0.9336\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2266 - accuracy: 0.9439 - val_loss: 0.2458 - val_accuracy: 0.9332\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2248 - accuracy: 0.9436 - val_loss: 0.2439 - val_accuracy: 0.9342\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2231 - accuracy: 0.9439 - val_loss: 0.2428 - val_accuracy: 0.9356\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2213 - accuracy: 0.9457 - val_loss: 0.2417 - val_accuracy: 0.9350\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2195 - accuracy: 0.9466 - val_loss: 0.2405 - val_accuracy: 0.9346\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2179 - accuracy: 0.9457 - val_loss: 0.2390 - val_accuracy: 0.9366\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2160 - accuracy: 0.9457 - val_loss: 0.2376 - val_accuracy: 0.9356\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9457 - val_loss: 0.2359 - val_accuracy: 0.9356\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2127 - accuracy: 0.9463 - val_loss: 0.2348 - val_accuracy: 0.9358\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2111 - accuracy: 0.9469 - val_loss: 0.2335 - val_accuracy: 0.9378\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2093 - accuracy: 0.9484 - val_loss: 0.2329 - val_accuracy: 0.9376\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9469 - val_loss: 0.2312 - val_accuracy: 0.9378\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2064 - accuracy: 0.9469 - val_loss: 0.2300 - val_accuracy: 0.9378\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2049 - accuracy: 0.9475 - val_loss: 0.2285 - val_accuracy: 0.9378\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2034 - accuracy: 0.9487 - val_loss: 0.2275 - val_accuracy: 0.9384\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2016 - accuracy: 0.9505 - val_loss: 0.2265 - val_accuracy: 0.9382\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2004 - accuracy: 0.9493 - val_loss: 0.2255 - val_accuracy: 0.9378\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1987 - accuracy: 0.9487 - val_loss: 0.2245 - val_accuracy: 0.9392\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1974 - accuracy: 0.9511 - val_loss: 0.2236 - val_accuracy: 0.9392\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1961 - accuracy: 0.9505 - val_loss: 0.2221 - val_accuracy: 0.9400\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1947 - accuracy: 0.9502 - val_loss: 0.2211 - val_accuracy: 0.9396\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1928 - accuracy: 0.9514 - val_loss: 0.2200 - val_accuracy: 0.9404\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1919 - accuracy: 0.9523 - val_loss: 0.2186 - val_accuracy: 0.9410\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1904 - accuracy: 0.9532 - val_loss: 0.2177 - val_accuracy: 0.9422\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1891 - accuracy: 0.9520 - val_loss: 0.2167 - val_accuracy: 0.9410\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1877 - accuracy: 0.9532 - val_loss: 0.2155 - val_accuracy: 0.9414\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.1863 - accuracy: 0.9526 - val_loss: 0.2148 - val_accuracy: 0.9418\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.9532 - val_loss: 0.2135 - val_accuracy: 0.9426\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1838 - accuracy: 0.9541 - val_loss: 0.2124 - val_accuracy: 0.9430\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9553 - val_loss: 0.2118 - val_accuracy: 0.9432\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1814 - accuracy: 0.9553 - val_loss: 0.2108 - val_accuracy: 0.9430\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1801 - accuracy: 0.9565 - val_loss: 0.2097 - val_accuracy: 0.9434\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1786 - accuracy: 0.9568 - val_loss: 0.2095 - val_accuracy: 0.9428\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1774 - accuracy: 0.9556 - val_loss: 0.2079 - val_accuracy: 0.9444\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9184\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 2s 8ms/step - loss: 2.0481 - accuracy: 0.3719 - val_loss: 1.8174 - val_accuracy: 0.5608\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 1.6136 - accuracy: 0.6425 - val_loss: 1.4368 - val_accuracy: 0.6848\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 1.2852 - accuracy: 0.7322 - val_loss: 1.1669 - val_accuracy: 0.7488\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 1.0591 - accuracy: 0.7849 - val_loss: 0.9836 - val_accuracy: 0.7882\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.9044 - accuracy: 0.8074 - val_loss: 0.8568 - val_accuracy: 0.8100\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.7979 - accuracy: 0.8218 - val_loss: 0.7665 - val_accuracy: 0.8266\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.7186 - accuracy: 0.8437 - val_loss: 0.6988 - val_accuracy: 0.8386\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.6582 - accuracy: 0.8542 - val_loss: 0.6470 - val_accuracy: 0.8476\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.6111 - accuracy: 0.8596 - val_loss: 0.6040 - val_accuracy: 0.8576\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5729 - accuracy: 0.8668 - val_loss: 0.5701 - val_accuracy: 0.8628\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5411 - accuracy: 0.8746 - val_loss: 0.5410 - val_accuracy: 0.8718\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5143 - accuracy: 0.8779 - val_loss: 0.5178 - val_accuracy: 0.8742\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.4919 - accuracy: 0.8806 - val_loss: 0.4966 - val_accuracy: 0.8776\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.4717 - accuracy: 0.8848 - val_loss: 0.4786 - val_accuracy: 0.8812\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.4546 - accuracy: 0.8878 - val_loss: 0.4626 - val_accuracy: 0.8858\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.4392 - accuracy: 0.8935 - val_loss: 0.4486 - val_accuracy: 0.8872\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.4254 - accuracy: 0.8956 - val_loss: 0.4366 - val_accuracy: 0.8894\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.4135 - accuracy: 0.8965 - val_loss: 0.4243 - val_accuracy: 0.8930\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.4022 - accuracy: 0.9025 - val_loss: 0.4142 - val_accuracy: 0.8956\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3921 - accuracy: 0.9025 - val_loss: 0.4042 - val_accuracy: 0.8976\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3823 - accuracy: 0.9037 - val_loss: 0.3959 - val_accuracy: 0.8976\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.3742 - accuracy: 0.9055 - val_loss: 0.3879 - val_accuracy: 0.8996\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3659 - accuracy: 0.9067 - val_loss: 0.3810 - val_accuracy: 0.9020\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3584 - accuracy: 0.9079 - val_loss: 0.3743 - val_accuracy: 0.9010\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3517 - accuracy: 0.9097 - val_loss: 0.3670 - val_accuracy: 0.9024\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3452 - accuracy: 0.9112 - val_loss: 0.3614 - val_accuracy: 0.9032\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.3389 - accuracy: 0.9118 - val_loss: 0.3554 - val_accuracy: 0.9038\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3328 - accuracy: 0.9124 - val_loss: 0.3509 - val_accuracy: 0.9078\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.9142 - val_loss: 0.3454 - val_accuracy: 0.9086\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3224 - accuracy: 0.9175 - val_loss: 0.3411 - val_accuracy: 0.9076\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3174 - accuracy: 0.9184 - val_loss: 0.3373 - val_accuracy: 0.9094\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.3127 - accuracy: 0.9202 - val_loss: 0.3330 - val_accuracy: 0.9082\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.9178 - val_loss: 0.3289 - val_accuracy: 0.9128\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.9226 - val_loss: 0.3243 - val_accuracy: 0.9122\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.9226 - val_loss: 0.3215 - val_accuracy: 0.9130\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2962 - accuracy: 0.9241 - val_loss: 0.3172 - val_accuracy: 0.9136\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2923 - accuracy: 0.9238 - val_loss: 0.3139 - val_accuracy: 0.9152\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2887 - accuracy: 0.9268 - val_loss: 0.3103 - val_accuracy: 0.9158\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2846 - accuracy: 0.9274 - val_loss: 0.3084 - val_accuracy: 0.9146\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2819 - accuracy: 0.9262 - val_loss: 0.3044 - val_accuracy: 0.9168\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2785 - accuracy: 0.9268 - val_loss: 0.3013 - val_accuracy: 0.9172\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2754 - accuracy: 0.9274 - val_loss: 0.2984 - val_accuracy: 0.9180\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2724 - accuracy: 0.9280 - val_loss: 0.2956 - val_accuracy: 0.9176\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2695 - accuracy: 0.9283 - val_loss: 0.2941 - val_accuracy: 0.9172\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2664 - accuracy: 0.9304 - val_loss: 0.2905 - val_accuracy: 0.9192\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2636 - accuracy: 0.9295 - val_loss: 0.2880 - val_accuracy: 0.9192\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2610 - accuracy: 0.9292 - val_loss: 0.2859 - val_accuracy: 0.9194\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2585 - accuracy: 0.9301 - val_loss: 0.2835 - val_accuracy: 0.9194\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2558 - accuracy: 0.9307 - val_loss: 0.2814 - val_accuracy: 0.9192\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2533 - accuracy: 0.9304 - val_loss: 0.2797 - val_accuracy: 0.9202\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.2505 - accuracy: 0.9322 - val_loss: 0.2769 - val_accuracy: 0.9214\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2486 - accuracy: 0.9325 - val_loss: 0.2748 - val_accuracy: 0.9214\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.2458 - accuracy: 0.9328 - val_loss: 0.2735 - val_accuracy: 0.9222\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 0.2441 - accuracy: 0.9325 - val_loss: 0.2709 - val_accuracy: 0.9220\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.2417 - accuracy: 0.9337 - val_loss: 0.2692 - val_accuracy: 0.9234\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.2395 - accuracy: 0.9331 - val_loss: 0.2676 - val_accuracy: 0.9250\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2372 - accuracy: 0.9352 - val_loss: 0.2658 - val_accuracy: 0.9238\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2353 - accuracy: 0.9340 - val_loss: 0.2640 - val_accuracy: 0.9254\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2331 - accuracy: 0.9370 - val_loss: 0.2620 - val_accuracy: 0.9262\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2312 - accuracy: 0.9367 - val_loss: 0.2605 - val_accuracy: 0.9258\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2291 - accuracy: 0.9379 - val_loss: 0.2587 - val_accuracy: 0.9276\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2271 - accuracy: 0.9364 - val_loss: 0.2574 - val_accuracy: 0.9270\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2254 - accuracy: 0.9382 - val_loss: 0.2555 - val_accuracy: 0.9278\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2232 - accuracy: 0.9406 - val_loss: 0.2541 - val_accuracy: 0.9276\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.2215 - accuracy: 0.9376 - val_loss: 0.2533 - val_accuracy: 0.9268\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.2198 - accuracy: 0.9388 - val_loss: 0.2509 - val_accuracy: 0.9294\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2178 - accuracy: 0.9409 - val_loss: 0.2497 - val_accuracy: 0.9296\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2162 - accuracy: 0.9391 - val_loss: 0.2486 - val_accuracy: 0.9290\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.2149 - accuracy: 0.9406 - val_loss: 0.2464 - val_accuracy: 0.9304\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.2128 - accuracy: 0.9403 - val_loss: 0.2450 - val_accuracy: 0.9308\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.9409 - val_loss: 0.2443 - val_accuracy: 0.9302\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.2096 - accuracy: 0.9424 - val_loss: 0.2428 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.9424 - val_loss: 0.2413 - val_accuracy: 0.9324\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.2061 - accuracy: 0.9433 - val_loss: 0.2400 - val_accuracy: 0.9326\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2049 - accuracy: 0.9430 - val_loss: 0.2388 - val_accuracy: 0.9328\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.2029 - accuracy: 0.9433 - val_loss: 0.2379 - val_accuracy: 0.9326\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.2013 - accuracy: 0.9430 - val_loss: 0.2362 - val_accuracy: 0.9338\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.2001 - accuracy: 0.9451 - val_loss: 0.2350 - val_accuracy: 0.9336\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1986 - accuracy: 0.9454 - val_loss: 0.2339 - val_accuracy: 0.9342\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.1971 - accuracy: 0.9466 - val_loss: 0.2331 - val_accuracy: 0.9336\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1957 - accuracy: 0.9466 - val_loss: 0.2315 - val_accuracy: 0.9340\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1942 - accuracy: 0.9466 - val_loss: 0.2303 - val_accuracy: 0.9352\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1927 - accuracy: 0.9460 - val_loss: 0.2290 - val_accuracy: 0.9350\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1913 - accuracy: 0.9469 - val_loss: 0.2283 - val_accuracy: 0.9360\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1900 - accuracy: 0.9469 - val_loss: 0.2270 - val_accuracy: 0.9362\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1884 - accuracy: 0.9493 - val_loss: 0.2258 - val_accuracy: 0.9360\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.1872 - accuracy: 0.9484 - val_loss: 0.2246 - val_accuracy: 0.9374\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1857 - accuracy: 0.9478 - val_loss: 0.2237 - val_accuracy: 0.9380\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.1848 - accuracy: 0.9499 - val_loss: 0.2225 - val_accuracy: 0.9378\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1833 - accuracy: 0.9493 - val_loss: 0.2214 - val_accuracy: 0.9382\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1821 - accuracy: 0.9487 - val_loss: 0.2205 - val_accuracy: 0.9396\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1807 - accuracy: 0.9505 - val_loss: 0.2201 - val_accuracy: 0.9386\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1796 - accuracy: 0.9514 - val_loss: 0.2187 - val_accuracy: 0.9394\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.1781 - accuracy: 0.9523 - val_loss: 0.2176 - val_accuracy: 0.9398\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.1767 - accuracy: 0.9523 - val_loss: 0.2168 - val_accuracy: 0.9408\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.1756 - accuracy: 0.9535 - val_loss: 0.2162 - val_accuracy: 0.9406\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.1744 - accuracy: 0.9532 - val_loss: 0.2155 - val_accuracy: 0.9416\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9559 - val_loss: 0.2141 - val_accuracy: 0.9412\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.1723 - accuracy: 0.9529 - val_loss: 0.2128 - val_accuracy: 0.9416\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.1709 - accuracy: 0.9556 - val_loss: 0.2121 - val_accuracy: 0.9418\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.9130\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 1.6591 - accuracy: 0.5320 - val_loss: 0.9099 - val_accuracy: 0.8102\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.6585 - accuracy: 0.8380 - val_loss: 0.4966 - val_accuracy: 0.8740\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.4407 - accuracy: 0.8842 - val_loss: 0.3804 - val_accuracy: 0.8978\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.3632 - accuracy: 0.9028 - val_loss: 0.3357 - val_accuracy: 0.9120\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3194 - accuracy: 0.9140 - val_loss: 0.2978 - val_accuracy: 0.9242\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.2916 - accuracy: 0.9170 - val_loss: 0.2603 - val_accuracy: 0.9302\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.2668 - accuracy: 0.9260 - val_loss: 0.2500 - val_accuracy: 0.9326\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.2492 - accuracy: 0.9306 - val_loss: 0.2273 - val_accuracy: 0.9366\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.2337 - accuracy: 0.9356 - val_loss: 0.2164 - val_accuracy: 0.9398\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.2228 - accuracy: 0.9352 - val_loss: 0.2009 - val_accuracy: 0.9438\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 0.2096 - accuracy: 0.9400 - val_loss: 0.1906 - val_accuracy: 0.9456\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 9s 17ms/step - loss: 0.1996 - accuracy: 0.9420 - val_loss: 0.1836 - val_accuracy: 0.9504\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.1894 - accuracy: 0.9472 - val_loss: 0.1696 - val_accuracy: 0.9570\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.1782 - accuracy: 0.9502 - val_loss: 0.1674 - val_accuracy: 0.9564\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.1689 - accuracy: 0.9532 - val_loss: 0.1547 - val_accuracy: 0.9610\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.1612 - accuracy: 0.9552 - val_loss: 0.1597 - val_accuracy: 0.9572\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.1530 - accuracy: 0.9574 - val_loss: 0.1406 - val_accuracy: 0.9618\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.1463 - accuracy: 0.9588 - val_loss: 0.1293 - val_accuracy: 0.9670\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.1373 - accuracy: 0.9620 - val_loss: 0.1223 - val_accuracy: 0.9712\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.1311 - accuracy: 0.9654 - val_loss: 0.1185 - val_accuracy: 0.9702\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.1244 - accuracy: 0.9666 - val_loss: 0.1138 - val_accuracy: 0.9728\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.1182 - accuracy: 0.9700 - val_loss: 0.1096 - val_accuracy: 0.9718\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.1124 - accuracy: 0.9714 - val_loss: 0.1038 - val_accuracy: 0.9742\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.1055 - accuracy: 0.9750 - val_loss: 0.0986 - val_accuracy: 0.9770\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9744 - val_loss: 0.0878 - val_accuracy: 0.9810\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0951 - accuracy: 0.9772 - val_loss: 0.0966 - val_accuracy: 0.9780\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0929 - accuracy: 0.9774 - val_loss: 0.0827 - val_accuracy: 0.9810\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0873 - accuracy: 0.9790 - val_loss: 0.0765 - val_accuracy: 0.9830\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0823 - accuracy: 0.9812 - val_loss: 0.0852 - val_accuracy: 0.9792\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.0788 - accuracy: 0.9810 - val_loss: 0.0698 - val_accuracy: 0.9852\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0740 - accuracy: 0.9840 - val_loss: 0.0724 - val_accuracy: 0.9840\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0712 - accuracy: 0.9836 - val_loss: 0.0650 - val_accuracy: 0.9862\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.0666 - accuracy: 0.9852 - val_loss: 0.0634 - val_accuracy: 0.9882\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.0620 - accuracy: 0.9882 - val_loss: 0.0603 - val_accuracy: 0.9870\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0593 - accuracy: 0.9886 - val_loss: 0.0546 - val_accuracy: 0.9904\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0565 - accuracy: 0.9892 - val_loss: 0.0528 - val_accuracy: 0.9908\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0536 - accuracy: 0.9906 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0503 - accuracy: 0.9914 - val_loss: 0.0516 - val_accuracy: 0.9894\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0486 - accuracy: 0.9904 - val_loss: 0.0419 - val_accuracy: 0.9940\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0467 - accuracy: 0.9922 - val_loss: 0.0400 - val_accuracy: 0.9944\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0435 - accuracy: 0.9932 - val_loss: 0.0372 - val_accuracy: 0.9956\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0416 - accuracy: 0.9932 - val_loss: 0.0370 - val_accuracy: 0.9956\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.0396 - accuracy: 0.9946 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 0.0375 - accuracy: 0.9952 - val_loss: 0.0331 - val_accuracy: 0.9970\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0357 - accuracy: 0.9952 - val_loss: 0.0309 - val_accuracy: 0.9974\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0334 - accuracy: 0.9960 - val_loss: 0.0295 - val_accuracy: 0.9970\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 0.0323 - accuracy: 0.9956 - val_loss: 0.0283 - val_accuracy: 0.9978\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0307 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9976\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0293 - accuracy: 0.9972 - val_loss: 0.0255 - val_accuracy: 0.9982\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.0276 - accuracy: 0.9982 - val_loss: 0.0243 - val_accuracy: 0.9988\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.0268 - accuracy: 0.9982 - val_loss: 0.0261 - val_accuracy: 0.9972\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0253 - accuracy: 0.9978 - val_loss: 0.0226 - val_accuracy: 0.9992\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.0243 - accuracy: 0.9982 - val_loss: 0.0223 - val_accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.0234 - accuracy: 0.9988 - val_loss: 0.0209 - val_accuracy: 0.9992\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.0213 - val_accuracy: 0.9992\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0213 - accuracy: 0.9990 - val_loss: 0.0194 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0205 - accuracy: 0.9992 - val_loss: 0.0188 - val_accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0197 - accuracy: 0.9988 - val_loss: 0.0181 - val_accuracy: 0.9994\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0189 - accuracy: 0.9992 - val_loss: 0.0170 - val_accuracy: 0.9994\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9994 - val_loss: 0.0179 - val_accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0175 - accuracy: 0.9994 - val_loss: 0.0162 - val_accuracy: 0.9996\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.0166 - accuracy: 0.9996 - val_loss: 0.0147 - val_accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0158 - accuracy: 0.9996 - val_loss: 0.0145 - val_accuracy: 0.9996\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0152 - accuracy: 0.9998 - val_loss: 0.0139 - val_accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0147 - accuracy: 0.9996 - val_loss: 0.0134 - val_accuracy: 0.9998\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0142 - accuracy: 0.9996 - val_loss: 0.0130 - val_accuracy: 0.9996\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0138 - accuracy: 0.9996 - val_loss: 0.0141 - val_accuracy: 0.9996\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9996 - val_loss: 0.0121 - val_accuracy: 0.9998\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.0129 - accuracy: 0.9996 - val_loss: 0.0120 - val_accuracy: 0.9998\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0124 - accuracy: 0.9998 - val_loss: 0.0111 - val_accuracy: 0.9998\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0121 - accuracy: 0.9996 - val_loss: 0.0110 - val_accuracy: 0.9998\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0114 - accuracy: 0.9998 - val_loss: 0.0112 - val_accuracy: 0.9998\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0111 - accuracy: 0.9998 - val_loss: 0.0102 - val_accuracy: 0.9998\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0109 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 0.9998\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.9996 - val_loss: 0.0097 - val_accuracy: 0.9998\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9998 - val_loss: 0.0090 - val_accuracy: 0.9998\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0097 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9998\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.0087 - val_accuracy: 0.9998\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;,\n",
       "                   param_distributions={&#x27;batch_size&#x27;: [10, 20, 30],\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x178023190&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: array([0, 1, 2, 3]),\n",
       "                                        &#x27;n_neurons&#x27;: array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "       67, 68, 69])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;,\n",
       "                   param_distributions={&#x27;batch_size&#x27;: [10, 20, 30],\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x178023190&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: array([0, 1, 2, 3]),\n",
       "                                        &#x27;n_neurons&#x27;: array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "       67, 68, 69])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x17a75feb0>,\n",
       "                   param_distributions={'batch_size': [10, 20, 30],\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x178023190>,\n",
       "                                        'n_hidden': array([0, 1, 2, 3]),\n",
       "                                        'n_neurons': array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "       67, 68, 69])})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv_opt = RandomizedSearchCV(keras_class, opt_param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv_opt.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                           tensorboard_cb],\n",
    "                  workers=2\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 10,\n",
       " 'learning_rate': 0.0071704255138615785,\n",
       " 'n_hidden': 2,\n",
       " 'n_neurons': 59}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv_opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9194000164667765"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv_opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv_opt.best_estimator_.model\n",
    "model.save(\"keras_model_mnist_2nd_rnd_search.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 72.2005 - accuracy: 0.9251\n"
     ]
    }
   ],
   "source": [
    "total_loss= model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17aef8940>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "                validation_data=(X_valid, y_valid),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                           tensorboard_cb],\n",
    "                workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 76.8283 - accuracy: 0.9266\n"
     ]
    }
   ],
   "source": [
    "total_loss= model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred.round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a wide and deep model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :14], X_train[:, 12:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :14], X_valid[:, 12:]\n",
    "X_test_A, X_test_B = X_test[:, :14], X_test[:, 12:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complex_model(n_hidden=3, n_neurons=40, learning_rate=3e-3, input_shape=[28, 28]):\n",
    "    num_output_neurons = 10\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    # flatten_A = keras.layers.Flatten(input_shape=input_shape)\n",
    "    input_1 = keras.layers.Input(shape=input_shape)\n",
    "    input_2 = keras.layers.Input(shape=input_shape)\n",
    "    # input_B = keras.Input(shape=input_shape)\n",
    "    # input_A = keras.layers.Flatten()(input_1)\n",
    "    # input_B = keras.layers.Flatten()(input_2)\n",
    "    for i in range(n_hidden):\n",
    "        if i == 0:\n",
    "            hidden = keras.layers.Dense(n_neurons, activation=\"relu\")(input_B)\n",
    "        else:\n",
    "            hidden = keras.layers.Dense(n_neurons, activation=\"relu\")(hidden)\n",
    "    concat = keras.layers.concatenate([input_A, hidden], axis=1)\n",
    "    aux_output = keras.layers.Dense(num_output_neurons, activation=\"softmax\")(hidden)\n",
    "    main_output = keras.layers.Dense(num_output_neurons, activation=\"softmax\")(concat)\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model = keras.models.Model(inputs=[input_A, input_B], \n",
    "                                    outputs=[main_output, aux_output])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "model = build_complex_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_359 (Dense)              (None, 40)           280         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_360 (Dense)              (None, 40)           1640        ['dense_359[0][0]']              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_361 (Dense)              (None, 40)           1640        ['dense_360[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 45)           0           ['input_5[0][0]',                \n",
      "                                                                  'dense_361[0][0]']              \n",
      "                                                                                                  \n",
      " dense_363 (Dense)              (None, 10)           460         ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_362 (Dense)              (None, 10)           410         ['dense_361[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,430\n",
      "Trainable params: 4,430\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xc/zkw390zs49vd6b73myjws_n40000gn/T/ipykernel_1491/977379048.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_complex_model)\n"
     ]
    }
   ],
   "source": [
    "keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_complex_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_5\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 14, 28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m run_logdir \u001b[39m=\u001b[39m get_run_logdir()\n\u001b[1;32m      3\u001b[0m tensorboard_cb \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(run_logdir)\n\u001b[0;32m----> 4\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit([X_train_A, X_train_B], [y_train, y_train], epochs\u001b[39m=\u001b[39;49m\u001b[39m80\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                 validation_data\u001b[39m=\u001b[39;49m([X_valid_A, X_valid_B], [y_valid, y_valid]),\n\u001b[1;32m      6\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m),\n\u001b[1;32m      7\u001b[0m                            tensorboard_cb],\n\u001b[1;32m      8\u001b[0m                 workers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/xc/zkw390zs49vd6b73myjws_n40000gn/T/__autograph_generated_file5pcdxpea.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/drewimhof/micromamba/envs/robostackenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_5\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 14, 28)\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=80,\n",
    "                validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                           tensorboard_cb],\n",
    "                workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_class.fit([X_train_A, X_train_B], [y_train, y_train], epochs=80,\n",
    "                validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                           tensorboard_cb],\n",
    "                workers=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robostackenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
